[{"title":"Typescript 入门","path":"/posts/14017.html","content":"环境和工具配置安装依赖WebStorm 配置","tags":["前端","Typescript"],"categories":["前端"]},{"title":"【面试相关】并发编程","path":"/posts/19520.html","content":"线程和进程有什么区别 进程 是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。 每个进程拥有独立的内存空间（包括代码、数据、堆栈等）。 Java 中，启动 main 函数的时候就是启动了一个 JVM 进程，而 main 函数所在的线程也被称为主线程。 线程 和进程类似，但是单位比进程更小。一个进程在执行过程中可以产生多个线程。 同一进程内的线程共享进程的资源（如内存、文件句柄等），但拥有独立的栈空间和程序计数器。 线程的生命周期线程在生命周期中并不是固定处于某一个状态而是随着代码的执行在不同状态之间切换。 NEW: 初始状态，线程被创建出来但没有被调用 start() 。 RUNNABLE: 运行状态，线程被调用了 start()等待运行的状态。 BLOCKED：阻塞状态，需要等待锁释放。 WAITING：等待状态，表示该线程需要等待其他线程做出一些特定动作（通知或中断）。 TIME_WAITING：超时等待状态，可以在指定的时间后自行返回而不是像 WAITING 那样一直等- 待。 TERMINATED：终止状态，表示该线程已经运行完毕。 直接创建线程的两种方式继承 Thread 类 创建方式 12345678910111213141516public class ThreadExample &#123; public static void main(String[] args) &#123; MyThread myThread = new MyThread(); myThread.start(); System.out.println(&quot;主线程启动&quot;); &#125;&#125;class MyThread extends Thread &#123; @Override public void run() &#123; System.out.println(&quot;MyThread线程启动&quot;); &#125;&#125; 适用场景 简单、一次性的线程任务，无需复用逻辑。 优点 简单直观，直接操作线程 缺点 使用继承方式实现，导致类无法再继承其他类，降低代码扩展性；任务逻辑和线程耦合，每个子类只能定义一种任务逻辑，复用性差；手动创建线程，缺乏复用机制，容易导致资源浪费。 实现 Runnable 接口 创建方式 123456789101112131415public class RunnableExample &#123; public static void main(String[] args) &#123; Thread t1 = new Thread(new MyRunnable()); t1.start(); &#125;&#125;class MyRunnable implements Runnable &#123; @Override public void run() &#123; System.out.println(&quot;MyRunnable线程启动&quot;); &#125;&#125; 适用场景 任务逻辑需要被多个线程共享（比如多线程下载统一资源）；负责项目中需要统一管理任务，推荐结合线程池。 优点 可以同时实现其他接口；同一个 Runnable 实例可以被多个线程复用，支持多线程共享资源；与线程池兼容，便于大规模并发场景。 缺点 需要使用 Thread 类包装，间接创建了线程（本质上还是通过 Thread 创建了新线程）；无法直接访问 Thread 的方法，需要获取当前线程（&#96;&#96;&#96;Thread.currentThread() 方法）。 实现 Callable 接口 创建方式 1234567891011121314151617public class CallableExample &#123; public static void main(String[] args) throws InterruptedException, ExecutionException &#123; FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;&gt;(new MyCallable()); Thread thread = new Thread(futureTask); thread.start(); System.out.println(&quot;线程返回值：&quot; + futureTask.get()); &#125;&#125;class MyCallable implements Callable&lt;Integer&gt; &#123; @Override public Integer call() throws Exception &#123; return 100; &#125;&#125; 适用场景 需要返回值的异步任务；异步任务需要抛出异常；任务有明确的生命周期。 优点 支持返回值；异常处理晚上；与线程池完美结合（submit() 方法支持直接提交 Callable() 任务，并返回 Future 对象）； 缺点 复杂度较高； 方法会阻塞当前线程，直到结果返回，可能会导致性能问题。12345678910111213141516171819### 使用线程池- 创建方式 ```java public class ThreadPoolExample &#123; public static void main(String[] args) &#123; ExecutorService executorService = Executors.newFixedThreadPool(5); executorService.submit(()-&gt;&#123;System.out.println(&quot;Task 1&quot;);&#125;); executorService.submit(()-&gt;&#123;System.out.println(&quot;Task 2&quot;);&#125;); executorService.submit(()-&gt;&#123;System.out.println(&quot;Task 3&quot;);&#125;); executorService.shutdown(); &#125; &#125; 适用场景 优点 缺点 常用操作方法插一嘴题外话，其实 Thread 类也实现了 Runnable 接口，并且重写了 run() 方法。这二者在多线程中扮演的角色不同：Thread 是线程执行者，代表线程本身，拥有执行代码的能力；Runnable 是线程任务，代表了线程要执行的任务，只有一个 run() 方法。这样做将二者解耦，更加专注于本身的任务。 start() 为什么 start() 源码中没有直接调用 run()是线程启动的入口，通过 JVM 创建新线程，在新线程中执行 run()start()方法源码1234567891011121314151617181920212223public synchronized void start() &#123; // 检查线程状态是否为 NEW，避免重复启动 if (threadStatus != 0) throw new IllegalThreadStateException(); // 将线程添加到所属的线程组 group.add(this); boolean started = false; try &#123; // 调用下面的 start0() 方法启动线程 start0(); started = true; &#125; finally &#123; try &#123; if (!started) &#123; group.threadStartFailed(this); &#125; &#125; catch (Throwable ignore) &#123; // 抛出异常后向上传递 &#125; &#125;&#125;start0()方法源码12// 此处标记为了 native，调用 JVM 本地库中的其他语言实现的功能private native void start0(); 方法作用：创建并启动一个新线程，异步执行（调用后立即返回，新线程独立运行） 调用次数：每个线程只能调用 1 次 线程状态：调用后，线程状态从 NEW 变为 RUNNABLE run() run()方法源码123456@Overridepublic void run() &#123; if (target != null) &#123; target.run(); &#125;&#125; 方法作用：线程的执行者，包含了线程的具体逻辑，同步执行（调用时在当前线程执行） 调用次数：可以调用多次 线程状态：不影响 sleep()、wait() 参照下面的章节 isAlive() 判断线程是否处于运行状态。 只有线程状态为 已启动并且尚未终止 时，返回 true，否则返回 false。 sleep() 和 wait() 的区别 Sleep()方法 所属类：Thread 类的静态方法 锁的持有与释放：不释放锁（即使暂停，仍持有对象锁） 唤醒条件：自动恢复（经过指定时间后） 线程状态：TIMED_WAITING 调用前的条件：无需同步块（但若在同步块中，仍持有锁） 返回时机：时间到或被中断 异常处理：抛出 InterruptedException Wait() 方法 所属类：Object 类的实例方法 锁的持有与释放：释放锁（调用前必须持有锁，调用后释放） 唤醒条件：依赖外部唤醒（需其他线程调用 notify() &#x2F; notifyAll() ） 线程状态：WAITING（或 TIMED_WAITING，若使用 wait(long timeout) ） 调用前的条件：必须在同步块 synchronized 中调用（否则抛出异常 IllegalMonitorStateException ） 返回时机：被 notify() &#x2F; notifyAll() 唤醒、超时或被中断 异常处理：抛出 InterruptedException","tags":["面试","多线程","并发"],"categories":["面试"]},{"title":"SpringCloud Alibaba 搭建过程 03","path":"/posts/24065.html","content":"Sentinel以流量为切入点，从流量控制、流量路由、熔断降级、系统自适应过载保护、热点流量防护等多个维度保护服务的稳定性。","tags":["SpringCloud Alibaba","微服务"],"categories":["SpringCloud Alibaba"]},{"title":"Ubuntu 常用操作和环境搭建","path":"/posts/18381.html","content":"Oracle JDK 17为什么是 Oracle JDK 而不是 Open JDKNacos 2.3.2 开启鉴权后控制台无论使用什么密码登录都显示账户密码错误Nacos踩坑记录：配置鉴权后控制台无法登录,返回 Invalid key: javax.crypto.spec.SecretKeySpec 切换到 root1sudo su 创建安装目录，并且把下载的安装包上传到该目录下Oracle jdk 171mkdir /usr/lib/jvm 解压安装包1sudo tar -zxvf jdk-17.0.15_linux-x64_bin.tar.gz -C /usr/lib/jvm 配置环境变量（全局配置），打开 /etc/profile 文件1sudo nano /etc/profile /etc/profile 文件末尾添加内容（保存：Ctrl + o，退出：Ctrl + x），12export JAVA_HOME=/usr/lib/jvm/jdk-17.0.15export PATH=$JAVA_HOME/bin:$PATH 刷新全局配置文件1source /etc/profile 验证环境变量、Java 命令（和步骤三结果相同）12345echo $JAVA_HOMEecho $PATH java -versionjavac -version 预期输出java -version123java version &quot;17.0.15&quot; 2025-04-15 LTSJava(TM) SE Runtime Environment (build 17.0.15+9-LTS-241)Java HotSpot(TM) 64-Bit Server VM (build 17.0.15+9-LTS-241, mixed mode, sharing)javac -version1javac 17.0.15 Nacos 2.3.2【Nacos】Nacos 2.3.2版本安装配置过程记录和踩坑分享 下载压缩包：nacos github releases 新建文件夹，并上传压缩包 12cd /optmkdir nacos 解压缩 1sudo tar -zxvf nacos-server-2.3.2.tar.gz 导入数据库脚本，路径：&#x2F;opt&#x2F;nacos&#x2F;conf&#x2F;mysql-schema.sql 修改配置文件 1234567### Count of DB:db.num=1 ### Connect URL of DB:db.url.0=jdbc:mysql://127.0.0.1:3306/nacos?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=true&amp;useUnicode=true&amp;useSSL=false&amp;serverTimezone=UTCdb.user.0=数据库用户名db.password.0=数据库密码 此处配置完成后可以启动了，但是会发现不需要账号密码就可以登陆（记得放行端口） 1234cd /opt/nacos/bin./startup.sh -m standalone ps -ef| grep nacos| grep -v grep 鉴权配置此处一定要把默认用户名和密码都设置为nacos，登录成功后在右上角修改密码，然后再登出重新登录使密码生效； 密钥需要将一个不低于32位长度的字符串，转为base64编码 base64编码Base64 编码&#x2F;解码原字符串：jL4iM8vX7vQ6lT8rX6aX5eB7nO6mW4jY转为base64后：akw0aU04dlg3dlE2bFQ4clg2YVg1ZUI3bk82bVc0alk&#x3D; 123456789### If turn on auth system:nacos.core.auth.enabled=true ### 默认用户名和密码nacos.core.auth.server.identity.key=nacosnacos.core.auth.server.identity.value=nacos ### 密钥nacos.core.auth.plugin.nacos.token.secret.key=eEo1ZlkybVIxY001b1Y1ckszZVkweFE2YVMwbkw5eFk= 添加命名空间（在数据库的表 tenant_info 中查看，测试是否正常） 为当前用户绑定权限权限控制 → 权限管理 → 添加权限此处角色名选择 ROLE_ADMIN","tags":["Ubuntu"],"categories":["其他"]},{"title":"SpringCloud Alibaba 搭建过程 02","path":"/posts/40641.html","content":"nacos 安装和配置参考：Ubuntu 常用操作和环境搭建 nacos 项目内配置 两个子模块都需要添加依赖 123456789101112&lt;!-- nacos服务注册发现 --&gt;&lt;dependency&gt;&lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;&lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- loadbalancer启动器 naocs2.2版本取消了自带的负载均衡器需要加这个 --&gt;&lt;dependency&gt;&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&lt;artifactId&gt;spring-cloud-starter-loadbalancer&lt;/artifactId&gt;&lt;/dependency&gt; 修改配置文件 application.properties 12345678910# 服务名称spring.application.name=order-servicespring.cloud.loadbalancer.nacos.enabled=true# ip地址和端口号spring.cloud.nacos.discovery.server-addr=ip地址:端口号spring.cloud.nacos.discovery.username=用户名spring.cloud.nacos.discovery.password=密码spring.cloud.nacos.discovery.namespace=public 修改 order 模块中的测试方法，确保服务可用 1234567@RequestMapping(&quot;/add&quot;)public String add() &#123; System.out.println(&quot;下单成功&quot;); // 在order里面调用stock服务 String msg = restTemplate.getForObject(&quot;http://stock-service/stock/reduce&quot;, String.class); return &quot;下单成功&quot; + msg;&#125; 启动两个本地应用后，在nacos后台查看服务是否注册成功 常用方法和功能服务发现 项目中引入依赖 1234567891011&lt;!-- nacos服务注册发现 --&gt;&lt;dependency&gt;&lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;&lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- loadbalancer启动器 新版本的springcloud去掉了ribbon自带的负载均衡器 --&gt;&lt;dependency&gt;&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&lt;artifactId&gt;spring-cloud-starter-loadbalancer&lt;/artifactId&gt;&lt;/dependency&gt; 在文件 application.properties 中添加配置： 12345678# Nacos 配置spring.cloud.loadbalancer.nacos.enabled=true# Nacos 服务发现spring.cloud.nacos.discovery.server-addr=$&#123;NACOS_ADDRESS&#125;spring.cloud.nacos.discovery.username=$&#123;NACOS_NAME&#125;spring.cloud.nacos.discovery.password=$&#123;NACOS_PASSWORD&#125;spring.cloud.nacos.discovery.namespace=$&#123;NACOS_namespace&#125; 区分服务发现和配置中心需要注意的是，新版本（Spring Cloud Alibaba 2021.x 开始）中， config 和 discovery 模块被明确区分开，需要分别进行配置。 启动项目后，可以在 nacos 后台查看状态 配置中心 项目中引入依赖 12345&lt;!-- nacos配置中心依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;&lt;/dependency&gt; 在文件 application.properties 中添加配置： 12345678910# Nacos 配置中心spring.config.import=nacos:service-order.propertiesspring.cloud.nacos.config.server-addr=$&#123;NACOS_ADDRESS&#125;spring.cloud.nacos.config.username=$&#123;NACOS_NAME&#125;spring.cloud.nacos.config.password=$&#123;NACOS_PASSWORD&#125;spring.cloud.nacos.config.namespace=$&#123;NACOS_namespace&#125;# Nacos 禁用配置中心检查#spring.cloud.nacos.config.import-check.enabled=false 区分服务发现和配置中心需要注意的是，新版本（Spring Cloud Alibaba 2021.x 开始）中， config 和 discovery 模块被明确区分开，需要分别进行配置。 创建 data-id （数据集），配置需要导入的信息 自动刷新功能，需要在 controller 类上添加注解：@RefreshScope 测试方法 12345678910111213@Value(&quot;$&#123;order.timeout&#125;&quot;)private String orderTimeout;@Value(&quot;$&#123;order.auto-confirm&#125;&quot;)private String orderAutoConfirm;/** * 获取配置中心测试类* @return*/@GetMapping(&quot;/getConfigTest&quot;)public String getConfigTest() &#123; return &quot;order.timeout: &quot; + orderTimeout + &quot;; order.auto-confirm&quot; + orderAutoConfirm;&#125; 配置中心的优先级远程配置优先级高于本地配置 数据隔离 + 环境切换 项目启动激活某一个环境，去加载指定的 namespace，区分环境 指定的 group 区分微服务、data-id 区分配置， 最终实现数据隔离和环境切换 配置监听 项目启动就监听配置文件变化 拿到变化后的值 发送邮件提醒 Open Feign集成 引入依赖 12345&lt;!-- Open Feign --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; 启动类上添加注解，确保 Feign 客户端会被注册 123456789// 添加 Feign 注解@EnableFeignClients(basePackages = &quot;com.example.order.feign&quot;)@SpringBootApplicationpublic class OrderApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(OrderApplication.class, args); &#125;&#125; 创建 Feign 客户端和方法 12345678910111213141516 /** * 商品服务 Feign */// Feign 客户端，指定调用微服务的名称 @FeignClient(value = &quot;product-service&quot;) public interface ProductFeignClient &#123; /** * 获取商品信息 * * 调用该方法时，是给 product-service 服务的 getProductById 方法发送请求 * @param id */ @GetMapping(&quot;/getProductById/&#123;id&#125;&quot;) ProductEntity getProductById(@PathVariable(&quot;id&quot;) Long id); &#125; 远程调用 12345678910111213141516171819202122232425@Servicepublic class OrderServiceImpl implements OrderService &#123; // 注入 Feign @Resource private ProductFeignClient productFeignClient; @Override public OrderEntity createOrder(Long productId, Long userId) &#123; // 调用商品服务，使用 feign 获取商品信息 ProductEntity productEntity = productFeignClient.getProductById(productId); OrderEntity orderEntity = new OrderEntity(); orderEntity.setId(1L); orderEntity.setTotalAmount(productEntity.getPrice().multiply(new BigDecimal(productEntity.getNum()))); orderEntity.setUserId(userId); orderEntity.setNickName(&quot;zhangsan&quot;); orderEntity.setAddress(&quot;派送地址&quot;); orderEntity.setProductList(Arrays.asList(productEntity)); return orderEntity; &#125;&#125; 第三方 API 调用OpenFeign - 远程调用 - 第三方API 常用注解FeignClient，声明一个远程调用客户端，常用属性： value，调用的服务名 path，统一前缀，类似 controller 上的 @RequestMapping； contexId，定义上下文 如果多个 Feign 客户端调用同一个服务名，Spring 会因为 Bean 名称冲突而报错，使用 contexId 为每个客户端指定唯一标识： 123456789// commonserver 是公用服务类// 客户端1：调用公告接口@FeignClient(value = &quot;commonserver&quot;, contextId = &quot;notice&quot;, path = &quot;/commonserver&quot;)public interface NoticeRemoteService &#123; ... &#125;// 客户端2：调用推送接口@FeignClient(value = &quot;commonserver&quot;, contextId = &quot;push&quot;, path = &quot;/commonserver&quot;)public interface PushRemoteService &#123; ... &#125; @RequestMapping、 @GetMapping、 @PostMapping 等，用法和 Spring MVC 中一致： 放在 controller 上：表示接收并处理该类型的 HTTP 请求： 当访问 &#x2F;users&#x2F;123 时，会调用 getUser 方法。 12345678@RestController@RequestMapping(&quot;/users&quot;)public class UserController &#123; @GetMapping(&quot;/&#123;id&#125;&quot;) public User getUser(@PathVariable Long id) &#123; return userService.findById(id); &#125;&#125; 放在 feign 上：表示该方法将要以这种类型调用远程服务的某个接口： 调用 userServiceClient.getUserById(123) 时，会向 user-service 的 &#x2F;users&#x2F;123 发起 GET 请求。 12345@FeignClient(name = &quot;user-service&quot;)public interface UserServiceClient &#123; @GetMapping(&quot;/users/&#123;id&#125;&quot;) User getUserById(@PathVariable(&quot;id&quot;) Long id);&#125; 日志功能官方文档 Feign logging application.properties 设置日志级别 12# 日志级别logging.level.com.example.order.feign=debug 新建配置类 12345678910@Configurationpublic class FeignConfig &#123; // Logger 一定是 feign 包下的 @Bean Logger.Level feignLoggerLevel() &#123; return Logger.Level.FULL; &#125;&#125; 测试 超时控制场景 服务宕机连接不上 API 速度慢不返回，读取不到 流程图 配置限时等待时间连接超时，connectTimeout：和服务端建立连接的最大等待时间读取超时，readTimeout：等待服务端返回响应的最大时间 全局配置 123spring.cloud.openfeign.client.config.default.logger-level=fullspring.cloud.openfeign.client.config.default.connect-timeout=3000spring.cloud.openfeign.client.config.default.read-timeout=5000 为某个服务单独配置 实际上应该使用上下文 contextId，用来区分不同的客户端 @FeignClient(value = &quot;product-service&quot;, contextId = &quot;product-info&quot;) 123spring.cloud.openfeign.client.config.product-info.logger-level=fullspring.cloud.openfeign.client.config.product-info.connect-timeout=3000spring.cloud.openfeign.client.config.product-info.read-timeout=5000 多个组件的超时注意事项Hystrix 处于最外层，起到熔断保护作用；Ribbon 在内层，负责负载均衡及发起 HTTP 请求等操作。由于这种层级关系，Hystrix 的熔断时间设置有特定要求：它必须大于 Ribbon 的 ConnectTimeout（连接超时时间）与 ReadTimeout（读取超时时间）之和。若 Ribbon 开启了重试机制（这里的重试可能是 Ribbon 自身的重试，也可能是 Feign 的重试 ），那么 Hystrix 的熔断时间还需大于 （ConnectTimeout + ReadTimeout）乘以重试次数的结果。这样才能确保在 Ribbon 里的请求还未结束时，Hystrix 不会因超时触发熔断。 重试机制底层使用 Retrywer，默认的重试参数为： 初始重试间隔时间（第一次失败后等待的时间），100ms 最大重试间隔时间（每次重试间隔会指数增长，但不会超过这个值），1s 最大重试次数（包括首次请求），5 FeignConfig类配置1234@Beanpublic Retryer feignRetryer() &#123; return new Retryer.Default();&#125; 源码1234// 参数依次为：初始重试间隔时间、最大重试间隔时间、最大重试次数public Default() &#123; this(100L, TimeUnit.SECONDS.toMillis(1L), 5);&#125; 拦截器有请求拦截器（RequestInterceptor）和响应拦截器（ResponseInterceptor），此处以请求拦截器为例： 创建请求拦截器配置类 123456789101112131415package com.example.order.interceptor;@Componentpublic class XTokenRequestInterceptor implements RequestInterceptor &#123; /** * 请求拦截器 * * @param requestTemplate 请求模板 */ @Override public void apply(RequestTemplate requestTemplate) &#123; requestTemplate.header(&quot;XToken&quot;, UUID.randomUUID().toString()); &#125;&#125; 生效方法 在类上添加 @component 注解，组件会自动扫描注册 在配置文件 application 中添加（仅对配置的服务生效）： 12# 请求拦截器配置spring.cloud.openfeign.client.config.service-order.request-interceptors=com.example.order.interceptor.XTokenRequestInterceptor 测试（在原有的 ProductController 测试方法中添加） 1234567891011@GetMapping(&quot;/getProductById/&#123;id&#125;&quot;)public ProductEntity getProductById(@PathVariable(&quot;id&quot;) Long id, HttpServletRequest request) &#123; String header = request.getHeader(&quot;XToken&quot;); System.out.println(&quot;自定义请求头为：&quot; + header); ProductEntity product = productService.getProductById(id); return product;&#125; Fallback此功能需要结合 Sentinel 实现 参考下面的使用场景，当出现超时或失败时，可以返回兜底数据，继续推进业务逻辑使用场景 - 流程图 添加依赖 1234&lt;dependency&gt;&lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;&lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt;&lt;/dependency&gt; 配置文件添加属性 12# fallback 启用feign.sentinel.enabled=true 创建 fallback 类，实现对应的 feignclient 方法 123456789101112131415161718192021package com.example.order.feign.fallback;@Componentpublic class ProductFeignFallback implements ProductFeignClient &#123; /** * 获取商品信息接口兜底数据返回 * * @param id * @return */ @Override public ProductEntity getProductById(Long id) &#123; ProductEntity productEntity = new ProductEntity(); productEntity.setId(id); productEntity.setPrice(new BigDecimal(&quot;1&quot;)); productEntity.setName(&quot;未知商品&quot;); productEntity.setNum(1); return productEntity; &#125;&#125; feignclient 类上添加注解 12345678910111213@FeignClient(value = &quot;product-service&quot;, fallback = ProductFeignFallback.class) // Feign 客户端，指定调用微服务的名称public interface ProductFeignClient &#123; /** * 获取商品信息 * * 调用该方法时，是给 product-service 服务的 getProductById 方法发送请求 * @param id */ @GetMapping(&quot;/getProductById/&#123;id&#125;&quot;) ProductEntity getProductById(@PathVariable(&quot;id&quot;) Long id);&#125; 关闭商品服务（为了方便测试） 测试结果123456789101112131415&#123; &quot;id&quot;: 1, &quot;totalAmount&quot;: 1, &quot;userId&quot;: 123, &quot;nickName&quot;: &quot;zhangsan&quot;, &quot;address&quot;: &quot;派送地址&quot;, &quot;productList&quot;: [ &#123; &quot;id&quot;: 22, &quot;price&quot;: 1, &quot;name&quot;: &quot;未知商品&quot;, &quot;num&quot;: 1 &#125; ]&#125;","tags":["SpringCloud Alibaba","微服务"],"categories":["SpringCloud Alibaba"]},{"title":"SpringCloud Alibaba 搭建过程 01","path":"/posts/13792.html","content":"组件和对应功能 Nacos：服务发现、治理，注册中心；系统配置 Feign：服务间通信（HTTP + Feign） Gateway：网关 Sentinel：流量控制，限流，熔断 Skywalking：链路追踪 Seata：分布式事物 组件版本关系版本发布说明 配置项 版本号 Java 17 spring-boot 3.2.4 spring-cloud 2023.0.1 Spring Cloud Alibaba 2023.0.1.0 Sentinel 1.8.6 Nacos 2.3.2 RocketMQ 5.1.4 Seata 2.0.0 项目基础框架搭建项目结构 父工程创建 创建父工程 不需要选择依赖，直接下一步 删除多余的文件 pom.xml 文件修改，直接覆盖即可（项目名等需要修改） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;groupId&gt;com.example.cloud&lt;/groupId&gt;&lt;artifactId&gt;cloud-practice&lt;/artifactId&gt;&lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;name&gt;cloud-practice&lt;/name&gt;&lt;description&gt;cloud-practice&lt;/description&gt;&lt;modules&gt; &lt;module&gt;order&lt;/module&gt; &lt;module&gt;stock&lt;/module&gt;&lt;/modules&gt;&lt;packaging&gt;pom&lt;/packaging&gt;&lt;properties&gt; &lt;java.version&gt;17&lt;/java.version&gt; &lt;spring-boot.version&gt;3.2.4&lt;/spring-boot.version&gt; &lt;spring-cloud.version&gt;2023.0.1&lt;/spring-cloud.version&gt; &lt;spring-cloud-alibaba.version&gt;2023.0.1.0&lt;/spring-cloud-alibaba.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;!--springboot基本场景启动器--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--springboot测试场景启动器--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!-- springboot版本管理器 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-boot.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- springCloud --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- springCloudAlibaba --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud-alibaba.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;/project&gt; 子模块添加 创建子模块 order 模块 pom.xml 文件修改 12345678910111213141516171819&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;parent&gt; &lt;groupId&gt;com.example.cloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-practice&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;artifactId&gt;order&lt;/artifactId&gt;&lt;packaging&gt;jar&lt;/packaging&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;/project&gt; stock 模块 pom.xml 文件修改 12345678910111213141516171819&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;parent&gt; &lt;groupId&gt;com.example.cloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-practice&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;artifactId&gt;stock&lt;/artifactId&gt;&lt;packaging&gt;jar&lt;/packaging&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;/project&gt; order 模块启动文件创建 OrderApplication 123456789101112131415161718@SpringBootApplicationpublic class OrderApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(OrderApplication.class, args); &#125; /** * 负载均衡方法，可以找到对应服务 * @param builder * @return */ @Bean public RestTemplate restTemplate(RestTemplateBuilder builder) &#123; RestTemplate restTemplate = builder.build(); return restTemplate; &#125;&#125; stock 模块启动文件创建 StockApplication 1234567@SpringBootApplicationpublic class StockApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(StockApplication.class, args); &#125;&#125; 修改端口（两个模块都需要修改） 123server.port=8010 # order模块端口号server.port=8011 # stock模块端口号 order 模块 测试方法 123456789101112131415@RestController@RequestMapping(&quot;/order&quot;)public class OrderController &#123; @Autowired RestTemplate restTemplate; @RequestMapping(&quot;/add&quot;) public String add() &#123; System.out.println(&quot;下单成功&quot;); // 在order里面调用stock服务 String msg = restTemplate.getForObject(&quot;http://localhost:8011/stock/reduce&quot;, String.class); return &quot;下单成功&quot; + msg; &#125;&#125; stock 模块 测试方法 12345678910@RestController@RequestMapping(&quot;/stock&quot;)public class StockController &#123; @RequestMapping(&quot;/reduce&quot;) public String reduce() &#123; System.out.println(&quot;扣减库存&quot;); return &quot;扣减库存&quot;; &#125;&#125; 测试 分别启动两个服务 在浏览器输入： 1http://localhost:8010/order/add 测试结果","tags":["SpringCloud Alibaba","微服务"],"categories":["SpringCloud Alibaba"]},{"title":"【面试相关】面试遇到的问题","path":"/posts/51863.html","content":"04.11SQL 优化的方案有哪些 索引优化，针对常用的检索条件，例如：where、order、group 后的字段创建索引；使用 EXPLAIN 分析执行计划，确保索引有效命中，减少全表扫描；同时也要注意索引变多带来的额外空间成本和写操作的开销 查询优化，编写查询的时候，尽量选择必要的列，减少回表操作；对于分页查询，可以采用游标分页或者嵌套子查询的方式，解决深分页问题； 对表结构进行优化，表设计时可以适当添加冗余字段，方便查询；避免使用过大的数据类型，减少存储和查询开销 减少单个事务的大小和执行时间，采用分批处理的方式，避免长事务 读写分离 还无法满足，可以考虑引入缓存，比如redis，减少数据库的直接访问压力 模糊查询左侧加%会失效，该怎样处理 创建辅助字段，把索引字段使用 REVERSE() 反向字符串存储，查询条件也反向传入。 缺点：空间换时间，额外存储开销，实际使用不多。 限制查询数量，除了模糊查询字段外，额外添加条件,在业务层面限制查询数量。 使用覆盖索引，确保查询字段均在索引中 1SELECT id, name FROM user WHERE name LIKE &#x27;%san&#x27;; 使用缓存，减少查询次数 小程序登录逻辑是怎样的 用户发起登录：调用 wx.login 获取临时 code。 向后端发送 code：前端将 code 传给后端服务器。 换取 openid 和 session_key：后端用 code + appid + appsecret 请求微信接口，获取用户唯一标识 openid 和会话密钥 session_key。 生成自定义登录态：后端生成 Token（如 JWT），关联用户信息，返回给前端。 前端存储 Token：前端将 Token 存入本地缓存（如 wx.setStorage）。 后续请求携带 Token：前端每次请求后端时，携带 Token 进行身份校验。 500w 数据导出为 Excel 数据库分页或游标逐批读取数据 需要注意工具限制（EasyExcel 对 Sheet 的数据量有要求，不超过104w） 分割为多个 Sheet 04.28微信小程序支付流程佣金分润的功能是在哪一步（支付后？确认收货后？退款了怎么办？） 创建订单：用户下单，后端生成订单并记录状态（待支付）。 统一下单接口：后端调用微信支付接口，生成 prepay_id。 签名返回参数：后端将 prepay_id 等参数签名后返回前端。 调起支付：前端调用 wx.requestPayment，用户输入密码完成支付。 支付结果通知：微信异步通知后端支付结果，后端更新订单状态（已支付）。 佣金分润：会员资格会在支付完成后分润（不支持退款），普通商品在 确认收货后。 公告已读未读功能Springcloud 用过哪些组件Springcloud Gateway断言 作用：定义路由规则，匹配请求是否进入某条路由。 常用断言： Path：匹配请求路径（如 /api/**）。 Query：匹配 URL 参数（如 ?name=xxx）。 Header：匹配请求头（如 X-Request-Id）。 Method：匹配 HTTP 方法（如 GET、POST）。 Cookie：匹配 Cookie 值。 Host：匹配域名（如 **.example.com）。 Nacos 宕机了，远程调用还会成功吗 首次调用失败：因客户端无缓存，需依赖注册中心获取服务列表。 非首次调用成功：客户端缓存了服务列表，但需注意缓存有效期（默认 30s）。 Open Feign 底层了解吗 核心机制： 基于动态代理：为接口生成实现类，将注解转化为 HTTP 请求。 整合 Ribbon：实现负载均衡（从注册中心获取服务列表）。 整合 Hystrix：支持熔断降级（需手动开启）。 请求流程： 解析接口方法上的 @RequestMapping 注解生成 RequestTemplate。 通过 Encoder 序列化参数，发送 HTTP 请求。 通过 Decoder 反序列化响应结果。 Open Feign 请求流程 动态代理生成：基于接口定义生成代理类。 模板构造：解析 @RequestMapping 生成 RequestTemplate。 负载均衡：通过 Ribbon 选择目标服务实例（如轮询策略）。 编码与发送：使用 HttpMessageConverter 序列化参数，发送 HTTP 请求。 响应处理：根据状态码和 Decoder 反序列化结果，抛出 FeignException 异常。 MQ 了解吗 核心概念： 解耦：生产者与消费者无需直接交互。 异步：生产者发送消息后立即返回，消费者异步处理。 削峰填谷：MQ 作为缓冲区应对流量突增。 技术选型： RabbitMQ：基于 AMQP，支持复杂路由（Exchange + Binding）。 Kafka：高吞吐量，适合日志、大数据场景。 RocketMQ：阿里开源，支持事务消息、顺序消息。 常见问题： 消息丢失：生产者确认机制、MQ 持久化、消费者手动 ACK。 重复消费：业务层幂等性设计。 客户端负载均衡和服务端负载均衡的区别MySQL 和 Oracle 的分页有什么区别 MySQL： 1SELECT * FROM table LIMIT offset, size; 直接通过 LIMIT 实现，性能随 offset 增大而下降。 Oracle： 123456789-- 12c 之前SELECT * FROM ( SELECT t.*, ROWNUM rn FROM ( SELECT * FROM table ORDER BY id ) t WHERE ROWNUM &lt;= end) WHERE rn &gt;= start;-- 12c 及以后SELECT * FROM table OFFSET start ROWS FETCH NEXT size ROWS ONLY; 传统方式需嵌套子查询，12c 后语法与 MySQL 趋同。 InnoDB 和 MyISAM 有什么区别 特性 InnoDB MyISAM 事务 支持 不支持 锁粒度 行锁 表锁 外键 支持 不支持 崩溃恢复 支持（Redo Log） 弱 全文索引 5.6+ 支持 支持 适用场景 高并发写、事务 读多写少、静态数据 MyISAM 有哪些使用场景 日志系统：写入后很少修改，频繁读取（如操作日志）。 读密集型应用：报表查询、数据仓库。 全文索引需求：MySQL 5.6 前的版本优先选 MyISAM。 索引了解吗SQL 调优用的是什么 工具： EXPLAIN：分析执行计划，关注 type（访问类型）、key（使用索引）、rows（扫描行数）。 慢查询日志：定位执行时间过长的 SQL。 常见手段： 避免 SELECT *，减少数据传输。 用 JOIN 代替子查询。 对 WHERE 条件字段加索引。 分批处理大数据量更新（如 LIMIT 1000）。 常用的设计模式 单例模式 ：确保一个类只有一个实例（如数据库连接池）。 工厂模式 ：解耦对象创建（如根据配置动态生成不同数据库访问类）。 策略模式 ：动态切换算法（如根据不同地区计算运费）。 观察者模式 ：事件驱动（如用户注册后触发发邮件、积分增加）。 装饰器模式 ：动态添加功能（如 Java IO 流的包装）。 Linux 有没有配置过Nginx 负载均衡策略有哪些？ 轮询（默认）：按顺序分配请求。 加权轮询：根据服务器权重分配流量。 IP Hash：同一 IP 的请求固定到同一服务器。 最少链接：优先分配给连接数最少的服务器。 URL Hash：按 URL 分配，相同 URL 到同一服务器。 两台服务器，怎样使得更多的请求打到高性能服务器 加权轮询：Nginx 中配置高权重。 1234upstream backend &#123; server server1 weight=3; # 高性能 server server2 weight=1;&#125; Least Connections：让处理能力强的服务器快速释放连接，从而接收更多请求。 动态权重：结合监控系统（如 Prometheus），根据实时负载自动调整权重。 05.08简单说一下集合类list 和 set 有什么区别创建线程的方式有哪些 Thread Runnable 字符串和变量怎样比较？变量如果为空呢使用 equals() 方法，不能使用 ==（比较的是内存地址）； 如果使用 equals() 方法没有先判空，会抛出异常：NullPointerException 接口和实现类的区别接口描述了某个对象应该具备的行为或能力，但是不关心具体实现，不能直接实例化，一个类可以实现多个接口； 实现类是接口的具体解决方案，为接口中所有抽象方法提供逻辑实现，更关注“如何做”，可以实例化。区别 Spring 的特点和常用注解简化应用程序的开发和部署，有以下优点： 对象托管，Spring 能赋值和管理所有对象，不需要手动管理对象的创建和依赖关系 动态代理，可以实现大部分逻辑代码复用，避免重复代码 低侵入性，对于业务代码几乎是无侵入的，只需要使用注解即可 AOP 是什么通过动态代理实现，可以将与业务无关但是公用的代码封装起来，降低模块之间的耦合度。 通过 @Aspect 实现日志、事务等横切关注点。 怎样把配置文件的值注入到变量 @Value 注解 @postconstruct 注解 Mybatis 的 #、$ 有什么区别 #{} 预编译，会把入参作为占位符 ？ 编译到 SQL 语句中，之后会进行替换 ${} 直接拼接语句，会直接把 ${} 替换为入参值，有注入风险 Redis 的常见数据类型和使用场景 String：缓存简单键值（如Token）。 Hash：存储对象属性（如用户信息）。 List：消息队列（如最新通知）。 Set：去重标签（如文章标签）。 ZSet：有序排行榜（如游戏积分） Redis 左进右出&#x2F;右进左出 用哪个命令 左进右出（队列，先进先出） 入队命令：RPUSH 出队命令：LPOP 将元素推入列表的右侧（RPUSH），从左侧弹出（LPOP），保证队列顺序。 右进左出（栈，后进先出） 入队命令：LPUSH 出队命令：RPOP 将元素推入列表的左侧（LPUSH），从右侧弹出（RPOP），保证栈的顺序。 Linux 解压命令文件名：test 1tar -zxvf test.tar.gz 怎样查看进程12345# 查看完整格式进程信息ps -ef# 实时显示进程动态top 怎样不打开查看日志12345678# 查看tail filename.log# 查看固定行数（30行）tail -n 30 filename.log# 查看实时tail -f filename.log cat做了什么输出整个文件到终端，适合查看小文件 Nginx 的前端代理和后端代理（正向反向代理） 正向代理 正向代理是客户端的代理，客户端主动设置代理服务器，由代理服务器代为访问外部资源 常见场景：VPN 反向代理 反向代理是服务器端的代理，客户端并不知道代理服务器的存在，代理服务器接收客户端请求后，将请求转发给内部服务器，并将结果返回给客户端。 常见场景：负载均衡、隐藏服务器 IP 对比项 正向代理 反向代理 代理对象 代理客户端 代理服务器 客户端是否感知 客户端需要主动配置代理 客户端无需配置，无感知 常见用途 VPN、隐藏客户端 IP 负载均衡、隐藏服务器 IP 部署位置 客户端网络 服务器端网络 Vue 的生命周期创建阶段 beforeCreate 实例初始化之后，数据观测 (data) 和 event/watcher 事件配置之前被调用。 用途：此时 data 和 methods 尚未初始化，适合初始化非响应式数据。 created 实例已经创建完成之后被调用。完成了数据观测 (data)、property 和 method 的计算、watch/event 事件回调。 用途：数据已经就绪，可以进行数据请求、初始化定时器等异步操作。 挂载阶段 beforeMount 在挂载开始之前被调用：相关的 render 函数首次被调用。 用途：模板编译&#x2F;挂载之前，可对模板进行最后的修改。 mounted 挂载完成后调用（完成 el 选项的编译和替换）。 用途：DOM 操作（如获取元素尺寸、初始化第三方插件）。 更新阶段 beforeUpdate 数据更新时调用，发生在虚拟 DOM 打补丁之前。 用途：在数据更新前访问旧 DOM，可用于清理操作。 updated 数据更新导致的虚拟 DOM 重新渲染和打补丁完成之后调用。 用途：DOM 更新后执行操作（如根据新 DOM 调整样式）。 销毁阶段 **beforeDestroy**（Vue 3 中改为 beforeUnmount） 实例销毁之前调用。此时实例仍然完全可用。 用途：清理定时器、取消事件监听、销毁第三方实例（如 axios 实例）。 **destroyed**（Vue 3 中改为 unmounted） 实例销毁后调用。所有事件监听器和子实例被销毁。 用途：确认资源已释放。 v-if、v-show 的区别v-if：通过条件判断是否渲染元素，切换时触发组件生命周期钩子（如销毁&#x2F;重建），适用于运行时条件变化少的场景。 v-show：通过CSS的display属性控制显示，元素始终保留在DOM中，适用于频繁切换的场景（如选项卡）。 预约提醒功能怎么实现全局异常处理怎么做的通过切面（Aspect）拦截目标方法，在方法抛出异常时统一捕获并处理。 定义切面：创建一个切面类，负责全局异常处理。 @Aspect 注解，标记一个类为切面类，Spring 会识别并处理其中的切面逻辑。 声明切入点：明确需要拦截的目标方法（如所有 Controller 层方法）。 @Pointcut 注解，定义切入点表达式，指定哪些方法需要被拦截。 捕获异常：在目标方法抛出异常时，通过通知（Advice）拦截异常。 @AfterThrowing，在目标方法抛出异常时执行处理逻辑。 统一响应：将异常信息转换为标准格式（如 JSON）返回给客户端。 用户拉新和返佣怎么做的自测文档怎么写，什么流程什么样的编码习惯是良好的项目的难点在哪里05.09选择题 Java 基本数据类型的包装类 Byte, Short, Integer, Long, Float, Double, Character, Boolean Spring 用于开启自动配置的注解 @EnableAutoConfiguration 在 Spring MVC 中，处理请求参数的注解 A. @PathVariable （选项补充：若题目允许多选，@RequestParam 也应包含，但选项中未列出） MybatisPlus 用于逻辑删除的注解 @TableLogic Java 反射中获取构造方法的类 Constructor 关于 Java IO 流的正确说法 C. 字节流以字节为单位进行读写操作 ServerSocket 和 Socket 的正确描述 C. 多线程需确保每个 Socket 关闭 D. read() 返回特定值表示连接结束 线程协作中必须使用的关键字 B. synchronized 消息队列支持多消费者的模式 发布-订阅模式（Pub&#x2F;Sub） Redis 设置键值对过期时间的命令 EXPIRE 或 SET key value EX seconds 方法覆写的关键字 @Override Spring Boot 配置值注入方式 @Value 或 @ConfigurationProperties Spring MVC 返回 JSON 的注解 B. @RestController MybatisPlus 模糊查询方法 like() synchronized 的错误说法 D. 修饰静态方法时，锁的是当前对象实例 范围查询适合的索引 B. 普通索引 提升查询性能的正确做法 B. 确保 where 的过滤条件使用索引列 MyBatis RowBounds 分页的正确说法 B. 逻辑分页，内存中分页 Spring Cloud 熔断组件 Hystrix SQL 函数输出 -12, -12 Spring MVC 注册拦截器的配置类 实现 WebMvcConfigurer 并重写 addInterceptors 对象转为字节数据的操作 C. 序列化 wait() 和 sleep() 的正确说法 B. wait() 只能在同步块中使用 JOIN 的错误说法 D. FULL OUTER JOIN 只返回不匹配的记录 date 范围查询的索引 B. 普通索引 填空题 Java 基本数据类型有 8 种，分别是 byte, short, int, long, float, double, char, boolean 实现多线程的两种方法是 继承 Thread 类 和 实现 Runnable 接口 定义抽象类的关键字是 abstract class，定义接口的关键字是 interface 数组在 Java 中是 Object 类型，创建数组时需要指定数组的 长度 当一个对象被垃圾回收时，会调用该对象的 finalize() 方法 Spring Boot 的配置文件默认命名为 application.properties 和 application.yml Spring MVC 中处理表单提交的注解是 @PostMapping MyBatis Plus 中用于分页查询的插件是 PaginationInterceptor 反射中获取类所有方法的类是 Class Redis 有序集合的数据类型是 Sorted Set (ZSET) Spring Boot 自动配置数据源的类是 DataSourceAutoConfiguration MyBatis XML 文件通过 &lt;mapper&gt; 标签里的 namespace 属性映射 Dao 文件 启用定时任务的注解是 @EnableScheduling Spring MVC 处理文件上传的注解是 @RequestPart 数据库锁类型有 行级锁 和 表级锁 编程题 把一个文件内容复制到另一个文件中12345678910111213141516171819import java.io.*;public class FileCopy &#123; public static void main(String[] args) &#123; try ( BufferedReader reader = new BufferedReader(new FileReader(&quot;source.txt&quot;)); BufferedWriter writer = new BufferedWriter(new FileWriter(&quot;target.txt&quot;)) ) &#123; String line; while ((line = reader.readLine()) != null) &#123; writer.write(line); writer.newLine(); &#125; System.out.println(&quot;复制成功！&quot;); &#125; catch (IOException e) &#123; System.err.println(&quot;错误：&quot; + e.getMessage()); &#125; &#125;&#125; 05.1905.21权限校验如何实现服务间鉴权怎么实现XXL-JOB定时任务怎么实现的，频率配置写死还是配置中心MySQL 索引怎么维护 维护场景： 碎片化：频繁增删改导致索引页不连续，需重建。 统计信息过期：优化器选错执行计划，需 ANALYZE TABLE。 冗余索引：删除未使用或重复索引，减少写入开销。 隐式失效：类型转换、函数操作导致索引未命中。 维护步骤 检查使用率： 12-- 查看未使用索引 SELECT * FROM sys.schema_unused_indexes; 优化碎片： 1OPTIMIZE TABLE table_name; -- InnoDB 在线重建 更新统计信息： 1ANALYZE TABLE table_name; 清理冗余索引： 1ALTER TABLE table DROP INDEX idx_redundant; 最佳实践 时机：业务低峰期执行 OPTIMIZE。 监控：用 pt-duplicate-key-checker 查重复索引。 设计：避免频繁更新字段建索引，联合索引最左前缀。 Mybatis 分页怎么实现PageHelper 分页插件 配置分页123456789101112131415import com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor; import com.baomidou.mybatisplus.extension.plugins.inner.PaginationInnerInterceptor; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class MyBatisPlusConfig &#123; @Bean public MybatisPlusInterceptor mybatisPlusInterceptor() &#123; MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor(); // 分页插件 interceptor.addInnerInterceptor(new PaginationInnerInterceptor()); return interceptor; &#125; &#125; 使用示例123456789101112131415import com.baomidou.mybatisplus.core.metadata.IPage; import com.baomidou.mybatisplus.extension.plugins.pagination.Page; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; @Service public class UserService &#123; @Autowired private UserMapper userMapper; public IPage&lt;User&gt; getUsersByPage(int pageNum, int pageSize) &#123; Page&lt;User&gt; page = new Page&lt;&gt;(pageNum, pageSize); return userMapper.selectPage(page, null); // null 表示无查询条件 &#125; &#125; 05.22Springboot 为什么要用？哪些地方比较方便？ 快速启动，内嵌 Tomcat Starter 依赖，统一管理依赖和版本，避免版本冲突 无 XML 配置，使用注解和配置类约定配置 Springboot 的自动装配流程常用的 starter 有哪些依赖注入的流程Spring 的核心是什么配置类用什么注解@EnableAutoConfiguration 是复合注解，有哪些和自动加载配置有关的分页查询用的是什么Mybatis的mapper怎么和xml关联？方法和sql语句怎么关联？MySQL 的隔离级别Java 常用的锁有哪些多线程在你的项目中有哪些应用微服务常用组件熔断、降级做过吗Redis 保存对象的常用参数此处以 SET 方法为例： 原生 EX seconds：设置过期时间（秒） PX milliseconds：设置过期时间（毫秒） NX：仅当 Key 不存在时设置（类似 setIfAbsent） XX：仅当 Key 存在时设置（类似 setIfPresent） Java 封装（RedisTemplate） 设置键、值、过期时间、时间单位 1234567// 设置 key-value，并指定过期时间和单位（例如30秒）redisTemplate.opsForValue().set( &quot;user:1001&quot;, userObject, 30, TimeUnit.SECONDS); 05.23SQL 的优化场景，什么样的会去优化常用的 Linux 命令有哪些简单讲一下负载均衡通过把请求分散到多个服务器，避免单个服务器因为过载而性能下降，充分利用多台服务器资源。 当某台服务器出现故障时，可以把请求转发到其他正常服务器上，保证服务可用性。 方便添加新服务器，可以将请求自动分配过去。 对锁的了解多吗MySQL 索引失效场景有哪些 查询条件包含函数操作 使用 LIKE 开头 数据类型不同（隐式数据类型转换） 使用 OR 连接 联合索引不遵从最左前缀原则 Docker 用过吗，之前是怎么做运维的SpringBoot的核心特性是什么？ 快速构建项目 自动配置（web-starter 自动引入 Tomcat、SpringMVC），依赖管理方便（starter等） 内嵌 Tomcat 无需单独部署就可以使用 跨域的问题怎么解决？跨域通常是是前后端部署在不同的服务器和端口上，导致浏览器同源策略（相同的URI、主机名、端口）触发，从而阻止访问端口。 后端请求头中添加字段，标明请求来源（@CrossOrigin 注解，或者全局配置类实现） 反向代理，转发到 Nginx，从代理服务器转发给后端 微服务项目中，使用 GateWay 统一配置跨域规则 Vue的生命周期Uniapp打包过程中体积太大怎么解决？ 压缩图片、图片懒加载 去除无用依赖 开启压缩混淆 按需引入组件 消息队列有没有用过","tags":["面试题"],"categories":["面试"]},{"title":"Redis","path":"/posts/44296.html","content":"基本数据类型 字符串 String 列表 List 集合 Set 有序集合 SortedSet 哈希 Hash 高级数据类型 消息队列 Stream 地理空间 Geospatial HyperLogLog 位图 Birmap 位域 Birfie","tags":["Redis"],"categories":["Redis"]},{"title":"目录","path":"/posts/11250.html","content":"文件夹目录 databases 数据库 MySQL MySQL 常用.md MySQL实战（1）.md MySQL实战（2）.md MySQL实战（3）.md MySQL实战（4）.md MySQL实战（5）.md MySQL 优化实践.md MySQL 索引补充.md redis Redis.md devops 运维相关 Hexo搭建静态博客流程.md interview 面试相关 Java基础常见面试题.md Java集合常见面试题.md Spring常见面试题.md 中间件常见面试题总结.md 数据库常见面试题总结.md 场景题.md # 新增内容 methodology 方法论 如何使用 AI 帮助学习.md 自我使用说明书.md middleware 中间件 caching nacos nginx programming 编程 designpatterns 设计模式 Java常见设计模式.md java spring SpringBoot 中如何使用 Caffeine 本地缓存.md springcloud alibaba 敏捷开发流程.md 目录.md 生成目录树生成（到文件夹下执行）： 1tree /F &quot;D:\\personalProjects\\travellerBlog\\source\\_posts&quot; &gt; folder_tree.txt 网站Git学习 - learn git branching 在线文本对比"},{"title":"MySQL 优化实践","path":"/posts/63404.html","content":"定位 开启慢查询日志 通常是不开启的，如果不是调优需要的话，一般不建议设置该参数，会有一定性能影响。 下面是临时开启的方法，会在重启后生效。 永久开启需要在配置文件中设置（my.cnf 或 my.ini） 12345-- 查看是否开启慢查询日志（ON/OFF），查看日志保存地址SHOW VARIABLES LIKE &#x27;%slow_query_log%&#x27;;-- 手动开启SET GLOBAL slow_query_log = &#x27;ON&#x27;; 查询结果如下： Variable_name Value slow_query_log ON slow_query_log_file &#x2F;data&#x2F;mysql&#x2F;mysql3306&#x2F;data&#x2F;slow.log 设置阈值 查看时间阈值（单位：秒），超过该阈值时才会被记录（等于的时候不会） 12345-- 查看默认的阈值SHOW VARIABLES LIKE &#x27;long_query_time&#x27;;-- 手动设置阈值（表示执行时间超过2秒的SQL会被记录）SET GLOBAL long_query_time = 2 分析现在已经获取到了慢查询日志，可以使用内置或外置工具进行分析，获取，以下是一个示例： 1234# Time: 2024-04-24T14:20:30 # User@Host: user[admin] @ localhost [] # Query_time: 5.233210 Lock_time: 0.000154 Rows_sent: 1 Rows_examined: 100000 SELECT * FROM orders WHERE user_id = 123 AND status = &#x27;pending&#x27;; 需要关注的指标 Query_time：执行时间（超过阈值则为慢查询）。 Rows_examined：扫描的行数（高值可能因缺少索引导致全表扫描）。 Rows_sent：返回的行数（若远小于扫描行数，可能需优化WHERE条件）。 使用工具进行筛选排序 MySQL 有自带的日志分析工具：mysqldumpslow，可以在 Linux 中输入命令获取参数：mysqldumpslow --help，示例： 123456 # 按执行时间排序，显示前10条最慢查询mysqldumpslow -s t -t 10 /path/mysql-slow.log # 输出内容如下Count: 10 Time=5.23s (52.3s) Lock=0.00s (0.0s) Rows=1 (10)SELECT * FROM orders WHERE user_id = ? AND status = ? 使用 EXPLAIN 进行详细分析 1EXPLAIN SELECT * FROM orders WHERE user_id = 123 AND status = &#x27;pending&#x27;; 输出结果为： id select_type table type possible_keys key rows Extra 1 SIMPLE orders ALL NULL NULL 100000 Using where 可以看到 type 结果是 ALL、key 结果是 NULL，并且数据行 rows 是 100000。 说明此时是全表扫描且没有走索引，且数据量很大，可以根据查询条件创建索引进行优化。 慢的原因分析和优化并发量太大原因： 锁竞争和阻塞，高并发写入时，行锁升级为表锁 长事物占用锁资源，导致其他事物排队等待 链接数超过数据库最大限制，新链接被拒绝或等待 优化方法： 优化索引避免锁升级 减少长事物的使用 使用链接池控制 索引没有使用或使用不当根据业务设计索引，要注意数量不要过多： 写入时需要同步更新索引提高，磁盘 I&#x2F;O 开销 占用存储空间 查询优化复杂度上升（优化器需要在大量索引中评估，可能会抛出异常） 碎片化严重的索引需要定期重建，增加运维负担 原因： MySQL 索引补充 - 索引失效的情况 优化方案： MySQL 索引补充 - 如何创建高性能的索引 SQL语句书写不当原因： 使用SELECT *导致返回过多字段 子查询、临时表或关联表过多（如多表JOIN） 未使用绑定变量（导致SQL无法命中缓存计划） 优化方案： 精简查询字段，仅查询必要字段，避免SELECT *。 优化复杂查询，将多表JOIN拆分为多次查询，或通过子查询优化逻辑。 使用绑定变量，避免SQL注入的同时，让数据库缓存执行计划，减少解析时间。 避免函数操作字段，确保查询条件字段不被函数包裹（如 WHERE YEAR(create_time) = 2023 会导致索引失效）。 表结构设计不当原因： 表字段过多 设计不规范导致数据冗余 优化方法： 垂直分表：将大字段（BLOB、TEXT）拆分到独立表中 规范化设计：合理拆分冗余字段，单表字段不要过多 针对高频查询场景，可以添加冗余字段，减少 JOIN 操作 尽量把列设置为 NOT NULL 不要用字符串存储日期，使用 DATETIME 等 业务设计不合理原因： 需求不合理导致实现困难，复杂度高（例如：频繁查询高并发的热点数据，排行榜等） 优化方法： 业务分层，或者增加缓存中间件，减少数据库访问 数据库服务器实例性能配置差(提升服务器性能配置)深分页问题示例表123456CREATE TABLE t_user ( id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY, name VARCHAR(255) NOT NULL, gmt_create DATETIME NOT NULL, INDEX idx_time (gmt_create) -- 为 gmt_create 字段创建索引)ENGINE=InnoDB 假设有以下的查询语句： 12-- 查询第300000条记录起的10条记录SELECT * FROM t_user ORDER BY gmt_create LIMIT 300000, 10; 使用 EXPLAIN 后会发现走的是全表扫描： id select_type table type key rows 1 SIMPLE t_user ALL 904000 原因在于 LIMIT offset, count 分页查询步骤： 需要扫描 offset + count 行数据 然后丢弃掉前 offset 行 即使有索引，也会遍历索引节点，然后再回表查询 解决方案1，延迟关联适用场景：需要随机跳页（如直接跳转到第1000页）不适用场景：超大数据量（如 offset &gt; 1亿） 1234567SELECT t1.* FROM t_user AS t1, (SELECT id FROM t_user ORDER BY gmt_create LIMIT 300000, 10) AS t2 WHERE t1.id = t2.id; 使用子查询查询到主键 id，再用主键查询避免回表操作 解决方案2，游标查询适用场景：连续翻页（如无限滚动、实时数据流）不适用场景：需要跳转到任意页 12345SELECT * FROM t_user WHERE gmt_create &gt; &#123;last_gmt_create&#125; -- 或结合 id 避免重复ORDER BY gmt_create LIMIT 10; 基于 gmt_create 字段作为游标（前提是保证该字段唯一性），每次分页时，记录最后一行的 gmt_create 和 id，作为下一次查询的起点","tags":["MySQL"],"categories":["MySQL"]},{"title":"如何使用 DeepSeek 帮助学习","path":"/posts/51861.html","content":"如何使用 DeepSeek 帮助学习为什么不直接问？比如：直接问 RabbitMQ 是什么？为什么要用？怎样和 Spring Boot 使用？ 这种问题得到的都是碎片化的知识，普通人确实将其“拼凑”成完整知识体系的能力。 推荐找一本讲 RabbitMQ 的书，重点看前几章的基础知识部分（最好找一些系统全面的、面向初学者的）。 在大脑中构建起基础的知识框架，了解关键词、术语、工作原理等。 没有必要把书读完，通常在成书的一刻，除基础框架和原理外，其他部分已经落后了。 Hello World使用 DeepSeek 写一个最简单的 Hello World 示例代码（需要添加注释）。 有了基础的知识框架和认知后，再加上注释，看懂这些代码并不难。 一定要自己从头敲一遍并运行，这一步是必须的。 如果中间有什么问题，比如：编译报错、运行不起来等，可以再询问 DeepSeek 找出原因。 全局理解可以和平时使用的框架结合起来问问题，比如：怎样和 Spring Boot 集成？需要哪些组件？职责是什么？怎样配合？ 需要你仔细阅读 DeepSeek 给出的解释，并且再根据这些去手敲一遍代码。可以根据这些信息阅读源码，加深理解。 如何加深理解这一步因人而异，向小黄鸭口述一遍你的理解、形成文章等。也可以手绘类图，了解组件之间的关系、依赖等，从而理解职责。学任何开发框架，明白它所提供的“编程模型”（即各个组件职责以及它们之间的协作方式），都是学习的关键环节。 针对场景实战向 DeepSeek 要实例，比如： 如何构建一个 Fanout 类型的 Exchange 实现消息的“广播” 如何将两个 Exchange 串联起来 如何捕获并处理运行过程中出现的异常等 将这些场景的解决方法整理、保存，构建个人代码仓库。 这一步就是总结特定环境下的编程模式，实际开发中随处可见这些“固定模式”的反复组合应用。 总结通过上面这些流程，就已经可以进行实际开发工作了，如果是第一次接触，通常会有一些小问题没有完善，可以多迭代几次。 个人觉得吧，传统的“看书学习”方式，后来的“看视频学习”方式，学习效率都还是低了一点，如果引入DeepSeek之类的AI助手，多种方式一起上，学习效率会有较大的提高。 高效学习帕累托法则（80&#x2F;20法则）：少数关键因素（约20%）往往导致大部分结果（约80%）。 用一些具体的问题来提升学校效率，深入理解核心概念，比如一些关键问题： 这是什么？ 这有什么重要的？ 学这个有什么用？ 什么时候用的上？ 这怎么用？ 问题的关键在于：是什么？为什么？什么时候？怎么用？ 举例：面向对象编程（OOP）什么是OOP？为什么OOP很重要？为什么要学OOP？什么场景能用上OOP？OOP是怎样使用的？ 将信息转化为问题 真正理解一件事，就是能把他简单化 项目驱动学习： 复现教程代码 花更多时间做实际项目，边做边学，而不是一直看教程 多使用图标进行思考、设计（UML类图、数据库模式、架构图等） 其他技巧： 主动回想，反复练习 间隔复习，在每次学习中留出时间进行复习，并且逐渐拉长间隔的出现时间（遗忘曲线） AI帮助： 解释概念，检验我的理解，反过来解释 帮忙生成练习题 和自己的回答、笔记进行对比，发现在理解上的不足 帮助简化，更容易理解 帮助理解解题思路和背后的解题模式（Leetcode）","tags":["个人成长"],"categories":["其他"]},{"title":"【面试相关】中间件","path":"/posts/44612.html","content":"NginxRedis后端开发除了增删改查还有什么？ - 大宽宽的回答 - 知乎https://www.zhihu.com/question/264370798/answer/3011389456 这是100万字面试宝典：https://www.yuque.com/tulingzhouyu/db22bv 密码：ztts CRUD项目怎么优化以及面试回答Java项目亮点与难点如何写 技术架构亮点 3年以内 技术是重点，例如： 高并发订单处理 高并发订单处理(技术亮点 1-3年) 采用多级缓存(本地缓存+Redis集群)架构，将热点产品信息查询延迟控制在10ms以内 设计了分布式锁+消息队列的架构，实现订单峰值1000+TPS的稳定处理 使用分库分表技术，解决了亿级订单数据存储问题(视情况写) 业务架构亮点 3年以上 业务是重点，例如： 【重点 宠一生：佣金计算规则引擎】 佣金分销系统 复杂佣金计算系统(业务点 3-5年) 设计了灵活的多级分销佣金计算规则引擎，支持20+种佣金计算规则 采用责任链+策略模式处理不同产品类型的佣金计算逻辑 实现佣金计算的实时预览功能，提升用户体验 性能瓶颈优化难点 3年以内问性能优化 PS:关于数据库优化的更多细节可以参考直播课《阿里巴巴内部Mysql性能优化最佳实践》 系统性能优化(性能优化) 结合业务场景优化复杂SQL，将30秒级查询优化到1秒内【宠一生】，例如： 这是一个代理人业绩计算场景的性能优化案例。原来计算sql需要30秒，我们通过以下步骤将其优化到1秒内。 sql优化 实现读写分离，利用多级缓存减少数据库访问压力 通过异步处理+任务队列，提升系统整体吞吐量 线上疑难问题解决经验 3年以上问 线上解决方案 有没有都行 服务器部署架构与监控 全程贯穿数据指标说明 一定要有","tags":["面试","Nginx","Redis","中间件"],"categories":["面试"]},{"title":"【面试相关】Spring","path":"/posts/33833.html","content":"BeanBean 注入流程 扫描阶段 通过 @ComponentScan 扫描标注 @Component、@Service、@Repository、@Controller 的类。 通过 @SpringBootApplication 自动触发扫描。 注册阶段 将扫描到的类或通过 @Bean 定义的对象注册到 Spring 容器（BeanDefinition）。 处理 @Import、@Conditional 等注解。 实例化阶段 根据 BeanDefinition 实例化对象（调用构造函数）。 属性注入阶段 通过反射注入依赖项（@Autowired、@Resource 等）。 初始化阶段 调用 @PostConstruct 方法或 InitializingBean.afterPropertiesSet()。 使用阶段 从容器中获取 Bean 并使用。 销毁阶段 调用 @PreDestroy 方法或 DisposableBean.destroy()。 注入方法如果一个接口有多个实现类，则只能用以下这些方式进行注入： 使用 @Qualifier 指定注入的类名称 使用 @Primary 标注一个类，注入时默认使用该类 使用 List&lt;&gt; 或者 Map 遍历接口，获取全部实现类 使用 @Conditional 根据配置条件进行注入，需要手动额外配置 三、第三方对象的引入方法1. @Bean 显式注册（推荐）1234567@Configurationpublic class ThirdPartyConfig &#123; @Bean public OkHttpClient okHttpClient() &#123; return new OkHttpClient.Builder().build(); &#125;&#125; 场景： 需要配置参数（如连接池、超时时间）。 需要绑定外部配置（@Value、@ConfigurationProperties）。 2. @Import 导入（简单对象）123@Import(ThirdPartyClient.class) // 直接导入类@Configurationpublic class AppConfig &#123;&#125; 场景： 第三方类有无参构造函数且无需配置。 3. 动态注册（BeanDefinitionRegistry）123456public class CustomRegistrar implements BeanDefinitionRegistryPostProcessor &#123; @Override public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) &#123; registry.registerBeanDefinition(&quot;customBean&quot;, BeanDefinitionBuilder.rootBeanDefinition(CustomBean.class).getBeanDefinition()); &#125;&#125; 场景： 需要根据条件动态注册 Bean。 扩展 Spring 的自动配置（如插件化系统）。 4. XML 配置（遗留系统兼容）12&lt;!-- beans.xml --&gt;&lt;bean id=&quot;thirdPartyBean&quot; class=&quot;com.example.ThirdPartyBean&quot;/&gt; 123@ImportResource(&quot;classpath:beans.xml&quot;)@SpringBootApplicationpublic class Application &#123;&#125; 场景： 迁移遗留项目时兼容旧 XML 配置。 四、补充关键问题1. Bean 作用域控制12345@Bean@Scope(&quot;prototype&quot;) // 每次请求创建新实例public MyBean myBean() &#123; return new MyBean();&#125; 场景： 需要多例（非单例）对象时。 2. 条件化注入（@Conditional）12345@Bean@ConditionalOnProperty(name = &quot;feature.enabled&quot;, havingValue = &quot;true&quot;)public FeatureBean featureBean() &#123; return new FeatureBean();&#125; 场景： 根据配置文件或环境动态启用&#x2F;禁用 Bean。 3. 生命周期管理1234@Bean(initMethod = &quot;init&quot;, destroyMethod = &quot;close&quot;)public ConnectionPool connectionPool() &#123; return new ConnectionPool();&#125; 场景： 需要显式控制初始化&#x2F;销毁逻辑（如数据库连接池）。 4. 避免循环依赖123456789// 通过构造器注入 + @Lazy@Servicepublic class ServiceA &#123; private final ServiceB serviceB; public ServiceA(@Lazy ServiceB serviceB) &#123; this.serviceB = serviceB; &#125;&#125; 场景： 解决 A 依赖 B、B 依赖 A 的循环问题。 5. Spring Boot 3 的 Jakarta EE 9 适配123// 包名从 javax.* 改为 jakarta.*import jakarta.annotation.Resource;import jakarta.persistence.Entity; 场景： 升级到 Spring Boot 3 时需处理包名冲突。 五、总结 核心原则：第三方对象必须通过 @Bean 或 @Import 显式注册。 最佳实践：优先使用构造器注入，避免字段注入。 扩展能力：结合 @Conditional 和 @ConfigurationProperties 实现灵活配置。 一、Spring核心机制Spring框架的核心实现原理与关键特性，包括IOC、AOP、Bean生命周期及设计模式应用。 1.SpringIOC的理解，原理与实现？ 2.springIOC的底层实现？ 3.描述一下bean的生命周期？ 4.Spring是如何解决循环依赖的问题的 5.缓存的放置时间和删除时间 6.BeanFactory与FactoryBean有什么区别 7.Spring中用到的设计模式 8.Spring的AOP的底层实现原理 9.Spring的事务是如何回滚的？ 10.谈一下spring事务传播？ 57.谈谈你对Spring的理解 58.谈谈你对IoC的理解 59.Spring中如何解决循环依赖问题的 60.谈谈你对IoC的理解 二、Java基础与集合Java核心语法、集合框架优化及多线程并发控制机制。 11.equals()和==区别，为什么重写equal要重写hashcode 12.hashmap在1.8中做了那些优化 13.hashmap线程安全的方式 14.为什么hashmap扩容的时候是两倍 15.解决hash冲突的方式有哪些 16.hashmap为什么用红黑树不用普通的AVL树 19.说一下反射，反射会影响性能吗 20.sleep与wait区别 21.synchronized和ReentrantLock的区别 22.Condition类和Object类锁方法区别 23.tryLock和Lock和lockInterruptibly的区别 24.单例模式的几种实现方式 三、Redis与缓存策略Redis核心机制、缓存问题解决方案及分布式场景应用。 25.说一下在你项目中的redis的应用场景 26.redis是单线程还是多线程 27.redis存在线程安全的问题么 28.遇到过缓存穿透么 29.遇到过缓存击穿么 30.如何避免缓存雪崩 31.缓存课后解答 32.redis是怎么删除过期key的(缓存时如何回收的) 33.缓存是如何淘汰的 34.如何进行缓存预热 35.数据库与缓存不一致如何解决 36.简述一下主从不一致的问题 37.描述一下redis持久化的方式 41.为什么使用setnx(redis实现分布式锁的指令) 122.Redis合适的应用场景？ 123.Redis6.0之前为什么一直不使用多线程？ 124.Redis6.0为什么要引入多线程？ 125.Redis有哪些高级功能？ 126.为什么要用Redis？ 127.Redis与memcached相对有哪些优势？ 128.Redis的过期策略以及内存淘汰机制？ 129.什么是缓存穿透？如何避免？ 130.什么是缓存雪崩？如何避免？ 131.使用Redis如何设计分布式锁？ 132.怎么使用Redis实现消息队列？ 133.Redis如何解决key冲突？ 134.怎么提高缓存命中率？ 135.Redis持久化方式有哪些？有什么区别？ 136.为什么Redis需要把所有数据放到内存中？ 137.如何保证缓存与数据库双写时的数据一致性 138.Redis集群方案什么情况下会导致整个集群不可用？ 139.说一说Redis哈希槽的概念？ 140.Redis集群会有写操作丢失吗？为什么？ 141.Redis常见性能问题和解决方案有哪些？ 142.热点数据和冷数据是什么 143.什么时候选择Redis，什么时候选择Memcached？ 143.Redis过期策略都有哪些？LRU算法知道吗？ 四、消息队列与分布式事务消息队列核心机制、分布式事务实现及高可用设计。 144.为什么要使用消息队列？ 145.消息队列有什么优点和缺点 146.常见消息队列的比较 147.RabbitMQ中的vhost起什么作用？ 148.RabbitMQ上的一个queue中存放的message是否有数量限制？ 149.说一说Kafka你熟悉的参数？ 150.kafka中，可以不用zookeeper么？ 151.说一说RabbitMQ中的AMQP 152.kafka适合哪些场景？ 153.RabbitMQ中交换器4种类型？ 154.为什么Kafka不支持读写分离？ 155.Kafka中是怎么做到消息顺序性的？ 156.Kafka为什么那么快？ 157.Rocketmq如何保证高可用性？ 158.RocketMq的存储机制了解吗？ 159.RocketMq性能比较高的原因？ 160.让你来设计一个消息队列，你会怎么设计？ 161.有几百万消息持续积压几小时，说说怎么解决？ 162.Rocketmq中Broker的刷盘策略有哪些？ 163.什么是路由注册？RocketMQ如何进行路由注册？ 164.什么是路由发现？RocketMQ如何进行路由发现？ 165.什么是路由剔除？RocketMQ如何进行路由剔除？ 166.使用RocketMQ过程中遇到过什么问题？ 167.讲一讲RocketMQ中的分布式事务及实现 168.讲一讲RocketMQ中事务回查机制的实现 169.分布式幂等性如何设计 170.说说那你对分布式事务的理解 171.什么是两阶段提交协议 172.什么是补偿性事务 173.消息队列和事件表实现分布式事务 181.什么是可靠消息最终一致性方案 182.RocketMQ在分布式事务中的应用 五、SpringBootSpringBoot自动装配原理、核心注解、配置管理及启动流程。 61.谈谈你对SpringBoot自动装配原理的理解 92.@ComponentScan注解是干什么的？ 93.@EnableAutoConfiguration注解是干什么的？ 94.bootstrap.yml的意义 95.Import注解的三种用法 96.RequestMapping和GetMapping的不同之处在哪里？ 97.SpringBoot的核心注解是哪个？它主要由哪几个注解组成的？ 98.SpringBoot可以兼容老Spring项目吗，如何做？ 99.SpringBoot如何定义多套不同环境配置？ 100.SpringBoot需要独立的容器运行吗？ 101.SpringBoot有哪几种读取配置的方式 102.SpringBoot支持哪些日志框架？推荐和默认的日志框架是哪个？ 103.SpringBoot、SpringMVC和Spring有什么区别？ 104.SpringBoot中的监视器是什么呢 105.SpringBoot打成的jar和普通jar有什么区别 106.SpringBoot的run方法做了什么事情 107.SpringBoot的优点 108.SpringBoot如何解决跨域问题 109.SpringBoot中如何配置log4j 110.SpringBoot中如何实现定时任务 111.SpringBoot自动装配的核心配置文件有哪些？ 112.SpringBoot自动装配的流程是怎样的？ 113.介绍几个常用的starter 114.你如何理解SpringBoot配置加载顺序？ 115.如何实现SpringBoot应用程序的安全性 116.如何在SpringBoot启动的时候运行一些特定的代码？ 117.如何重新加载SpringBoot上的更改，而无需重新启动服务器？ 118.什么是SpringBootStarter？ 119.什么是SpringBoot 120.我们如何连接一个像MySQL或者Orcale一样的外部数据库？ 121.运行SpringBoot项目的方式 六、微服务与分布式组件微服务架构中的注册中心、配置中心、负载均衡、熔断限流及分布式事务实现。 62.如何设计一个注册中心？ 63.Nacos1.x作为注册中心的原理？ 64.Nacos服务领域模型有哪些？ 65.Nacos中的Distro协议 66.配置中心的技术选型 67.Nacos1.x配置中心长轮询机制？ 68.Nacos配置中心配置优先级？ 69.Nacos2.x客户端探活机制？ 70.Ribbon底层怎样实现不同服务的不同配置 71.为什么Feign第一次调用耗时很长？ 72.Ribbon的属性配置和类配置优先级 73.Feign的性能优化？ 74.Feign怎样实现认证的传递？ 75.谈谈Sentienl中使用的限流算法 76.谈谈Sentienl服务熔断过程 77.在Gateway中怎样实现服务平滑迁移？ 78.Seata支持那些事务模式？ 79.请简述2PC流程以及优缺点 80.Seata中xid怎样通过Feign进行全局传递 81.分布式事务应用的典型场景 82.请说一下CAP和BASE理论 83.简述Seata的AT模式两阶段过程 84.简述Eureka自我保护机制 85.简述Eureka集群架构 86.从Eureka迁移到Nacos的解决方案 87.Apollo的整体架构 88.Apollo的整体架构可靠性分析 89.Apollo配置发布后的实时推送设计 90.Apollo客户端设计 91.Zuul有几种过滤器类型，分别是什么 七、分布式系统与算法分布式系统核心理论、一致性算法及负载均衡策略。 174.分布式id的生成方案有哪些 175.常用的负载均衡算法有哪些 176.什么是滑动时间窗口算法 177.什么是漏桶算法 178.什么是令牌桶算法 179.数据库如何处理大数据量 180.什么是CAP定理 八、Elasticsearch与搜索优化Elasticsearch核心机制、写入原理及性能调优。 183.Elasticsearch前言 184.倒排索引深入骨髓 185.Elasticsearch的写入原理 186.读写性能调优一 187.读写性能调优二 188.ES的节点类型 189.搜索引擎和ES 九、MySQL与持久层框架MySQL优化策略、MyBatis实现原理及事务控制。 46.为什么MySQL选择B+树作为索引？ 47.MySQL的优化可以从哪些方面考虑？ 48.什么是慢查询，如何避免？ 49.什么是执行计划？如何理解？ 50.如何优化MySQL的表结构？ 51.MySQL如何避免死锁？ 52.如何优化大量数据插入的性能？ 53.大数据量的批量写会导致什么问题？ 54.MyBatis的自动过程 55.MyBatis中的缓存设计 56.MyBatis中的SqlSession数据安全问题如何解决","tags":["面试","Spring"],"categories":["面试"]},{"title":"常见设计模式","path":"/posts/12977.html","content":"策略模式定义一组算法，将每个算法都封装起来，并且使他们之间可以互换。策略模式让算法独立于它的使用者而变化。","tags":["设计模式"],"categories":["Program"]},{"title":"【面试相关】MySQL","path":"/posts/36556.html","content":"一、索引机制与B+树001.MySQL如何实现的索引机制InnoDBt 引擎中使用 B+树 作为数据结构实现，是多路平衡搜索树，叶子结点间形成有序列表，适合范围查询。非叶子节点只存键值，叶子结点存储完整数据。且树的高度较低，减少磁盘 I&#x2F;O 次数，提高查询效率。 004.说一下B+树索引实现原理（数据结构）是一种多路搜索树，每个节点包含多个键和子节点，且按照键的顺序存储。聚簇索引，根和中间节点存储的是索引键和指向子节点的指针，叶子节点存储的是该键的完整行数据；非聚簇索引，根和中间节点存储的是索引键和指向子节点的指针，叶子节点存储的是该键对应的主键值，叶子节点间，使用指针形成双向链表 005.聚簇索引与非聚簇索引B+树实现有什么区别？ 聚簇索引数据和索引存储在同一颗B+树上页内、页和页之间，在物理存储上按照主键有序排列叶子节点保存该行的完整数据减少磁盘 I&#x2F;O，插入速度受插入顺序影响 非聚簇索引数据和索引分开存储只针对索引进行有序排列，不考虑物理存储顺序非叶子节点保存索引列的值和主键值，通过主键值回表查询快速定位聚簇索引需要回表操作，查询性能受影响 006.说一下B+树中聚簇索引的查找（匹配）逻辑 从根节点出发，按主键值二分查找确定下一层节点 重复比较过程，直到叶子结点 叶子结点遍历链表或直接定位到目标数据 007.说一下B+树中非聚簇索引的查找（匹配）逻辑 查询非聚簇的B+树，查询到主键值 通过主键值返回聚簇索引的B+树，获取完整数据（如果查询字段也在索引中，则不需要回表） 008.平衡二叉树，红黑树，B树和B+树的区别是什么？都有哪些应用场景？009.一个B+树中大概能存放多少条索引记录？010.使用B+树存储的索引crud执行效率如何？ 查询：时间复杂度 $\\mathcal{O}(\\log n)$，高效 插入&#x2F;删除：可能因为节点分裂、合并等有额外开销，总体高效 修改：相当于插入 + 删除，效率较高 012.什么是2-3树2-3-4树？ 2-3树 ：节点可存1或2个键，有2或3个子节点。 2-3-4树 ：节点可存3或4个键，有4个子节点。 017.如果是大段文本内容，如何创建（优化）索引？使用全文索引。会将文字拆分为一个个关键词，完成后会构建倒排索引（把每个关键词和包含该关键词的记录关联起来） 023.什么是回表操作？通过非聚簇索引查到主键后，二次查询聚簇索引获取完整数据行的过程。 024.什么是覆盖索引？通过索引完全满足查询的所有需求，避免回表操作。 025.非聚集索引一定回表查询吗不一定，如果查询结果只是主键值的话，就不会触发回表。 026.为什么要回表查询？直接存储数据不可以吗？ 多个索引重复存储数据浪费空间 如果有更新或者修改当操作，数据只在聚簇索引树中执行一次 028.什么是复合索引（也叫联合索引、组合索引）？使用多个字段组合，创建的索引。使用时需要注意： 最左前缀原则：查询条件中需要包含最左侧的字段 应该将使用频率高的字段放到左边，更有效地过滤数据 029.复合索引创建时字段顺序不一样使用效果一样吗？必须满足最左前缀原则 034.什么是索引下推？非聚簇索引的叶子结点遍历时，直接过滤掉不符合要求的记录，避免不必要的回表 035.有哪些情况会导致索引失效？ 使用 LIKE 左模糊、或全模糊查询（’%a’、’%a%’) 不满足最左前缀要求 对索引字段使用了函数或者表达式 范围查询 数据类型不匹配时，会出发隐式类型转换（123，’123’) OR 链接多个索引字段（可以使用 union 优化） 使用：NOT IN、!=会全表扫描（使用UNION、BETWEEN、IN 代替）； IS NOT NULL会对 NULL 值进行判断，使用非空代替 036.为什么LIKE以%开头索引会失效？需要注意的是，LIKE &#39;%a%&#39; 全模糊查询也会导致索引失效。索引是按照前缀排序的，无法进行反向搜索。 二、聚簇索引与非聚簇索引002.InnoDB索引与MyISAM索引实现的区别是什么？018.什么是聚簇索引？聚簇索引是InnoDB的主索引，数据与索引存储在同一个B+树中，叶子节点直接包含完整数据行。 页内数据按主键值顺序存储，页之间通过双向链表链接。 每张表只能有一个聚簇索引（主键默认）。若无显式主键，InnoDB会自动生成 ROWID 作为聚簇索引。 查询高效；插入&#x2F;删除可能导致页分裂或合并；更新主键需要移动数据，开销较大。 019.一个表中可以有多个（非）聚簇索引吗？聚簇索引只能有一个。非聚簇索引可以有多个（普通索引、唯一索引）。 020.聚簇索引与非聚簇索引的特点是什么？聚簇索引： 只能有一个 叶子节点存储完整数据 按照主键顺序存储 查询时不会触发回表操作，直接获取查询值 范围查询高效 插入速度依赖于主键排序 非聚簇索引： 可以有多个 叶子节点存储聚簇索引的索引值 按照索引值排列 查询时会触发回表，需要再次使用聚簇索引获取完整的查询数据 维护成本高（数据修改时需要更新所有相关索引） 适合频繁查询非主键字段的场景 021.CRUD时聚簇索引与非聚簇索引的区别是什么？聚簇索引： 增：按照主键顺序插入，可能导致页分裂 删：直接从叶子节点中取出，可能导致页合并 查：直接通过 B+树查找数据，无需回表 改：需要移动数据，同时更新所有非聚簇索引，开销较大 非聚簇索引： 增：需要维护所有非聚簇索引的 B+树，比如新增字段值和主键关联关系 删：删除非聚簇索引树的主键记录 查：先查询主键值后再回表查询数据 改：只维护该索引的 B+树 022.非聚簇索引为什么不存数据地址值而存储主键？ 通过主键关联，保证数据和索引的一致性 主键值是固定的，数据地址可能会因为页分裂、合并导致变更 主键值更加节省存储空间 三、主键与自增013.说一下自增主键和字符串类型主键的区别和影响自增主键 使用 int&#x2F;bigint 作为数据结构，占用空间比 varchar 少 自动有序递增，无序手动维护 查询速度快，无序逐个字符比对 分布式场景可能会出现主键冲突 没有业务意义 字符串主键 varchar 占用空间多 需要手动维护 需要逐个字符进行比对，速度慢 分布式场景友好，全局唯一 如果是订单号等数据，可能会暴露业务信息 014.使用int自增主键后最大id是10，删除id10和9，再添加一条记录，最后添加的id是几？11。自增主键计数器不会被重置，如果继续添加会在此基础上进行自增。 027.如果把一个InnoDB表的主键删掉，是不是就没有主键，就没办法进行回表查询了？如果没有显示指定的主键，首先选择第一个唯一且不为空的列作为主键，如果没有，则使用隐藏的 row_id 代替主键。 四、索引优化与使用场景015.索引的优缺点是什么？优点： 查询速度提升 减少全表扫描的资源损耗 排序高效，B+树 天然有序 缺点： 占用额外空间 新增操作变慢，插入&#x2F;删除需要额外维护索引树 当数据量较少时，全表扫描可能更快 016.使用索引一定能提升效率吗？不一定。当数据量较少时，直接全表扫描效率更高。索引失效时效率较慢（不满足最左前缀，索引列重复值过多） 030.什么是唯一索引？索引列的值唯一且非空（只允许一个 NULL 值，除非明确禁止非空） 031.唯一索引是否影响性能？插入&#x2F;更新时需要检查唯一性，会影响性能。查询时由于已知该字段值是唯一的，速度更快。存储空间上需要有唯一性数据，比普通索引更大。 032.什么时候使用唯一索引？该数据列值不允许重复，比如用户的账号、订单号等 033.什么时候适合创建索引，什么时候不适合创建索引？适合： 频繁查询的列 唯一值较多 表连接的列（JOIN） 不适合： 数据较少的表 频繁更新的列 值较为单一（例如：性别列） 037.一个表有多个索引的时候，能否手动选择使用哪个索引？可以，使用 FORCE INDEX 或者 USE INDEX，例如：SELET * FROM table USE INDEX(user_name) WHERE ... 040.多个索引优先级是如何匹配的？ 根据区分程度进行选择（不同值数量 ÷ 总行数） 是否满足最左前缀 覆盖索引优先于普通索引（不需要回表） 根据类型选择：B+树适合范围查询，哈希索引适合等值查询 表的数据量大小，小的话全表扫描 045.如果表中有字段为null，又被经常查询该不该给这个字段创建索引？可以根据查询的情况判断：作为复合索引的一部分，将该字段放到第二个位置；如果 NULL 占比较低，可以创建，较高的话索引效果不明显； 046.有字段为null索引是否会失效？不一定。索引失效的情况： 唯一索引：有多个 NULL，因为唯一性失效 普通索引、等值索引：使用 WHERE a = NULL 会失效（需要使用 WHERE a IS NULL） 五、存储引擎与表结构003.一个表中如果没有创建索引，那么还会创建B+树吗？在 InnoDB 引擎中是有的，如果没有显式创建索引，会有下面两种情况创建 聚簇索引： 使用第一个唯一非空列作为聚簇索引 会使用默认的 row_id。 050.MySQL内部有哪些核心模块组成，作用是什么？054.MySQL支持哪些存储引擎？默认使用哪个？055.MySQL8.0自带哪些存储引擎？分别是做什么的？056.MySQL存储引擎架构了解吗？057.能否单独为一张表设置存储引擎？059.MyISAM和InnoDB的区别是什么？060.具体说一下如何做技术选型149.MySQL线上修改表结构有哪些风险六、事务与隔离级别061.什么是数据库事务？事务的特性是什么？062.什么是ACID？063.并发事务会有哪些问题？064-068.并发事务会有哪些问题？脏读丢失修改不可重复读幻读069-073.MySQL是如何避免事物并发问题的？074.MySQL事务隔离是如何实现的？075.什么是一致性非锁定读和锁定读？076.说一下MVCC内部细节077-078.MySQL事务一致性，原子性，持久性是如何实现的？七、锁机制表锁与行锁的区别、死锁处理及SELECTFORUPDATE的作用。 079-085.表级锁和行级锁相关面试题？090.是否使用过select for update？会产生哪些操作？091.说一下MySQL死锁的原因和处理方法八、日志机制日志类型（undo&#x2F;redo&#x2F;binlog）、刷盘机制及数据恢复原理。 092.MySQL会产生几种日志？093-095.undologredologbinlog的作用是什么？096-097.MySQL日志是否实时写入磁盘？binlog刷盘机制是如何实现的098-099.redolog，undolog刷盘机制是如何实现的？数据脏页100.MySQL的binlog有几种录入格式？分别有什么区别？101.MySQL集群同步时为什么使用binlog？优缺点是什么？九、查询优化与执行查询执行流程、排序&#x2F;分组优化、慢SQL分析及分页处理。 041.使用OrderBy时能否通过索引排序？042.通过索引排序内部流程是什么？043.什么是双路排序和单路排序044.groupby分组和orderby在索引使用上有什么区别？047.MySQL内部支持缓存查询吗？048.MySQL8为何废弃掉查询缓存？049.替代方案是什么？051.说一下MySQL执行一条查询语句的内部执行过程？052.MySQL提示“不存在此列”是执行到哪个节点报出的？053.如果一张表创建了多个索引，在哪个阶段或模块进行的索引选择？121-125.join多表关联与优化相关面试题126-127.是否有过MySQL调优经验？用过哪些调优工具128-129.如何监控线上环境中执行比较慢的sql？如何分析一条慢sql？130-132.如何查看当前sql使用了哪个索引？EXPLAIN关键字中的重要指标有哪些？133.MySQL数据库cpu飙升的话你会如何分析147.如果有超大分页改怎么处理？146.count(列名)和count(星号)有什么区别十、数据类型与存储数据类型选型（如IP、日期、文本）、存储优化及精度问题。 102-105.文件存储emoji相关面试题106.如何存储ip地址？107-110.长文本如何存储如何设计表结构如何建立索引？等111-114.日期，时间如何存取TIMESTAMP，DATETIME的区别为什么不使用字符串存储日期时间戳timestamp和int该如何选择？115.char与varchar的区别？如何选择？116.财务计算有没有出现过错乱？117-118.decimal与float,double的区别是什么？如何选型？十一、分库分表与高可用分库分表场景、工具实现思路及读写分离方案。 134-136.什么是分库分表？什么时候进行分库分表？有没有配合es使用经验？137-140.说一下实现分库分表工具的实现思路及读写分离方案十二、其他高级特性高级功能如预编译SQL、XA事务、自研存储引擎及进程管理。 011.什么是自适应哈希索引？038.如何查看一个表的索引？039.能否查看到索引选择的逻辑？是否使用过optimizer_trace？058.阿里、京东等大厂都有自研的存储引擎，如何开发一套自己的？086-089.什么是XA协议MySQLxa事务与普通事务区别是什么？2pc3pc的区别119-120.预编译sql是什么好处是什么？141-144.视图，外键，存储过程，processlist相关面试题145.某个表有数千万数据，查询比较慢，如何优化？说一下思路148.MySQL服务器毫无规律的异常重启如何排查问题？150.什么是MySQL多实例部署？","tags":["面试","数据库","MySQL"],"categories":["面试"]},{"title":"【面试相关】Java集合","path":"/posts/51727.html","content":"Java的集合类主要由两个接口派生出来的：分别是：Collection、Map Java集合概述 数组和集合的区别 容纳元素的区别： 数组：可以存储基本数据类型和引用数据类型。 集合：只能存储引用数据类型（如果存储的是 int 类型，会自动封装为 Integer）。 长度的区别： 数组：长度是固定的，需要提前声明。 集合：长度可变。 List、Set、Queue、Map 的区别 List：存储的元素有序、可重复，可使用下标操作元素； Set：无序、不可重复的集合； Queue：按照特定规则确定先后顺序，存储的元素有序、可重复； Map：使用键值对保存数据，kay无序不可重复，value无序可重复。 总结1. ListList 是一个有序集合，允许重复元素。 ArrayList 底层实现：基于 Object[] 数组。 特点：支持快速随机访问，但插入和删除效率较低（需要移动元素）。 应用场景： Vector 底层实现：基于 Object[] 数组。 特点：线程安全（通过 synchronized 实现），但性能较低。 LinkedList 底层实现：双向链表（JDK 1.6 之前为循环链表，JDK 1.7 取消了循环）。 特点：适合频繁插入和删除操作，但随机访问效率低。 2. SetSet 是一个可以存放无序、不重复的数据结构。 HashSet 底层实现：基于 HashMap，键值对中的键作为 Set 的元素，值固定为一个占位对象（PRESENT）。 特点：无序、唯一。 LinkedHashSet 底层实现：基于 LinkedHashMap，在 HashSet 的基础上增加了双向链表以维护插入顺序。 特点：有序（按插入顺序）、唯一。 TreeSet 底层实现：基于红黑树（自平衡的排序二叉树）。 特点：有序（按自然顺序或自定义比较器排序）、唯一。 3. QueueQueue 是一个队列集合，主要用于实现先进先出（FIFO）的数据结构。 PriorityQueue 底层实现：基于小顶堆（Object[] 数组）。 特点：元素按优先级排序（默认是自然顺序或自定义比较器）。 DelayQueue 底层实现：基于 PriorityQueue，存储实现了 Delayed 接口的元素。 特点：只有延迟时间到期的元素才能被取出。 ArrayDeque 底层实现：可扩容的动态双向数组。 特点：双端队列，支持高效的头尾插入和删除操作。 4. MapMap 是一个键值对集合，键唯一，值可以重复。 HashMap 底层实现： JDK 1.8 之前：数组 + 链表（解决哈希冲突）。 JDK 1.8 之后：数组 + 链表&#x2F;红黑树（当链表长度超过阈值 8 且数组长度大于等于 64 时，链表会转换为红黑树）。 特点：非线程安全，性能高。 LinkedHashMap 底层实现：继承自 HashMap，增加了一条双向链表以维护插入顺序或访问顺序。 特点：有序（按插入顺序或访问顺序）。 Hashtable 底层实现：数组 + 链表。 特点：线程安全（通过 synchronized 实现），但性能较低。 TreeMap 底层实现：基于红黑树（自平衡的排序二叉树）。 特点：按键排序（自然顺序或自定义比较器）。 ConcurrentMap 底层实现：基于分段锁（JDK 1.7）或 CAS + synchronized（JDK 1.8）优化的哈希表。 特点：线程安全，性能优于 Hashtable，支持高并发操作，不允许存储 null 键和 null 值 ListArrayList扩容机制底层基于动态数组实现，容量也可以动态增长。 扩容顺序创建新数组，容量是原来的1.5倍。把旧数组元素拷贝到新数组中使用新数组覆盖旧数组对象并发修改ArrayList元素会有什么问题 初始容量为 0；第一次添加元素后，容量为 10 手动扩容，需要提前知道数据的大概长度 12ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;();list.ensureCapacity(1000); // 提前扩容到至少 1000 个元素的容量 自动扩容 计算出新的扩容数组的长度后实例化，并将原有数组的内容复制到新数组中去。默认情况下，新的数组容量是原有容量的1.5倍 怎么在遍历ArrayList时移除一个元素只要在遍历过程中修改了集合的结构，就会导致记录修改次数的modCount对不上号，从而报错（快速失败：ConcurrentModificationException） 123456789101112131415161718192021ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;();list.add(&quot;a&quot;);list.add(&quot;b&quot;);list.add(&quot;c&quot;);// 错误示例，异常信息：ConcurrentModificationExceptionlist.forEach(item -&gt; &#123; if (item.equals(&quot;b&quot;)) &#123; list.remove(item); &#125; &#125;);// 正确移除元素，推荐使用迭代器Iterator iterator = list.iterator();while (iterator.hasNext()) &#123; if (iterator.next().equals(&quot;b&quot;)) &#123; iterator.remove(); System.out.println(&quot;b被移除&quot;); &#125;&#125; ArrayList和LinkedList实际开发中很少用到LinkedList，需要用到的场景几乎都可以用ArrayList平替。（需要频繁在首尾两端操作、实现队列&#x2F;双端队列结构时使用LinkedList） 特性 ArrayList LinkedList 底层数据结构 动态数组（Object[]） 双向链表（每个元素包含前后节点的引用） 访问速度 随机访问更快（通过索引直接访问） 访问较慢（需要从头或尾遍历到指定位置） 插入&#x2F;删除性能 尾部插入&#x2F;删除较快，中间/头部插入&#x2F;删除较慢（需要移动元素） 头尾插入&#x2F;删除较快，中间插入&#x2F;删除时相对较慢（需要遍历链表） 扩容方式 创建新数组并复制原数组（默认容量为原数组1.5倍） 不需要扩容，链表节点动态增加 内存开销 只存储数据本身和未使用的容量，占用较少内存 存储数据和前后节点引用，因此内存开销较大 线程安全 不是线程安全的，必须手动同步 不是线程安全的，必须手动同步 适用场景 适合频繁进行随机访问操作，尤其是查询操作较多的场景 适合频繁进行插入和删除操作，尤其是队列操作的场景 关于随机index访问： ArrayList：通过数组下标直接找到元素 LinkedList：需要移动指针遍历，直到找到为止 新增和删除元素，需要根据操作位置判断： ArrayList：可能会扩容和复制数组 LinkedList：只需要修改指针即可 SetSet的无序和不可重复 无序性 只有 HashSet 无序，不等于元素顺序是随机的，指的是存储的数据在底层数组中不是按照数组索引顺序添加， 而是根据数据的哈希值决定顺序。 不可重复性 添加的元素按照 equals() 判断时，返回 false，需要同时重写 equals() 和 hashCode() 方法。 排序：Comparable 和 Comparator 对比维度 Comparable Comparator 所属包 java.lang java.util 接口方法 int compareTo(Object obj) int compare(Object obj1, Object obj2) 排序逻辑位置 内置于类中（修改原类） 独立于类外（不修改原类） 排序方式 自然排序（类的默认排序规则） 定制排序（灵活定义多种排序规则） 使用场景 类有唯一明确的排序逻辑时（如 String, Date） 需要多种排序方式，或无法修改原类代码时 排序触发方式 Collections.sort(list) Collections.sort(list, comparator) 多条件排序支持 需要手动编写多条件比较逻辑 可通过 thenComparing() 链式调用（Java 8+） 线程安全性 依赖具体实现 依赖具体实现 Java 8+ 增强 无 支持 Lambda 和方法引用（如 Comparator.comparing()） Comparable 强制修改原类，耦合较重 1234567891011121314151617181920212223242526272829303132333435363738@Getter@Setterclass Person implements Comparable&lt;Person&gt; &#123; String name; int age; Person(String name, int age) &#123; this.name = name; this.age = age; &#125; @Override public int compareTo(Person o) &#123; // 升序：this.age - o.age // 降序：o.age - this.age return this.age - o.age; &#125; @Override public String toString() &#123; return name + &quot; (&quot; + age + &quot;)&quot;; &#125;&#125;public static void main(String[] args) &#123; TemporaryTest test = new TemporaryTest(); List&lt;Person&gt; personList = new ArrayList&lt;&gt;(); personList.add(test.new Person(&quot;name1&quot;, 20)); personList.add(test.new Person(&quot;name2&quot;, 50)); personList.add(test.new Person(&quot;name5&quot;, 1)); System.out.println(&quot;排序前：&quot; + personList); Collections.sort(personList); System.out.println(&quot;排序后：&quot; + personList);&#125; Comparator 实现排序逻辑完全解耦，可以定制排序 123456789101112131415161718192021222324252627282930313233343536373839@Getter@Setterclass Person &#123; String name; int age; Person(String name, int age) &#123; this.name = name; this.age = age; &#125; @Override public String toString() &#123; return name + &quot; (&quot; + age + &quot;)&quot;; &#125;&#125;public static void main(String[] args) &#123; TemporaryTest test = new TemporaryTest(); List&lt;Person&gt; personList = new ArrayList&lt;&gt;(); personList.add(test.new Person(&quot;Alice&quot;, 20)); personList.add(test.new Person(&quot;Charlie&quot;, 50)); personList.add(test.new Person(&quot;Bob&quot;, 1)); System.out.println(&quot;排序前：&quot; + personList); // Comparator 示例（不修改原类） Comparator&lt;Person&gt; nameComparator = new Comparator&lt;Person&gt;() &#123; public int compare(Person p1, Person p2) &#123; // 外部比较逻辑（按姓名排序） return p1.name.compareTo(p2.name); &#125; &#125;; Collections.sort(personList, nameComparator); System.out.println(&quot;排序后：&quot; + personList);&#125; HashSet、LinkedHashSet、TreeSet 特性 HashSet LinkedHashSet TreeSet 底层数据结构 哈希表（基于 HashMap 实现） 哈希表 + 双向链表（基于 LinkedHashMap 实现） 红黑树（自平衡的排序二叉树） 存储顺序 无序（根据哈希值存储，不保证顺序） 按插入顺序存储（有序） 按自然顺序或自定义比较器排序（有序） 访问速度 快速查找（通过哈希值定位元素） 查找速度与 HashSet 类似，但由于维护了插入顺序，稍慢一些 查找速度较慢（红黑树的查找时间复杂度为 O(log n)） 插入&#x2F;删除性能 插入和删除较快（基于哈希表操作） 插入和删除较快，但比 HashSet 稍慢（需要维护链表） 插入和删除较慢（需要维护红黑树的平衡性） 扩容方式 动态扩容（默认扩容为原容量的 2 倍） 动态扩容（与 HashSet 类似） 不需要扩容（红黑树动态调整结构） 内存开销 内存占用较少（仅存储哈希表） 内存占用较大（需要额外存储链表节点的前后引用） 内存占用较大（红黑树节点需要存储额外的指针信息） 线程安全 非线程安全，必须手动同步 非线程安全，必须手动同步 非线程安全，必须手动同步 适用场景 适合需要快速查找且不关心顺序的场景 适合需要保持插入顺序且快速查找的场景 适合需要对元素进行排序的场景 HashSet：基于 HashMap，无序、快速查找、支持 null，非线程安全。 LinkedHashSet：基于 LinkedHashMap，按插入顺序存储、快速查找、支持 null，非线程安全。 TreeSet：基于红黑树，按键排序（自然顺序或自定义顺序）、不支持 null，非线程安全。 HashMap实现和特点实现 JDK 1.8 之前：数组 + 链表 JDK 1.8 之后：数组 + 链表&#x2F;红黑树 JDK 1.8 之前的实现 JDK 1.8 之后的实现 特点 键唯一，值可以重复 允许存储 null 键和 null 值（只能存储一个 null 键） JDK 1.8 中引入了红黑树优化 非线程安全 默认初始容量：16，默认负载因子：0.75 链表和红黑树切换机制每个数组的位置，都可能存储以下三种数据结构之一： 空：没有键值对 链表： 当冲突的键值对较少时，使用链表存储 红黑树：当冲突的键值对较多时，使用红黑树存储 链表 → 红黑树的切换规则： 某个数组元素存储的链表长度 ≥ 8，且当前数组长度 ≥ 64时，链表转为红黑树 如果数组长度 ＜ 64，优先扩容数组，不进行转换 红黑树 → 链表的切换规则： 某个数组元素存储的红黑树的节点数 ≤ 6，红黑树退化为链表 哈希冲突的解决方法 开放寻址法 当出现哈希冲突时（两个键映射到同一个数组索引），通过某种规则在哈希表中寻找下一个空间的位置。 实现方式： 线性探测：依次查找下一个位置（例如：hash(key) + 1) 二次探测：按照平方步长查找空位（例如：例如：hash(key) + 1^2） 双重哈希：使用第二个哈希函数计算步长 优点不需要额外空间存储指针实现简单 缺点多个冲突元素堆积在一起，导致性能下降删除节点时只能标记为已删除，否则会影响后续查找 再哈希法 发生冲突时，使用另一个哈希函数重新计算位置，直到找到不冲突的位置为止。 示例代码12345int index1 = hash1(key);if (table[index1] != null) &#123; int index2 = hash2(key); // 继续尝试其他哈希函数...&#125; 优点减少冲突概率不会产生堆积问题 缺点计算多个哈希函数，增加时间开销实现复杂 链地址法（HashMap使用的方法） 每个哈希桶（数组的每个位置称为一个桶）维护一个链表或红黑树，所有哈希值相同的元素存放到同一个链表或红黑树内。 优点实现简单，适合处理大量冲突动态扩展性强，不需要重新分配数组JDK 1.8 引入红黑树，解决极端情况下哈希冲突的性能问题 缺点需要额外空间存储链表节点链表过长时，性能会倒退 扩容过程是怎样的当 HashMap 的元素容量超过阈值（计算方式：当前数组长度 * 负载因子）时，就会触发扩容（创建一个新数组，容量是原数组的两倍的）： 创建新数组： 当前数组长度为 16，负载因子为 0.75，阈值为：16 * 0.75 &#x3D; 12，插入第 13 个元素时触发扩容，创建新数组。 重新分配键值对： 重新计算原数组的键值对索引位置，并迁移到新数组，计算公式：index = (n - 1)&amp; hash。 其中，n 是数组长度，hash 是键的哈希值 其他问题 为什么容量是原来的两倍？ 因为 `HashMap` 要求数组长度必须是 2 的幂，方便通过位运算快速计算索引（数组下标，也就是元素的存储位置）， 如果容量不是 2 的幂，会导致哈希分布不均，增加冲突概率 数组下标的计算方法计算公式为：index = (n - 1)&amp; hash。当数组长度 n 是 2 的幂次方时，等价于 hash &amp; n，同时可以使用位运算取代取余操作，计算效率更高 扩容对红黑树的影响由于扩容后需要重新计算索引位置，红黑树的 8 个节点也是如此，可能的结果： 如果所有节点仍然映射在一个桶中，则红黑树不变 如果部分节点被分配到其他桶中，则红黑树会分裂（分裂后节点数量小于 6，则会退化为链表） HashMap的 Key 可以是可变对象吗可以使用，但是不推荐 常见的不可变对象：String、包装类（Integer、Double、Boolean等）、BigInteger、BigDecimal； 常见的可变对象：StringBuilder、StringBuffer、集合类（如 ArrayList、HashMap）、自定义类。 不推荐的原因 会破坏 HashMap 的数据结构和功能 前提：键对象发生变化后，hashCode() 会重新计算 插入新的键值对时，会根据新的 hashCode() 计算存储位置，认为是一个新的键（逻辑上应该是同一个），会导致重复插入实际上是同一个 key 的键值对，造成数据冗余 由于 hashCode() 已经发生变化，原来的键值对可能被存储在不同位置， 可能会导致查找或删除操作失败 为什么线程不安全？ JDK 1.7 扩容死循环问题在 JDK 1.7 中的 HashMap 使用头插法迁移数据，多线程时扩容可能会导致环形链表的情况 示例 线程 A 和 B，同时进行扩容操作，原链表顺序为 A → B → NULL ：线程 A 迁移后的链表变为：B → A → NULL（头插法反转）线程 B 基于线程 A 的结果再次迁移，形成 A → B → A 的环状链表。JDK 1.8 后修改为 尾插法，避免链表反转，解决了死循环问题 JDK 1.8 数据覆盖两个线程若同时进行 put() 操作，且计算出的哈希值指向同一个桶 桶为空，两个线程都认为该节点为空，并尝试插入，最终只会有一个线程的写入生效，另一个线程写入的数据被覆盖 桶非空，两个线程同时修改链表或红黑树，导致节点丢失或链表断裂 put 方法的流程put方法执行流程 检查数组是否初始化如果 table 未初始化，则进行懒加载（初始化数组） 计算哈希值使用 hash 算法 index = (n - 1) &amp; hash，计算 key 的索引 插入逻辑 桶为空 ：直接插入新节点 桶不为空 ： 如果是链表节点，遍历链表并插入到尾部（JDK 1.8 后改为尾插法） 如果是红黑树节点，插入到红黑树中 链表 → 红黑树当链表长度 ≥ 8 且数组长度 ≥ 64 时，链表转为红黑树 插入成功后检查是否需要扩容扩容时，重新分配所有节点到新数组，如果红黑树节点数 ≤ 6，则退化为链表 和 HashTbale 的异同注意除了有强一致性需求（遍历时不允许修改集合结构）外，不推荐使用 HashTable，推荐使用 ConcurrentHashMap 特性 HashMap Hashtable 底层数据结构 数组 + 链表&#x2F;红黑树（Java 8+ 优化） 数组 + 链表 null键&#x2F;值 允许一个null键和多个null值 键和值均不允许null，否则抛出NullPointerException 访问速度 无同步锁，读取速度快 方法级同步（synchronized），读取速度较慢 插入&#x2F;删除性能 无锁机制，性能较高 同步锁导致性能较低 扩容方式 按需扩容（默认负载因子0.75），重新哈希并迁移元素 按需扩容（默认负载因子0.75），重新哈希并迁移元素 内存开销 较小（无同步开销） 较大（同步机制和额外对象） 线程安全 非线程安全，需手动同步或使用ConcurrentHashMap 线程安全，所有方法通过synchronized实现同步 适用场景 单线程环境或无需同步的场景，追求高性能 多线程需线程安全的场景，但推荐优先使用ConcurrentHashMap ConcurrentMap 底层实现： 数组 + 链表&#x2F;红黑树 线程安全实现： CAS（无锁操作） 和 synchronized synchronized 只锁定当前链表或红黑树的首节点，锁粒度更小，支持更高并发。 和 HashTable 的异同 特性 Hashtable ConcurrentHashMap 线程安全机制 全局锁（synchronized） 分段锁（JDK 1.7）或 CAS + 细粒度锁（JDK 1.8） 性能 低（全局锁竞争激烈） 高（锁粒度细化，支持并发） null 支持 不允许 null 键和值 不允许 null 键，允许 null 值（JDK 1.8+） 迭代器一致性 强一致性（遍历时不允许修改） 弱一致性（遍历时允许修改） 扩容效率 低（锁住整个表） 高（支持多线程协作扩容） 适用场景 遗留系统或低并发 高并发场景 数据结构 数组 + 链表 数组 + 链表&#x2F;红黑树（同 HashMap） 历史背景 Java 早期实现（JDK 1.0） 现代实现（JDK 1.5+） 怎样保证复合操作的原子性 怎样算是复合操作？ 即使 ConcurrentMap 的单个操作是线程安全的（put、get），但多个操作的组合无法保证线程安全，示例代码如下： 示例123if (!map.containsKey(key)) &#123; // 检查 map.put(key, value); // 修改&#125; 线程 A 执行 containsKey，结果返回 false 线程 B 在线程 A 检查后，抢先插入了相同的 key 线程 A 继续执行 put，导致覆盖了线程 B 的数据，破坏了原子性 怎样保证复合操作的原子性？ 使用 ConcurrentMap 自带的原子方法，或显示同步 synchronized，例如： putIfAbsent(K key, V value)，仅在键不存在时插入值 remove(Object key, Object value)，仅在键和值同时匹配时删除键值对 replace(K key, V oldValue, V newValue)，仅在键存在且旧值匹配时替换为新值 迭代器 IteratorJava 集合框架提供的接口，用于遍历集合元素，使用统一的方式访问集合元素，更加安全。 和 for 的对比 对比项 Iterator for 循环 遍历适用范围 适用于所有集合类型，提供统一接口进行遍历 基于索引的遍历，仅适用于数组或 List（如 ArrayList） 元素删除特点 支持在遍历时安全删除元素，通过调用 remove() 方法实现 直接删除元素可能会引发 ConcurrentModificationException 异常 和 ListIterator 的对比 特性 Iterator ListIterator 遍历方向 单向（从头到尾） 双向（支持向前和向后遍历） 修改操作 仅支持删除（remove()） 支持删除、添加（add()）、修改（set()） 适用范围 所有集合 仅 List 类型（如 ArrayList、LinkedList） fail-fast 和 fail-safe fail-fast错误检测机制，当发现可能导致数据不一致的操作时，抛出异常：ConcurrentModificationException。 实现原理集合内部维护了一个修改计数器：modCount，集合创建时记录当前的modCount，每次迭代时进行检查，如果有变化就抛出异常 在单线程或多线程环境下，迭代过程中的集合结构被修改： 触发场景1234567891011List&lt;String&gt; list = new ArrayList&lt;&gt;();list.add(&quot;A&quot;);list.add(&quot;B&quot;);Iterator&lt;String&gt; iterator = list.iterator();while (iterator.hasNext()) &#123; String item = iterator.next(); if (item.equals(&quot;A&quot;)) &#123; list.remove(item); // 抛出 ConcurrentModificationException &#125;&#125; fail-safe在迭代过程中，即使集合被修改，也不会抛出异常：`ConcurrentModificationException`。 实现原理集合实际上遍历的是旧副本（快照），而不是实时数据，修改操作也不会影响到已经存在的迭代器 特性 Fail-Fast（快速失败） Fail-Safe（安全失败） 异常抛出 迭代期间修改集合会抛出ConcurrentModificationException 不会抛出异常 实现原理 检查 modCount 计数器变化 遍历集合的快照或弱一致性视图 性能 高（无额外开销） 较低（需要维护快照或同步机制） 适用场景 单线程或手动同步的多线程环境 高并发场景（如多线程读写） 典型集合类 ArrayList、HashMap、TreeMap ConcurrentHashMap、CopyOnWriteArrayList 迭代器行为 直接操作集合的实时数据 操作集合的旧副本或弱一致性数据","tags":["面试","Java集合"],"categories":["面试"]},{"title":"【面试相关】Java基础","path":"/posts/38943.html","content":"面向对象特性 封装 隐藏实现细节，保护数据，将类的内部实现细节隐藏，不允许外部程序直接访问，而是通过该类提供的方法进行操作和访问 继承 从已有类中派生出新的类，新的类继承父类属性和行为，并扩展新的能力，提升代码复用与扩展性 Java是单继承的，也就是一个子类只有一个父类。 多态 同一个行为具有多个不同表现形式的能力（同一接口，不同实现）。 实现多态的三要素：继承、重写、父类引用指向子类对象。 静态多态性 通过重载实现。相同的方法有不同的參数列表，可以根据参数的不同，做出不同的处理 动态多态性 在子类中重写父类的方法。运行期间判断所引用对象的实际类型，根据其实际类型调用相应的方法 抽象 把客观事物用代码抽象出来 接口和抽象类的异同 共同点 实例化，都不能直接实例化，只能被实现（接口）、继承（抽象类）后，才能创建具体的对象 抽象方法，都可以包含抽象方法，抽象方法没有方法体，必须在子类或实现类中实现 区别 接口，interface目的：对类的行为进行约束，实现某个接口就有了对应的行为继承和实现： 可以实现或继承多个接口成员变量：必须是 public static final 类型的，不能被修改且必须有初始值方法：从Java8开始，接口中可以定义 default 和 static 方法；从 Java 9 开始，接口中可以定义 private 方法。 抽象类，abstract目的：主要用于代码复用，强调所属关系继承和实现： 只能继承一个类（Java不支持多继承）成员变量：成员变量可以使用任何修饰符，也可以在子类中被重新定义或赋值方法：可包含抽象（没有方法体，在子类中实现）和非抽象方法（有具体实现，可在子类中重写） 内部类【重要】深拷贝、浅拷贝、引用拷贝 深拷贝会创建新对象复制基本类型成员复制引用类型对象（类）新对象和原对象在内存上是完全独立的 浅拷贝会创建新对象复制基本类型成员引用类型对象（类）共享引用，数据相互影响新对象和原对象在内存上不是完全独立的， 新对象和原对象的引用类型对象指向内存中的同一个对象 引用拷贝没有创建新的对象，只是创建了一个新的引用， 该引用指向原对象在内存中的地址。如果对其中一个进行修改， 会直接影响到另一个引用。 如果对象内只有基本数据类型，深拷贝和浅拷贝是没有区别的，因为二者都会复制基本数据类型的对象 深浅拷贝的区别在类的 clone() 方法中，深拷贝会对引用类型的成员变量进行拷贝（需要这些成员也实现 Cloneable 接口）。 而浅拷贝则仅复制引用，不复制对象本身。 引用拷贝，就是新对象直接指向了原对象。 深拷贝示例 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859@Getter@Setterclass Address implements Cloneable &#123; private String city; public Address(String city) &#123; this.city = city; &#125; @Override protected Object clone() throws CloneNotSupportedException &#123; return super.clone(); &#125;&#125;@Getter@Setterclass Person implements Cloneable &#123; private String name; private int age; private Address address; public Person(String name, int age, Address address) &#123; this.name = name; this.age = age; this.address = address; &#125; @Override protected Object clone() throws CloneNotSupportedException &#123; Person clone = (Person) super.clone(); // 对引用类型进行深拷贝 clone.address = (Address) address.clone(); return clone; &#125;&#125;public class TemporaryTest &#123; public static void main(String[] args) throws CloneNotSupportedException &#123; // 创建原对象 Person originalPerson = new Person(&quot;Alice&quot;, 30, new Address(&quot;北京&quot;)); // 进行浅拷贝 Person shallowCopyPerson = (Person) originalPerson.clone(); // 修改浅拷贝对象的属性 shallowCopyPerson.setName(&quot;Bob&quot;); shallowCopyPerson.setAge(25); shallowCopyPerson.getAddress().setCity(&quot;上海&quot;); // 先获取拷贝后对象的属性，再对其修改 // 输出原对象和浅拷贝对象的属性（可以看到，原对象的引用数据类型没有变化） System.out.println(&quot;原对象: &quot; + originalPerson.getName() + &quot;, &quot; + originalPerson.getAge() + &quot;, &quot; + originalPerson.getAddress().getCity()); System.out.println(&quot;浅拷贝对象: &quot; + shallowCopyPerson.getName() + &quot;, &quot; + shallowCopyPerson.getAge() + &quot;, &quot; + shallowCopyPerson.getAddress().getCity()); &#125;&#125; 浅拷贝示例 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@Getter@Setterclass Address&#123; private String city; public Address(String city) &#123; this.city = city; &#125;&#125;@Getter@Setterclass Person implements Cloneable &#123; private String name; private int age; private Address address; public Person(String name, int age, Address address) &#123; this.name = name; this.age = age; this.address = address; &#125; @Override protected Object clone() throws CloneNotSupportedException &#123; return super.clone(); &#125;&#125;public class TemporaryTest &#123; public static void main(String[] args) throws CloneNotSupportedException &#123; // 创建原对象 Person originalPerson = new Person(&quot;Alice&quot;, 30, new Address(&quot;北京&quot;)); // 进行浅拷贝 Person shallowCopyPerson = (Person) originalPerson.clone(); // 修改浅拷贝对象的属性 shallowCopyPerson.setName(&quot;Bob&quot;); shallowCopyPerson.setAge(25); shallowCopyPerson.getAddress().setCity(&quot;上海&quot;); // 先获取拷贝后对象的属性，再对其修改 // 输出原对象和浅拷贝对象的属性（可以看到，原对象的引用数据类型也发生了变化） System.out.println(&quot;原对象: &quot; + originalPerson.getName() + &quot;, &quot; + originalPerson.getAge() + &quot;, &quot; + originalPerson.getAddress().getCity()); System.out.println(&quot;浅拷贝对象: &quot; + shallowCopyPerson.getName() + &quot;, &quot; + shallowCopyPerson.getAge() + &quot;, &quot; + shallowCopyPerson.getAddress().getCity()); &#125;&#125; 引用拷贝示例 1234567891011121314151617181920212223class Point &#123; int x; int y; public Point(int x, int y) &#123; this.x = x; this.y = y; &#125;&#125;public class TemporaryTest &#123; public static void main(String[] args) &#123; Point p1 = new Point(1, 2); Point p2 = p1; // 修改新拷贝中的值 p2.x = 3; System.out.println(p1.x); // 3 &#125;&#125; Object一个特殊的类，是所有类的父类。 常用方法 hashCode()，返回对象的哈希码。将与对象相关的信息映射成一个哈希值，默认的实现是根据内存地址换算的 toString()，默认输出对象地址，推荐重写以输出对象的值 equals(Object obj)，比较两个对象的内存地址是否相等 clone()，创建并返回当前对象的一份拷贝（需要实现Cloneable接口） wait()，根据入参暂停线程的执行 getClass()，返回此Object的运行时类，常用于反射机制 &#x3D;&#x3D;和equals的区别 &#x3D;&#x3D;对于基本数据类型，比较的是他们的值是否相等对于引用数据类型，比较对象的内存地址（引用），即是否指向同一个对象 equals常用于比较引用数据类型的内容，即是否具有相同的属性值默认实现和==类似，即比较对象的内存地址 示例123456// String的equals()方法已经被重写过String a = new String(&quot;hello&quot;);String b = new String(&quot;hello&quot;);System.out.println(a == b); // false, 因为引用不同System.out.println(a.equals(b)); // true, 因为内容相同 hashCode()有什么用 用于返回哈希码，作用是确定该对象在哈希表中的位置 在使用哈希算法进行对象查找时，可快速定位对象，提高查询效率 总结 如果两个对象通过equals()比较为相同，那么它们的hashCode也相同两个对象的hashCode相同， 两个对象的equals()不一定相同（可能发生哈希碰撞） 如果hashCode不相同，就可以直接认为这两个对象不相等 重写equals()时，也必须重写hashCode()，否则会出现用hashCode()判断是相等的两个对象，hashCode()缺不相等 StringString、StringBuffer、StringBuilder String 是否可变：不可变 线程安全：是 性能：较低（每次修改都会创建新对象） 适用场景：适用于不频繁修改的场景 内存使用：内存占用较大 常用方法：concat() , replace(), substring() StringBuffer 是否可变：可变 线程安全：是（通过同步） 性能：较高（支持高效的修改操作） 适用场景：适用于多线程环境，频繁修改时使用 内存使用：内存占用较小 常用方法：append(), insert(), delete(), reverse() StringBuilder 是否可变：可变 线程安全：否（不通过同步） 性能：较高（支持高效的修改操作） 适用场景：适用于单线程环境，频繁修改时使用 内存使用：内存占用较小 常用方法：append(), insert(), delete(), reverse() 对于三者的使用总结 操作少量数据，可以使用：String 单线程情况下，操作大量数据，使用：StringBuilder多线程情况下，操作大量数据，使用：StringBuffer String为什么不可变？ String类本身是final的，不能被继承，进而避免子类破坏String不可变 1public final class String 存储字符串的数组使用final修饰，并且是私有的（private） 12/** The value is used for character storage. */private final char value[]; String类没有类似setter的方法，内容不能被直接修改 new String(“ss”) 创建了几个对象？1String str = new String(&quot;ss&quot;); 答案：会创建一个或者两个对象 如果字符串常量池中已经存在了ss，则只会创建一个str对象 如果字符串常量池中不存在，则会在字符串常量池中创建一个ss对象，并且再创建一个str对象 字符串常量池针对String类专门开辟的区域，主要为了避免字符串重复创建。 底层实现为什么从char换成byte是从JDK 9开始的，底层实现从 char[] ，换成了 byte[] ： 减少内存占用：char在内存中占2字节，byte占1字节，相当于压缩了数据 新增byte类型的coder字段，记录当前字符串的编码格式： 0：LATIN-1（单字节） 1：UTF-16（双字节） 字符串拼接 方式 优点 缺点 适用场景 + 简单直观，代码易读 大量拼接时效率低 少量拼接，代码简洁为主 StringBuilder 高效，适合频繁拼接 线程不安全 大量拼接，性能要求较高 StringBuffer 高效，线程安全 较 StringBuilder 慢 多线程拼接，线程安全为主 自增自减运算符符号在前就先加&#x2F;减，符号在后就后加&#x2F;减。 前缀形式（++a、–a），先自增&#x2F;自减，然后再赋值或使用该变量 后缀形式（a++、a–），先赋值或使用该变量，然后再执行自增&#x2F;自减 各变量的值分别是多少答案12345int a = 9;int b = a++;int c = ++a;int d = c--;int e = --d;答案：a &#x3D; 11，b &#x3D; 9，c &#x3D; 10， d &#x3D; 10，e &#x3D; 10，过程如下：a &#x3D; 9， 初始值为9b &#x3D; a++， 先赋值给 b &#x3D; 9，再自增 a &#x3D; 10c &#x3D; ++a， 先自增再赋值，此时 a &#x3D; 10，所以 a &#x3D; 11，此时 c &#x3D; 11（c还有一次运算）d &#x3D; c–， 先赋值再自减，此时 d &#x3D; 11（d还有一次运算），c &#x3D; 10e &#x3D; –d， 先自减再赋值，此时 d &#x3D; 10，e &#x3D; 10 基本数据类型和包装数据类型 类型名称 类型 位数 字节数 默认值 取值范围 整数型 byte 8 1 0 -128 至 127 整数型 short 16 2 0 -32768（-2^15） 至 32767（2^15 - 1） 整数型 int 32 4 0 -2147483648 至 2147483647 整数型 long 64 8 0L -9223372036854775808（-2^63） 至 9223372036854775807（2^63 -1） 单精度浮点 float 32 4 0.0f ±3.40282347E+38F （有效数字 6-7 位） 双精度浮点 double 64 8 0.0d ±1.79769313486231570E+308 （有效数字 15 位） 字符型 char 16 2 ‘\\u0000’ 0 ~ 65535（2^16 - 1） 布尔型 boolean 1 false true 或 false 为什么要有包装数据类型 支持泛型：Java 的泛型只能接受对象（List）无法使用基础类型 对象特性：可以参与面向对象的操作（多态、方法调用等） 空值表示：可以赋值为 null 自动拆装箱：提供自动转换机制（int → Integer） 方法内传递变量优先使用基础类型还是包装类型优先使用基础类型 性能更高：基础类型没有创建对象的开销 避免空指针：基础类型不能为 null，减少异常风险 区别 用途： 方法参数、对象属性等常使用包装类型，并且可用于泛型，基本类型则很少用于这些地方。 存储： 基本数据类型局部变量在栈中局部变量表， 未被 static 修饰的成员变量在虚拟机的堆中； 包装类型属于对象类型，存放于堆中。 基本数据类型存放在栈中是一个常见的误区如果它们是局部变量，那么它们会存放在栈中； 如果它们是成员变量，那么它们会存放在堆&#x2F;方法区&#x2F;元空间中。 空间： 基本数据类型比包装类型占用空间小。 默认值： 成员变量包装类型默认 null，基本类型有非 null 默认值。 比较： 基本类型使用 &#x3D;&#x3D; 比值，包装类型 &#x3D;&#x3D; 比内存地址。 所有整型包装类对象之间值的比较，用 equals() 方法。 包装类型的缓存机制 整数型（Byte，Short，Integer，Long） 这四种都默认创建了数值[-128, 127]]的相应类型缓存数据 字符型（Character） 默认创建了数值[0, 127]]的相应类型缓存数据 布尔型（Boolean） 缓存了True、False两种 浮点型（Float，Double） 和其他类型不同，没有缓存机制 自动拆装箱 装箱：将基本类型用其对应的包装类型（实际上调用了包装类的 valueOf() 方法） 拆箱：将包装类型转换为基本数据类型（调用了xxxValue()方法） 频繁拆装箱会影响性能，应尽量避免不必要的操作 示例12345678Integer i = 10; // 装箱// 等价于Integer i = Integer.valueOf(10)int n = i; // 拆箱// 等价于int n = i.intValue() 浮点数运算精度丢失示例12345float a = 2.0f - 1.9f;float b = 1.8f - 1.7f;System.out.println(a + &quot; &quot; + b); // 0.100000024 0.099999905System.out.println(a == b); // false 原因： 二进制表示：十进制小数转化为二进制时，有些小数无法精确表示，还有的会出现无限循环小数，由于浮点型的尾数部分有限，所以只能截取一部分存储，造成精度丢失 十进制的0.1，转为二进制就是无限循环小数0.00011001100110011… 运算过程的舍入：由于存储位数限制，在存储运算的中间结果和最终结果时，会对二进制数进行舍入，同样会导致精度丢失 解决方法：使用 BigDecimal BigDecimal 常见问题 使用BigDecimal时，禁止使用构造方法（new BigDecimal(double)），会造成精度丢失，应该使用下面两种之一： 123new BigDecimal(String val);BigDecimal.valueOf(double val); 比较大小时应使用compareTo()方法，因为equals()方法除了比较大小还会比较精度： 123BigDecimal a = new BigDecimal(&quot;1&quot;);BigDecimal b = new BigDecimal(&quot;1.0&quot;);System.out.println(a.equals(b)); // false 四舍五入和指定小数位数，属于同一个方法 setScale()： 1234567// 基本语法BigDecimal.setScale(int newScale, RoundingMode roundingMode);// 四舍五入（保留两位小数）BigDecimal value = new BigDecimal(&quot;123.456&quot;);BigDecimal rounded = value.setScale(2, RoundingMode.HALF_UP);System.out.println(rounded); // 输出：123.46 方法为什么静态方法不能调用非静态成员 静态方法 属于类，而不属于类的实例，类加载时就会分配到内存中 可以通过类名直接调用 不能直接访问非静态成员（非静态变量、方法） 非静态成员 属于类的实例，创建了类的对象后才会分配内存空间 包括非静态变量、方法，是和对象绑定的 总结 静态方法属于类，类加载时就会分配内存，可通过类名直接访问； 非静态成员属于实例对象，对象实例化后才存在，需要通过类的实例对象访问。 重载和重写 方法重载 在同个类中多个方法可以有相同的方法名称，必须有不同的参数列表 12345void setPersonInfo()&#123;&#125;void setPersonInfo(String name)&#123;&#125;void setPersonInfo(String name, int age)&#123;&#125; 方法重写 针对的是父类和子类之间的，父类功能无法满足子类需求时，可以在子类中对父类方法进行重写。 方法重写时，方法名和形参列表必须一致 123456789101112class Animal &#123; public void makeSound() &#123; System.out.println(&quot;动物&quot;); &#125;&#125;class Dog extends Animal &#123; @Override public void makeSound() &#123; System.out.println(&quot;狗&quot;); &#125;&#125; 可变长参数可变长参数就是允许在调用方法时传入长度不定的参数，同时，可变参数只能作为函数的最后一个参数，例如： 示例1234567public static void method(String... args)&#123; &#125;public static void method(String arg, String... args)&#123; &#125; 如果遇到方法重载的情况时，优先匹配固定参数的方法，因为固定参数的方法匹配度更高 Java为什么只有值传递首先要明确实参和形参的概念： 实参实际参数，用于传递给函数、方法的参数，必须要有确定的值 形参形式参数，用于定义函数、方法，不需要有确定的值 示例123456789String str = &quot;hello&quot;;// 此处的str为实参sayHello(str);// 此处的arg为形参void sayHello(String arg)&#123; System.out.println(arg);&#125; 值传递和引用传递程序中将实参传递给方法、函数的方式有两种： 值传递：方法接收的是实参值的拷贝，会创建副本 引用传递：方法接收的是实参在堆中的地址，不会创建副本，对形参的修改会影响到实参 Java中只有值传递 案例一：传递基本类型 swap() 方法中 arg1、arg2 的值，都是从 num1、num2 复制过来的，修改副本不会影响到原参数。 传递基本类型123456789101112131415161718public static void main(String[] args) &#123; int num1 = 1; int num2 = 2; swap(num1, num2); System.out.println(&quot;方法执行后，num1：&quot; + num1); // num1 = 1 System.out.println(&quot;方法执行后，num2：&quot; + num2); // num2 = 2&#125;static void swap(int arg1, int arg2) &#123; int temp = arg1; arg1 = arg2; arg2 = temp; System.out.println(&quot;swap方法内，arg1：&quot; + arg1); // arg1 = 2 System.out.println(&quot;swap方法内，arg2：&quot; + arg2); // arg2 = 1&#125; 案例二：传递引用类型1（数组） 这个案例中，形参传递的还是值，不过值是实参的地址，和 arr[] 指向的是同一个数组对象。 因为数组也是对象，传递的是引用的副本，方法内部和外部指向的是同一个对象，在方法内部的修改也会反映到原始对象上。 传递引用类型1（数组）123456789101112131415public static void main(String[] args) &#123; int arr[] = &#123;1,2,3,4&#125;; System.out.println(&quot;方法执行前，arr[0]：&quot; + arr[0]); setArrFirstValue(arr); System.out.println(&quot;方法执行后，arr[0]：&quot; + arr[0]);&#125;static void setArrFirstValue(int[] arg) &#123; arg[0] = 0; System.out.println(&quot;方法内，arg[0]：&quot; + arg[0]);&#125; 案例三：传递引用类型2（对象） 参数p1、p2拷贝的只是 zhang、wang 的地址，因此 swap() 方法内的互换也只是两个地址的互换，不会影响到实参 zhang、wang。 传递引用类型2（对象）1234567891011121314151617181920212223@Setter@Getter@AllArgsConstructorpublic static class Person &#123; private String name;&#125;public static void swap(Person p1, Person p2) &#123; Person temp = p1; p1 = p2; p2 = temp; System.out.println(&quot;方法内，p1（传入zhang）：&quot; + p1.name); // wang System.out.println(&quot;方法内，p2（传入wang）：&quot; + p2.name); // zhang&#125;public static void main(String[] args) &#123; Person zhang = new Person(&quot;张&quot;); Person wang = new Person(&quot;王&quot;); swap(zhang, wang); System.out.println(&quot;方法执行后，zhang：&quot; + zhang.name); // zhang System.out.println(&quot;方法执行后，wang：&quot; + wang.name); // wang&#125; 为什么修改了引用副本，还是会影响原对象？对象引用本质上是一个指向堆内存地址的值（例如：new param 的地址值是 0x1001）。引用的副本也是如此，不是在堆中复制一份对象，而是 复制原对象的地址值（例如：拷贝了param 对象的地址：0x1001）。对象引用的一些行为特点：原引用 和 副本，指向堆中的同一个对象通过副本修改对象的属性，本质是操作同一块堆内存修改副本的指向（param = new Object()），不影响原对象的使用 异常Java异常类 概述Throwable是所有异常的父类，有两个直接子类：Exception、Error ExceptionChecked Exception（已检查异常）必须在代码中手动处理（使用try-catch或throws声明），常见例子：IOExceptionSQLExceptionClassNotFoundExceptionUnchecked Exception（未检查异常）继承自RuntimeException，可以选择处理或不处理，常见例子：NullPointerExceptionArrayIndexOutOfBoundsExceptionIllegalArgumentException Error程序无法处理的错误，通常是JVM层面的问题不建议捕获或处理（可以捕获，但是Java设计理念中，不应尝试通过代码处理Error），常见例子：IOErrorOutOfMenmoryErrorAssertionError try-with-resources 和 try-catch-finally try-with-resources实现了 AutoCloseable 或 Closeable 接口自动关闭 try 中声明的资源，无需手动调用 close() try-catch-finally需要在 finally 中手动调用 close()如果在 finally 中关闭资源时抛出异常，可能会覆盖掉原有异常 注意事项 如果 try 和 finally 块中都有 return 语句，finally 块仍然会执行。 但如果 finally 块中也包含 return 语句，则 try 块中的 return 值会被 finally 块中的 return 覆盖。 1234567891011public static int testTryAndFinally()&#123; try &#123; return 1; &#125; finally &#123; return 2; &#125;&#125;public static void main(String[] args) &#123; System.out.println(testTryAndFinally()); // 2&#125; throw 和 throws 关键字 作用 指定的内容 出现位置 支持的异常数量 throws 声明方法可能抛出的异常 异常类型名称 方法定义的括号后 可以声明多个异常，使用逗号分隔 throw 显式抛出一个异常对象 异常实例 方法体内部 一次只能抛出一个异常 出现位置1234567// throws 出现在方法签名中public void readFile(String filePath) throws IOException &#123; if (filePath == null || filePath.isEmpty()) &#123; // throw 出现在方法体内 throw new IOException(&quot;文件路径不能为空&quot;); &#125;&#125; 泛型参数化类型机制，允许类、接口、方法能够操作不同类型的对象。 主要目的是提高代码的类型安全性和可读性。 作用 类型安全，编译时检查类型错误，避免运行时报错 代码复用，可以支持多种数据类型的通用代码 可读性和可维护性，明确指定类型，减少模糊的类型操作 常用的参数命名T：Type，表示任意类型，常用于通用类或者方法 1public class Box&lt;T&gt;&#123;&#125;E：Element，多用于集合类型 1List interface List&lt;E&gt; &#123;&#125;K、V：Key、Value，用于键值对映射 1public interface Map&lt;K, V&gt; &#123;&#125;N： Number，多用于操作数字的情况 1public class Calculator&lt;N extends Number&gt; &#123;&#125;?：用于不确定的类型 1public void printList(List&lt;?&gt; list) &#123;&#125;R：Result，表示返回值类型（不常用） 1234567public interface Converter&lt;T, R&gt; &#123; // T 表示输入类型，R 表示返回类型 R convert(T input);&#125;Converter&lt;String, Integer&gt; converter = Integer::parseInt; // String 转换为 Integerint result = converter.convert(&quot;123&quot;);System.out.println(result); // 输出: 123 擦除机制擦除就是在编译时，把所有泛型信息删除或者替换为它的上界， 从而使运行时候只能看到原始类型，编译时依然可以保证类型安全。 以下代码可以看出，编译后的泛型参数T被替换为它的上界（如果没有指定，默认为Object） 编译前1234567891011public class Box&lt;T&gt; &#123; private T item; public void set(T item) &#123; this.item = item; &#125; public T get() &#123; return item; &#125;&#125; 编译后的字节码1234567891011public class Box &#123; private Object item; public void set(Object item) &#123; this.item = item; &#125; public Object get() &#123; return item; &#125;&#125; 上界常用于需要从集合中读取元素，且希望类型兼容 用于限制泛型参数可以接收的类型范围， 如果希望传入的类型必须实现某个接口或者继承自某个类时，可以使用 extends 设置上界： 示例代码12345void copy(List&lt;? extends Number&gt; source, List&lt;Number&gt; target) &#123; for (Number num : source) &#123; target.add(num); &#125;&#125; 下界需要向集合中添加元素，且类型兼容 可以确保元素类型是 T 或者其父类，通常用于写的操作，使用 super 设置下界： 示例代码12345void addAll(List&lt;? super Number&gt; dest, List&lt;Number&gt; src) &#123; for (Number num : src) &#123; dest.add(num); // 安全添加到dest &#125;&#125; 方法重载时的局限由于泛型在编译的时候会被擦除（泛型参数被替换为其上界，默认是Object），所以在运行时不同的泛型参数之间的信息会丢失。 123456// 假设写了下面两个方法public void process(List&lt;Integer&gt; list) &#123; ... &#125;public void process(List&lt;String&gt; list) &#123; ... &#125;// 编译器编译后的代码public void process(List list) &#123; ... &#125; 这样会导致两个方法签名完全相同，编译器会报重载冲突错误。 方法签名由方法名称和参数列表（参数类型和顺序）组成，编译器判断两个方法是否重载时，只会比较名称和参数类型 解决方法：PECS原则 当一个泛型容器用于读取数据时，它就是生产者，使用上界通配符：extends，&lt;? extends T&gt; 示例代码12345678910111213141516171819202122232425/** * 计算入参的和，要求入参类型为Number类型或其子类 * * 从集合中读取数据，确保每个元素都是Number或其Number子类。 * 生产者模式，只负责提供数据，不允许添加新的数据。 * @param numbers * @return */public static double sumNumbers(List&lt;? extends Number&gt; numbers) &#123; double sum = 0; for (Number num : numbers) &#123; // 这里可以安全地调用 Number 的方法，比如 doubleValue() sum += num.doubleValue(); &#125; return sum;&#125;public static void main(String[] args) &#123; // 调用示例： List&lt;Integer&gt; intList = Arrays.asList(1, 2, 3); double total = sumNumbers(intList); // 输出结果：应该输出 6.0 System.out.println(&quot;Sum: &quot; + total);&#125; 当一个泛型容器用于写入数据时，它就是消费者，使用下界通配符：super，&lt;? super T&gt; 示例代码123456789101112131415161718192021222324252627282930/** * 计算入参的和，要求入参类型为Integer或其父类 * * 从集合中读取数据，要求是Integer或其父类（Number下的其他类型也可写入） * 消费者模式，允许写入Integer或Number下的其他子类，但是读取时只能为Object * @param list * @return*/public static int addAndSumNumbers(List&lt;? super Integer&gt; list) &#123; // 读取数据：由于参数类型是 &lt;? super Integer&gt;，编译器只能将读取的数据视为 Object // 因此这里需要进行类型检查，并将能转换为 Number 的对象取出其数值参与求和 int sum = 0; for (Object obj : list) &#123; if (obj instanceof Number) &#123; sum += ((Number) obj).intValue(); &#125; &#125; return sum;&#125;public static void main(String[] args) &#123; // 调用示例 List&lt;Number&gt; numberList = new ArrayList&lt;&gt;(); numberList.add(100); numberList.add(200); int total = addAndSumNumbers(numberList); // 输出结果：应该输出 300（100 + 200） System.out.println(&quot;Total sum: &quot; + total);&#125; 反射在运行时动态获取类的元数据（如类名、方法、属性）并操作对象。 优点代码更加灵活，在运行时动态获取和操作类的成员Spring、Mybatis等框架核心实现机制 缺点有性能影响，需要检查类型和安全性安全风险，可能绕过访问权限（private）难以阅读和维护 常见使用场景框架开发： 例如Spring、Mybatis等，使用反射来实现动态代理、依赖注入、AOP等功能工具类： 一些通用工具可能会用到：序列化（将对象转为JSON或XML）、日志工具（通过反射打印对象属性）动态代理： 在需要拦截权限的场景中使用：权限校验、日志记录等（可以直接使用框架提供的功能，Spring的AOP）测试： 单元测试中通过反射访问私有字段和方法，方便测试无法直接访问的内部逻辑 实际开发中，由于性能可可读性问题，通常采用其他方法代替： 直接调用 设计模式（工厂模式、策略模式等） 框架自带功能（Spring AOP、依赖注入等） 反射与泛型注解本质是一个继承了Annotation的特殊接口。 序列化和反序列化 序列化：将数据结构或对象，转换为可以存储或传输的形式（二进制字节流、JSON、XML等） 反序列化：将序列化后的数据，转换为原始数据结构或对象的过程 常见应用场景：远程方法调用RPC之前，需要先序列化，对方接收到序列化的对象后，再反序列化存储到文件、数据库前需要序列化，从文件或数据库中读取对象时需要反序列化 SerializableJDK自带的序列化方式，没有定义任何方法，只是表明这个类可以被序列化为字节流，或者反序列化，在参与交互的对象中，一般要求手动指定序列化号：serialVersionUID。 如果不手动指定，编译器会动态生成默认的serialVersionUID。 SerializableUID的序列化处理通常被static修饰的不会被序列化，而SerializableUID是一个特例： 序列化时被写进二进制流； 反序列化时会对其解析并做一致性判断，以此来验证序列化对象的版本一致性，如果不匹配，反序列化时会抛出异常。 为什么要实现 Serializable1、可以确保只有那些被设计为可序列化的类的对象才能被序列化，保障类型安全 2、它规范了类的行为表示该类的对象可以被序列化，确保序列化行为是合法的 RedisRedis 的客户端（Jedis、Lettuce）默认的序列化机制是：JdkSerializationRedisSerializer，依赖于 Serializable。 可以通过更换序列器，使用 JSON 进行序列化： 12345678910@Configurationpublic class RedisConfig &#123; @Bean public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory factory) &#123; RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;&gt;(); template.setConnectionFactory(factory); template.setDefaultSerializer(new GenericJackson2JsonRedisSerializer()); // JSON 序列化 return template; &#125;&#125; 微服务和 RPC 框架的应用此处以 Springcloud Alibaba 为例，服务间通过 HTTP + Fegin 通信。 需要注意一些特殊场景： 分布式 Session 的序列化器配置 RocketMQ 使用默认的 Serializable 时 I&#x2F;OJava的IO模型对比 概述所有IO流都是从下面四个抽象基类中派生的： InputStream&#x2F;Reader：所有输入流的基类，前者是字节输入流，后者是字符输入流 OutputStream&#x2F;Writer：所有输出流的基类，前者是字节输出流，后者是字符输出流 主要分为字节流和字符流： 特点 字节流 字符流 单位 字节（8 bits） 字符（16 bits，基于编码） 常用类 FileInputStream，FileOutputStream FileReader，FileWriter 编码问题 不处理编码，按字节读取 自动编码解码 适用场景 二进制数据处理（图片、视频等） 文本数据处理（文件、字符串） 缓冲流提高IO效率，减少物理磁盘操作次数。 字节缓冲流：BufferedInputStream、BufferedOutputStream 字符缓冲流：BufferedReader、BufferedWriter NIO特点引入非阻塞IO和多路复用机制，减少线程阻塞，提高并发能力，适合高性能网络编程，有三个核心： Channel：数据传输通道，常用的有FileChannel、SocketChannel Buffer：数据容器，用于读写操作 Selector：多路复用起，用于管理多个Channel 文件读写示例12345678910try (FileChannel fileChannel = new FileInputStream(&quot;input.txt&quot;).getChannel()) &#123; ByteBuffer buffer = ByteBuffer.allocate(1024); while (fileChannel.read(buffer) &gt; 0) &#123; buffer.flip(); while (buffer.hasRemaining()) &#123; System.out.print((char) buffer.get()); &#125; buffer.clear(); &#125;&#125; Lambda表达式由三部分组成：参数、箭头（-&gt;）、表达式，使用示例： 如果无法放在一个表达式中，需要用大括号 &#123;&#125; 包裹： 123456789(String first, String second) -&gt;&#123; if (first.length() &lt; second.length()) &#123; return -1; &#125; else if (first.length() &gt; second.length()) &#123; return 1; &#125; else &#123; return 0; &#125;&#125; 如果没有参数，仍需提供括号： 12345() -&gt; &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.println(i); &#125;&#125; 如果知道参数的类型，可以不用写参数类型： 123String[] planets = new String[]&#123;&quot;Mercury&quot;, &quot;Venus&quot;, &quot;Earth&quot;, &quot;Mars&quot;, &quot;Jupiter&quot;, &quot;Saturn&quot;, &quot;Uranus&quot;, &quot;Neptune&quot;&#125;;Arrays.sort(planets, (first, second) -&gt; first.length() - second.length()); 不允许在某个分支返回值，其他分支不返回： 1(int x) -&gt; &#123; if (x &gt;= 0) return 1; &#125; 总结 特性 示例 说明 基本语法 (a, b) -&gt; a + b 省略 return 省略参数类型 (x, y) -&gt; x * y 编译器自动推断 单个参数省略括号 x -&gt; x * 2 只有一个参数可省略 () 省略 &#123;&#125; (a, b) -&gt; a + b 只有一行代码时可省略 &#123;&#125; 作为匿名类替代 Runnable r = () -&gt; System.out.println(&quot;Run!&quot;); 代码更简洁 Stream API .filter(x -&gt; x &gt; 5).map(String::toUpperCase).collect(...) 操作集合更简洁 方法引用 list.forEach(System.out::println); Lambda 的简化","tags":["面试","Java基础"],"categories":["面试"]},{"title":"Hexo搭建静态博客流程","path":"/posts/51860.html","content":"其他配置使用CloudFlare配置博客搭建（一）| 利用cloudflare加速github博客访问https://qinyu.space/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/%E5%88%A9%E7%94%A8cloudflare%E5%8A%A0%E9%80%9Fgithub%E4%B8%BB%E9%A1%B5%E8%AE%BF%E9%97%AE/ 如何给你的网站套上Cloudflare（以阿里云为例）https://blog.csdn.net/zhyl8157121/article/details/100551592 需要在阿里云上修改DNS服务器 如果提示：重定向次数过多需要在cloudflare中修改 SSL&#x2F;TLS，点击配置、自定义、选择完全并保存。 HEXO 通用语法增加站内文章链接使用相对地址，示例和语法如下： 跳转文章：SQL 优化实践 跳转文章内章节：SQL 优化实践 - 定位 123[SQL 优化实践](/posts/63404.html)[SQL 优化实践 - 定位](/posts/63404.html#定位) 个性化配置左侧边栏背景色设置 打开主题的css文件进行修改： node_modules/hexo-theme-stellar/source/css/_defines/theme.styl1234567_light_root()...--alpha60: hsl($color-background-h, $color-background-s, $color-background-l)_dark_root()...--alpha60: hsl($color-background-h, $color-background-s * 0.5, (100 - $color-background-l) * 2 + 8) 需要修改两个节点下的 –alpha60 属性，要和 –site-bg 的值一致 左侧边栏主导航栏配置修改方式https://github.com/weekdaycare/hexo-theme-stellar/blob/main/source/css/_components/sidebar/menu.styl 新建 menu.styl 文件，路径： node_modules/hexo-theme-stellar/source/css/_components/sidebar/menu.styl 文件内容如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556.nav-area .menudisplay: gridmargin-bottom: 8pxbox-shadow: $boxshadow-inset-blockpadding: 1pxborder: 1px solid var(--block-border)border-radius: $border-barbackground: var(--block)grid-template-columns: repeat(hexo-config(&#x27;menubar.columns&#x27;), 1fr)grid-gap: 2px&amp;::-webkit-scrollbardisplay: none&amp;::-webkit-scrollbar-track-piecebackground: transparent&amp;::-webkit-scrollbar-thumbdisplay: none.nav-itembox-sizing: border-boxwidth: 100%min-height: 38pxfont-size: $fs-15font-weight: 500color: var(--text-p3)text-align: centerposition: relativedisplay: flexflex-direction: columnalign-items: centerjustify-content: centerimg,svgheight: 28pxobject-fit: containfilter: grayscale(100%) brightness(0.8) opacity(0.8)trans1 allspantext-overflow: ellipsisword-break: keep-all&amp;.active, &amp;:hovercolor: var(--text-p1)background: var(--card)trans1 backgroundborder-radius: $border-barbox-shadow: $boxshadow-buttonimg,svgfilter: unset&amp;.active:aftercontent: &#x27;&#x27;position absolutewidth: 16pxheight: 2pxleft: 50%transform: translateX(-50%)border-radius: 2pxbottom: 2pxbackground: currentColor 左侧边栏主导航栏按钮配置 修改或新建 _config.stellar.yml 中 menubar 节点下的内容：_config.stellar.yml123456789101112131415161718menubar: columns: 3 # 一行多少个 items: # 可按照自己需求增加，符合以下格式即可 - id: post theme: &#x27;#1BCDFC&#x27; icon: # solar:documents-bold-duotone title: 博客 url: / - id: shuoshuo theme: &#x27;#3DC550&#x27; icon: # solar:notebook-bookmark-bold-duotone title: 时间线 url: /shuoshuo/ - id: about theme: &#x27;#FA6400&#x27; icon: # solar:planet-bold-duotone title: 关于 url: /about/ 在 source 文件夹下创建与配置文件中 menubar.items.id&#x2F;url 同名的文件夹，并创建 index.md 文件，内容如下：source/about/index.md12345---menu_id: abouttitle: 关于comments: false--- 给超长代码添加滚动条给超长代码添加滚动条https://felicxfoster.github.io/4199909915.html#%E7%BB%99%E8%B6%85%E9%95%BF%E4%BB%A3%E7%A0%81%E5%9D%97%E5%A2%9E%E5%8A%A0%E6%BB%9A%E5%8A%A8%E6%9D%A1 新建 custom.js 文件路径：在node_modules/hexo-theme-stellar/source/js 1234567891011121314151617181920// 给超长代码块增加滚动条function adjustCodeBlockHeight() &#123; document.addEventListener(&quot;DOMContentLoaded&quot;, function () &#123; // 选择所有的.md-text元素 var codeBlocks = document.querySelectorAll(&#x27;.md-text&#x27;); // 遍历每个.md-text元素 codeBlocks.forEach(function (block) &#123; // 检查是否包含.highlight类的子元素，且父元素高度超过500px var highlightBlocks = block.querySelectorAll(&#x27;.highlight&#x27;); highlightBlocks.forEach(function (highlightBlock) &#123; if (highlightBlock.clientHeight &gt; 800) &#123; highlightBlock.style.maxHeight = &#x27;300px&#x27;; highlightBlock.style.overflow = &#x27;auto&#x27;; &#125; &#125;); &#125;); &#125;);&#125;adjustCodeBlockHeight() 在 _config.yml 文件的最后一行添加以下信息 12345inject: script: # 自定义js - &lt;script type=&quot;text/javascript&quot; src=&quot;/js/custom.js?1&quot;&gt;&lt;/script&gt; - &lt;script src=&quot;/js/custom.js?1&quot;&gt;&lt;/script&gt; 文章页面包屑添加信息文章页面包屑添加显示信息https://blog.felicx.eu.org/4199909915.html#%E6%96%87%E7%AB%A0%E9%9D%A2%E5%8C%85%E5%B1%91%E6%98%BE%E7%A4%BA%E5%AD%97%E6%95%B0-%E9%98%85%E8%AF%BB%E6%97%B6%E9%95%BF-%E6%A0%87%E7%AD%BE 在 article_banner.ejs 内添加内容，路径：node_modules/hexo-theme-stellar/layout/_partial/main/navbar/123456789101112131415161718// 3.left.bottomel += partial(&#x27;dateinfo&#x27;)// 新增内容如下：//新增：字数显示|阅读时长显示el += &#x27;&lt;div class=&quot;flex-row&quot; id=&quot;page-words&quot;&gt;&lt;span style=&quot;padding: 4px;&quot;&gt;本文：&#x27; + wordcount(page.content) + &#x27;字&lt;/span&gt;&lt;span class=&quot;sep updated&quot; style=&quot;padding: 4px;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;text updated&quot; style=&quot;padding: 4px;&quot;&gt;阅读时长：&#x27; + min2read(page.content) + &#x27;分&lt;/span&gt;&lt;/div&gt;&#x27;;//新增：标签显示if (page.layout == &quot;post&quot; &amp;&amp; page.tags &amp;&amp; page.tags.length &gt; 0) &#123;el += &#x27;&lt;div class=&quot;flex-row&quot; id=&quot;tag&quot;&gt;&#x27;; // 将标签容器的创建移动到条件内部el += &#x27; &lt;span&gt;&amp;nbsp标签：&lt;/span&gt;&#x27;;el += list_categories(page.tags, &#123;class: &quot;cap breadcrumb&quot;,show_count: false,separator: &#x27;&amp;nbsp; &#x27;,style: &quot;none&quot;&#125;);el += &#x27;&amp;nbsp&lt;/div&gt;&#x27;;&#125; 在 _custom.styl 内的最后添加内容，路径：node_modules/hexo-theme-stellar/source/css/12345678910/* 文章内字数统计&amp;阅读时长 */.bread-nav div#page-words span.sep:before &#123;content: &#x27;|&#x27;;&#125;.bread-nav div#page-words span.updated &#123;visibility: visible;&#125;.bread-nav:hover div#page-words span.updated &#123;visibility: visible;&#125; 在 bread-nav.styl 中修改内容，将hidden修改为visible，路径：node_modules/hexo-theme-stellar/source/css/_components/partial/12345div#post-meta span.sep:before content: &#x27;|&#x27; span.updated visibility: visible 常用写作组件quot 引用Stellar 是迄今为止最好用的主题 1&#123;% quot Stellar 是迄今为止最好用的主题 %&#125; 热门话题 1&#123;% quot 热门话题 icon:hashtag %&#125; 特别引用 1&#123;% quot 特别引用 icon:default %&#125; copy 复制行 1&#123;% copy curl -s https://sh.xaox.cc/install | sh %&#125; $ 1&#123;% copy curl -s https://sh.xaox.cc/install | sh prefix:$ %&#125; 1&#123;% copy git:https xaoxuu.com/hexo-theme-stellar %&#125; box 盒子容器此处为代码块格式，如果需要普通盒子容器，去掉 child:codeblock 即可： 支持的颜色：red，orange，yellow，green，cyan，blue，purple，light，dark test123func test() &#123; // ...&#125; 语法123&#123;% box child:codeblock color:green %&#125; 内容（在代码块声明的语言名称后，用空格分隔标题）&#123;% endbox %&#125; 普通格式的盒子容器： 标题内容 语法123&#123;% box 标题 color:green %&#125; 内容&#123;% endbox %&#125; 代码块代码块左上角为文件名或文件路径： Application.java12345public class App &#123; public static void main(String[] args) &#123; System.out.println(&quot;Hello World!&quot;); &#125;&#125; 语法1234``` 语言 文件名或路径 代码```（此处为占位符需要删除） tabs 分栏容器active：默认显示的标签页，默认为1 align:center：设置默认居中对齐（设置后，box容器按照内容显示大小） box容器代码块内容12let x = 123print(&quot;hello world&quot;) 语法12345678910111213&#123;% tabs active:1 align:center %&#125;&lt;!-- tab 标签页1名称--&gt;&#123;% box %&#125;内容&#123;% endbox %&#125;&lt;!-- tab 标签页2名称--&gt;&#123;% box %&#125;内容&#123;% endbox %&#125;&#123;% endtabs %&#125; grid 网格容器默认为动态列数，即每格最小宽度为240px，页面大于480px会显示2列，大于720px会显示3列，以此类推。 如果在网格内使用box容器，需要注意调整格式 工作为什么不喜欢工作也能很好的完成？工作是别人为你设计好的系统，像是在传送带上。同事、老板会不断推着你向前。 自我目标自发想去做的为什么会拖延？理论上内在动机更足，例如：学习、考证、副业等。但是这些没有人管你要结果，也没有deadline，把自己从舒服的状态抓出来做这件事是很累的，身体会默认选择让自己产生多巴胺的行为。 语法12345678910111213&#123;% grid %&#125;&lt;!-- cell --&gt;**标题**&#123;% box child:codeblock color:green %&#125;内容&#123;% endbox %&#125;&lt;!-- cell --&gt;**标题**&#123;% box child:codeblock color:red %&#125;内容&#123;% endbox %&#125;&#123;% endgrid %&#125; note 备注块、标题备注块、彩色备注块部分颜色：red、orange、amber、yellow、green、cyan、blue、purple 常用：light、dark、warning、error 正文 1&#123;% note color:warning 正文 %&#125; 标题正文 1&#123;% note color:cyan 标题 正文 %&#125; 文本修饰标签 这是 密码 标签 这是 下划线 标签 这是 着重号 标签 这是 波浪线 标签 这是 删除线 标签 这是 上角标 标签 这是 下角标 标签 这是 键盘样式 标签，试一试：⌘ + D 12345678- 这是 &#123;% psw 密码 %&#125; 标签- 这是 &#123;% u 下划线 %&#125; 标签- 这是 &#123;% emp 着重号 %&#125; 标签- 这是 &#123;% wavy 波浪线 %&#125; 标签- 这是 &#123;% del 删除线 %&#125; 标签- 这是 &#123;% sup 上角标 color:red %&#125; 标签- 这是 &#123;% sub 下角标 %&#125; 标签- 这是 &#123;% kbd 键盘样式 %&#125; 标签，试一试：&#123;% kbd ⌘ %&#125; + &#123;% kbd D %&#125; hashtag 标签Stellar Hexo GitHub Gitea 1234&#123;% hashtag Stellar https://xaoxuu.com/wiki/stellar/ %&#125;&#123;% hashtag Hexo https://hexo.io/ %&#125;&#123;% hashtag GitHub https://github.com/xaoxuu/ %&#125;&#123;% hashtag Gitea https://git.xaox.cc/ color:green %&#125;","tags":["Hexo"],"categories":["其他"]},{"title":"敏捷开发流程","path":"/posts/51728.html","content":"需求整理概述 生活中的问题→需求 解决问题的方式（APP、小程序等）→愿景 达到的效果→心动念 需求管理将需求细化，明确应用的功能，整理为需求库 项目规划 明确部分需求（规划项目） 哪些需求可以快速地做出来？ 哪些需求是用户必须使用的？ 讨论规划的可行性 规划好迭代功能和周期 根据第一次迭代规划的需求，进行任务设计和OKR设计，使用Smart指标描述任务 第一次迭代完成后（项目第一个版本） 收集意见整理需求库（需求管理） 从需求库中选择并进行二次规划和迭代（项目规划中的1、2部分） 其他 迭代过程通常需要进行5~6次或更多 上线前需要压测、准备宣传资料","tags":["敏捷开发"],"categories":["Program"]},{"title":"自我使用说明书","path":"/posts/60549.html","content":"心力状态和情绪像天气一样不受控制，解决拖延、心力不足的出发点应该像农民一样，按照不同天气构建不同的应对方式。 很多优秀的人都是拥有一套能够push自己的系统和支撑他们的环境，拖延、行动力不足是因为缺乏这个系统和环境。 不要相信能够使用Passion一直支撑自己，这不符合人的天性，可以使用系统对自己进行客观、标准化的描述。 数据记录（看见自己尚未被觉察的部分）绝大多数人没有想象中了解自己 比如在假期开始前制定的计划，假期结束后有多少能够完成呢？ 缺少无痛启动工作状态的方法和策略 即使知道目标多重要，没有人push的话仍然没有办法完成自己给自己制定的任务。 把心力状态按照最低1星，最高5星这样的状态去计算，制定计划时期的心力状态实际是5星，按照这种是肯定执行不到位的。 所以做计划的时候，要按照自己是3星，甚至是2星的状态去制定，哪怕状态不好的时候也能去推动进展。 但是，很多人不知道，甚至会高估自己做事的3星水平，所以需要使用工具来对自己进行统计： 番茄钟1234567在任务开始和结束时点击，计算自己这次任务时长有多少个番茄钟，如果中途被打断了，使用其他计时器统计被打断的时长，最后在总的时长中减去，这样就可以统计出一天中在这件事上专注了多长时间，用了多少个番茄钟。把每天的番茄钟个数等统计到日记里进行汇总 情绪周期 压迫自己太久后，身体自然会让你变慢下来。这段时间内不需要再逼迫自己赶进度，顺其自然休息一下。 项目管理（尽可能减少内耗）把一件事进行下去并不难，最难的部分在于每天的启动，怎样才能在启动上减少自己的内在阻力呢？ 提高行动的可能性 提高行动概率，降低拖延概率。 不要把重点放在今天怎么没有做？我为什么没有坚持下来这种事情上，而是如果提高下次行动起来的可能性，哪怕行动概率提升10%也是很大的进步。 行动力 &#x3D; 行动的概率 × 时间 工作为什么不喜欢工作也能很好的完成？工作是别人为你设计好的系统，像是在传送带上。同事、老板会不断推着你向前。 自我目标自发想去做的为什么会拖延？理论上内在动机更足，例如：学习、考证、副业等。但是这些没有人管你要结果，也没有deadline，把自己从舒服的状态抓出来做这件事是很累的，身体会默认选择让自己产生多巴胺的行为。 如何设计系统 每天为这个目标工作至少半小时，状态好可以多做一点 尽量简单的开始，状态极差时也能至少完成一分钟的简单工作 目的：每天都能和这件事或者这个方向产生连接，保持一个做事的状态比拥有一大块时间时再启动要容易的多 calender1234567891011使用单独的日历工具安排计划，不要超过3~5天，否则会容易摆烂。如果今天不想做，就把任务拖拽到下一天，并把在今天做的事标注为新任务，拖拽前也要考虑下是卡在哪个任务上，让自己产生了消极情绪，是否任务太难了？如果拆分为多个小任务，能否继续完成？如果还是不行，就拖拽到第二天精力比较好的时候，这时会知道有一个确定的任务在等待完成，会提高推进这件事的可能性。再微小的推进也能极大的刺激自我效能感，因为已经从纠结的心态转变为行动的心态。 系统设计最重要的部分：每天都要和任务产生链接 设计的Tips每次开始工作时进行计时（番茄钟），完成后进行统计归档每个项目刚开始没有头绪时，从问自己问题开始，不断拆解细分。 记录下来，选一些能做的放到3天计划内，如果被卡住了，也要写日记记录下来和自己对话（包括没有心力去执行的时候也是如此）卡住是很正常的，不要等着状态变好再去执行，要学会给自己做心理辅导，不断和自己对话，写着写着大概就能分析出接下来该去做什么了对工作内容进行拆分，并分段计时，查看具体哪个环节花费的时间过长，下次进行改善最重要的是让自己能够轻松启动起来，进入工作状态，把自己哄进工作的轨道，就会自然而然push不需要设计的过于详细，边推进边改动 复盘（需要持续、定期的亲自去做）目的一：定期关照自己的身心状态 是否处于某种惯性中不自知？ 目的二：明确清晰下一步行动 写出下一阶段的任务和目标 周复盘记录本周（实事求是）需要记录本周做了哪些事情计划下一周（通常只做3天的计划） 复盘模板示例回顾目标，评估结果输入输出改善提升身心其他下周的任务关键任务记录项目还能如何拆分？分析原因，总结原因遇到了哪些困难和卡点，做了哪些尝试？可以做哪些改变，可以让下周更好？ 月复盘&#x2F;季度复盘重点不是记录做了什么事情，而是反思和规划这段时间做了哪些项目，遇到什么问题（5Why），自己的想法，有没有改变等使用奥德赛模型询问自己恐惧假设，担心自己某些事情得到不好的结果时，问自己一些问题 复盘模板示例回顾目标，评估结果这个有有哪些产出和改善？自述一下工作状态分析原因，总结原因OKR进度如何？遇到了哪些问题？（至少问自己5个问题）改善的措施思考一下这个月发生的事情，老天爷想告诉你什么信息？规划未来行动奥德赛计划如果我继续现在的到了，五年后的生活该是什么样子？如果我走一条完全不同的道路，五年后的生活该是什么样子？如果我走一条完全不同的道路，不担心钱也不在意别人的眼光，五年后的生活该是什么样子？接下来的12个月，在生活的不同方面，你希望庆祝什么？发现自己有恐惧的事情时再写这个 恐惧假设？当你担心某件事有不好的结果时，试着问自己以下的问题如果我做了这件事，最糟糕的情况是什么？我可以做些什么来防止这些最糟糕的情况发生？如果最糟糕的情况真的发生，我可以做些什么弥补？尝试做这件事的好出是什么？如果我不做这件事情，六个月、一年、三年的生活会是什么样子？ 持续改善 把所有改善措施单独拎出来（Kaizen系统） 一开始很容易做得形式化，沉迷于各种各样的复盘模型，花里胡哨，只要坚持做下去，就会自然地精简掉那些矫情的部分，慢慢接近复盘最核心的意义：让自己定期地记录和反思，在这个过程里关照自己内心的真正需求。 结语如果没有支持帮助你的外在环境和力量，就可以建立一些自我支持的系统，多关照自己的内心，保护好自己的念头 向外寻求帮助是一种方法，自我支持也是一种坚实的力量，佛家讲：每人都是本自具足的 不要专注于目标、系统，而是专注于自己的内心 人的内心和想法很多是受身体和外在环境影响的，当一些因素满足时，有些行为的发生是必然的 10倍比2倍重要https://sobrief.com/zh/books/10x-is-easier-than-2x KISS常用于活动策划落地或者项目执行结束后总结时使用。 K（Keep） 需要保持的：哪些做得好，以后继续保持。 I（Improve） 需要改进的：哪些不理想，后续需要改进。 S（Stop） 需要停止的：哪些不利行为，需要停止。 S（Start） 需要开始的：哪些东西缺失，需要开始执行。 PCDAP（Plan） 计划：确定目标、方针、活动计划。D（Do） 执行：拆解上一步的目标，将其转换为具体行动并且执行。C（Check） 检查：总结执行计划的结果，注意效果，找出问题。A（Action） 行动、处理：对检查的结果进行处理，成功的经验进行肯定并适当标准化；失败的教训加以总结，避免重现。本阶段未解决的问题放到下一个 PDCA 循环。","tags":["个人成长"],"categories":["其他"]},{"title":"MySQL 索引补充","path":"/posts/51857.html","content":"索引类型 按「数据结构」分类：B+tree 索引、Hash系引、全文系引 按「物理存储」分类：聚簇索引（主键索引）、非聚簇索引（二级索引 或 辅助索引） 按「字段特性」分类：主键索引、唯一索引、普通索引、前缀索引 按「字段个数」分类：单列索引、联合索引 普通索引和唯一索引查询过程的区别 普通索引 查询到第一个符合条件的记录后，继续查询，在碰到第一个不符合条件的记录时停止。 唯一索引 查询到第一个符合条件的记录后，停止查询。 更新过程的区别需要分两种情况：要更新的目标页在内存中，或者不在内存中。 目标页在内存中 普通索引：找到 3 到 5 之间的位置，插入记录，结束； 唯一索引：找到 3 到 5 之间的位置，判断是否有冲突，插入记录，结束。 要更新的目标页不在内存中 普通索引：将记录更新到 change buffer 中，结束（后续写回磁盘）； 唯一索引：读取数据页到内存，判断是否有冲突（有冲突会抛出异常），无冲突则插入记录，结束。 结束后的步骤更新操作完成后，修改后的页都需要从内存回写到磁盘，这一过程由 InnoDB 的缓冲池（Buffer Pool）进行管理。 如何选择和使用如果业务可以接受（业务代码保证不会写入重复数据），优先使用普通索引，change buffer 优化效果明显。 如果业务要求数据库对字段进行约束，就只能选择唯一索引。 查询 二者区别不大，仅有一些特殊情况（例如：索引在数据页的末尾，需要读下一页进行判断时，但是MySQL有预读机制）。 插入、更新 尽量选择 普通索引 如果有更新后立即查询的场景，也使用 普通索引，并关闭 change buffer change buffer 和 普通索引 搭配使用时，对大数据量的表和使用机械硬盘存储的优化效果明显 备注 如果碰上大量插入数据慢、内存命中率低时，可以根据索引排查原因。 为什么会选择错误的索引如果在 SQL 语句中没有指定索引，就会由优化器选择，有时本可以执行很快的语句，却因为错误索引导致执行速度变慢。 优化器在选择索引时主要考虑以下几个因素: 是否需要排序 是否使用临时表 扫描行数 如何判断扫描行数扫描行数根据索引的选择性进行判断，索引上不同的值越多，选择性越高，不同值的个数称为基数（cardinality）。 举例表 t 有 100 条记录，在字段 a 上建立索引：如果 a 的值是 1 ~ 100，则 a 有 100 个不同值，基数高（很快可以查出主键ID，再回表查询记录），选择性好；如果 a 的值都是 1，则字段 a 只有一个值，基数很低，选择性很差，a 索引就没有意义。 索引的选择性索引的选择性是指 不重复的索引值（基数） 和 数据表记录总数的比值。 选择性越高，查询效率越高，因为可以过滤更多的行。唯一索引的选择性为 1，是最高的索引选择性，查询效率也是最高的。 可以用以下语句计算 1SELECT COUNT(DISTINCT b)/COUNT(*) FROM t; 基数（cardinality） 如何获取基数？使用 随机采样统计 的方法估算行数；如果逐行进行统计，得到的结果精确，但是代价太高。 自动触发索引统计 统计信息会随着记录变更而修改，当变更行数超过 1&#x2F;m 时，就会自动重新统计。 例如：表 t 有 100 行数据，变更超过 10 行时，就会自动触发重新统计。 基数的计算过程选择 N 个数据页，统计数据页上的不同值，得到这些不同值的平均值，再乘索引页面数。选择 3 个数据页（page1、page2、page3），假设有 10 个索引页，数据页的不同值分别为，page1：10、page2：20、page3：15；则索引基数为：基数 &#x3D; (10 + 20 + 15)&#x2F;3 * 10 &#x3D; 150 在 MySQL 中，有两种存储索引统计的方式，可以通过设置参数 innodb_stats_persistent 的值来选择：N：数据页的数量；M：变更行数的比例。 设置为 on 的时候，表示统计信息会持久化存储。这时，默认的 N 是 20，M 是 10。 设置为 off 的时候，表示统计信息只存储在内存中。这时，默认的 N 是 8，M 是 16。 选择异常时如何处理强制指定使用 force index 强制指定索引，例如： 1SELECT * FROM t force index(a) where a between 100 and 20000 order by b; 使用该方法时，MySQL 将不会评估其他索引的执行效率，将会直接使用指定的索引。 但是这种方法很不方便，如果索引名称变更，则 sql 语句也需要修改；如果迁移数据库，也可能不支持该方法。 引导优化器使用正确的索引这个方法也需要修改语句，添加其他条件引导优化器，例如： 1234-- 修改前SELECT * FROM t force index(a) where a between 100 and 2000 and b between 3000 and 5000 order by b;--修改后SELECT * FROM t force index(a) where a between 100 and 2000 and b between 3000 and 5000 order by b, a; 修改前使用 b 索引，可以避免重新排序，只要遍历，所以优化器采用了 b 索引。 修改后使用 b, a 两字段进行排序，意味着需要将两个索引都需要排序，这时候，扫描行数就成为选择索引的关键条件。 这种方法也不太好用，不仅没有通用性，还难以维护。 新建或者删除索引既然当前索引不合适，可以选择新建一个索引，提供给优化器做选择；或者删除掉误用或者没有必要的索引，帮助优化器排除错误选项。 这种方法简单粗暴好用。 索引的使用场景 字段有唯一性限制的，比如：ID、商品编码 经常用于 WHERE 查询的字段 经常用于 GROUP BY 和 ORDER BY 的字段 索引失效的情况 使用左或者左右模糊查询时（LIKE %xx、LIKE %xx%），因为索引树是按照 索引值 有序排列的，只能根据前缀进行比较 对索引列使用函数，因为索引保存的是字段值，而不是函数计算后的值 对索引列使用表达式，原因同上 一些特例12345-- 参与了运算，不走索引SELECT * FROM user WHERE id + 1 = 10;-- 是运算后的值，走索引SELECT * FROM user WHERE id = 10 - 1; 数据类型有隐式转换，比如：字段类型是 varchar，使用整型输入，不会走索引；字段类型是整型，输入了 varchar，会走索引 一些特例 《mysql45讲》中提到，数据类型自动转换规则是：遇到字符串和数字比较时，会自动把字符串转为数字，然后进行比较 可以用 SELECT &#39;10&#39; &gt; 9; 进行测试12345-- phone 类型为 varcharSELECT * FROM user WHERE phone = 13011112222;-- id 类型为 整型SELECT * FROM user WHERE id = &#x27;1&#x27;; 不满足最左前缀原则 因为索引是 B+ Tree 结构，在数据页中顺序排列，所以不能跳过第一个索引 WHERE 查询中使用了 OR，因为 OR 只需要满足二者其中之一即可，只有一个条件列是索引的话毫无意义。只要把两个条件列都设置为索引列就可以解决。 使用 LIKE 一定会失效吗？查询语句如下，在这两种情况中，哪些能触发索引，哪些不能： 12345678-- 1SELECT * FROM user WHERE name LIKE &#x27;张三&#x27;;-- 2SELECT * FROM user WHERE name LIKE &#x27;张三%&#x27;;-- 3SELECT * FROM user WHERE name LIKE &#x27;%张三&#x27;;-- 4SELECT * FROM user WHERE name LIKE &#x27;%张三%&#x27;; 情况一，表中有多个字段，其中 id 字段是主键索引， name 字段有索引，其余字段无索引： 123456789101112131415CREATE TABLE `user` ( `id` INT NOT NULL AUTO_INCREMENT, `name` VARCHAR(255) NOT NULL, `age` INT DEFAULT NULL, `address` VARCHAR(100) DEFAULT &#x27;未知&#x27;, PRIMARY KEY (`id`), INDEX `idx_name` (`name`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;INSERT INTO `user` (`name`, `age`, `address`) VALUES(&#x27;张三&#x27;, 25, &#x27;北京市&#x27;), (&#x27;李四&#x27;, 30, &#x27;上海市&#x27;),(&#x27;王五&#x27;, 28, &#x27;广州市&#x27;), (&#x27;赵六&#x27;, 35, &#x27;深圳市&#x27;),(&#x27;陈七&#x27;, 22, &#x27;杭州市&#x27;), (&#x27;刘八&#x27;, 40, &#x27;成都市&#x27;),(&#x27;孙九&#x27;, 27, &#x27;武汉市&#x27;), (&#x27;周十&#x27;, 33, &#x27;南京市&#x27;),(&#x27;吴十一&#x27;, 29, &#x27;西安市&#x27;), (&#x27;郑十二&#x27;, 31, &#x27;重庆市&#x27;); 使用 EXPLAIN 后会发现，语句1、2触发了索引；3、4没有触发。 情况二，表中只有两个字段，id 字段是主键索引， name 字段有索引： 123456789CREATE TABLE `user` ( `id` INT NOT NULL AUTO_INCREMENT, `name` VARCHAR(255) NOT NULL, PRIMARY KEY (`id`), INDEX `idx_name` (`name`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;INSERT INTO `user` (`name`) VALUES(&#x27;张三&#x27;),(&#x27;李四&#x27;),(&#x27;王五&#x27;),(&#x27;赵六&#x27;),(&#x27;陈七&#x27;),(&#x27;刘八&#x27;),(&#x27;孙九&#x27;),(&#x27;周十&#x27;),(&#x27;吴十一&#x27;),(&#x27;郑十二&#x27;); 使用 EXPLAIN 后会发现，以上语句全部触发了索引，为什么呢？ 覆盖索引可以看到情况二的 user 表中，两个字段全部都是索引列。所以使用：SELECT * 查询时，就相当于 SELECT id, name，而查询的数据也都在非聚簇索引中。也就是查询非聚簇索引树就能得到全部的查询结果，也就是覆盖索引。 同时还会在 EXPLAIN 的结果中发现：语句1、2的 type 是 range，说明使用范围查询，通过比较的方式快速定位到了数据行；语句3、4的 type 是 index，代表通过遍历非聚簇索引树查询到了数据。 为什么会扫描非聚簇索引树，而不是聚簇索引树呢？非聚簇索引树中，只保存了 索引列 和 主键值；聚簇索引树中保存了：主键值、事物ID、事物和MVCC回滚指针等信息，以及所有的剩余列。再加上这里使用了覆盖索引不需要回表，优化器认为直接遍历非聚簇索引树要比回表的成本小，所以就选择了遍历的方式。 不满足最左前缀一定会失效吗？12345678CREATE TABLE `user` ( `id` INT NOT NULL AUTO_INCREMENT, `name` VARCHAR(255) NOT NULL, `age` INT DEFAULT NULL, `address` VARCHAR(100) DEFAULT &#x27;未知&#x27;, PRIMARY KEY (`id`), INDEX `idx_name_age_address` (`name`, `age`, `address`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 参考：不满足最左前缀一定会失效吗？ 这种情况下，表中的字段全部都有索引，即使不满足最左前缀，也会遍历非聚簇索引树查询。 如何优化一条sql 分析需求，保证逻辑清晰，同时去掉无用的返回列，避免 SELECT * 这种情况出现 使用 EXPLAIN 分析语句的执行情况 索引优化 索引是否缺失？是否可以通过新建索引覆盖查询？ 是否触发了索引？（不满足最左前缀、索引列参与了运算或函数等） 是否过度索引？ 优化查询语句 避免全表扫描，是否走了索引？ 避免子查询嵌套，使用 JOIN 等（使用了的话，可以小表作为结果集驱动大表进行优化） 减少数据量 进行分表 在实际查询前，先过滤一遍目标表 如何创建高性能的索引查询时使用独立列独立的列是指：索引列不能作为表达式的一部分，也不能是函数的参数。 索引列参与运算时 正常使用索引 使用 explan 命令很容易看出，作为表达式的一部分时，没有使用索引。 使用中应该简化 where 条件，始终将索引列单独放在比较符号的一边。 前缀索引有时需要在很长的字符串上建立索引，例如：邮箱、身份证号等，字符串长度过长会影响索引速度。 可以索引开始的部分字符，降低索引长度，提高效率，但是也会降低索引的选择性（选择性可以参考本文中 索引的选择性）。 一般情况下，某个列的前缀选择性可以满足查询性能的。对于 BLOB、TEXT、很长的 VARCHAR 列，必须使用前缀索引。 举例使用邮箱登录的系统中建立用户表，id 为自增主键，email 列上也需要建立索引。如果使用整个字符串，则占用的空间更多；如果使用前缀索引，则扫描次数更多。12345-- 该索引包含每个记录 email 字段的全部字符串alter table user_info add index index1(email);-- 该索引包含每个记录 email 字段的前 6 个字符alter table user_info add index index2(email(6));如何确定前缀索引的的长度呢？需要关注索引的选择性，选择性越高，则重复的值越少，可以参考本文中的：索引的选择性。12345SELECT COUNT(DISTINCT left(email, 4))/COUNT(*), COUNT(DISTINCT left(email, 5))/COUNT(*), COUNT(DISTINCT left(email, 6))/COUNT(*) FROM t;执行顺序： 1SELECT username, email FROM user_info WHERE email = &#x27;12345678@gmail.com&#x27;;index1（即 email 整个字符串的索引结构）index1 索引树找到满足索引值为 &#49;&#50;&#x33;&#x34;&#53;&#x36;&#x37;&#56;&#x40;&#x67;&#x6d;&#97;&#x69;&#x6c;&#46;&#x63;&#111;&#x6d; 的记录，并获取主键 id；为了获取 username 的值，需要用 id 回主键表查询记录，将这行记录加入结果集；因为是普通索引，需要取 index1 索引树上的下一条记录，发现条件不满足 &#49;&#x32;&#x33;&#52;&#x35;&#x36;&#55;&#56;&#x40;&#x67;&#x6d;&#97;&#105;&#x6c;&#46;&#99;&#111;&#109;，循环结束。 email索引结构图index2（即 email(6) 索引结构）在 index2 索引树上查找满足 123456 的结果，id 为1；回主键表，查询 id &#x3D; 1 的记录，验证 email 是否为 &#49;&#x32;&#51;&#52;&#x35;&#54;&#55;&#x38;&#64;&#x67;&#x6d;&#x61;&#105;&#x6c;&#x2e;&#x63;&#111;&#x6d;，如果不是则弃用，继续循环；假设 index2 查询到下一条记录的索引仍是 12346，则取出 id，回表，校验 email，结果一致时加入结果集；重复上述循环，直到 index2 上取得索引不是 123456，返回结果集。 email(6)索引结构图这个过程可以看出，前缀索引的扫描次数要多于普通索引。优点：如果能控制好前缀索引的长度，可以做到既省空间、又不额外增加查询成本。缺点：增加扫描次数，不能使用覆盖索引。 如何使用 EXPLAINEXPLAIN 是MySQL中分析执行计划的工具，帮助理解如何执行查询，从而优化查询性能。 执行后，会返回以下信息： 字段名称 描述 id 查询的标识符，表示执行顺序（id相同的优先执行，id大的后执行）。 select_type 查询类型：SIMPLE 简单查询，PRIMARY 主查询，SUBQUERY 子查询，DERIVED 派生表。 table 当前操作涉及的表名，如果是子查询，则显示则查询的别名。 type 查询使用的连接类型，反应查询效率，从高到低：system 系统表，const 主键&#x2F;唯一索引精准匹配，eq_ref 关联表主键&#x2F;唯一索引一对一匹配，ref 非唯一索引等值匹配，range 索引范围查询（如BETWEEN&#x2F;&gt;,&lt;），index 全索引扫描，ALL 全表扫描 possible_keys 可能使用的索引（如果为空，表示没有可用索引）。 key 实际使用的索引（如果为空，表示未使用索引）。 key_len 索引使用的长度（越短越好，通常与字段类型相关）。 ref 与索引匹配的列或常量（如 const 表示常量匹配）。 rows 预计扫描的行数（数值越小越好）。 filtered 表示查询条件过滤后剩余的行数的百分比。这个值越接近 100%，说明查询条件的过滤效果越好。 Extra 额外信息： Using where，使用 WHERE 语句过滤结果、Using index，查询使用了覆盖索引，无需回表，Using temporary，需要用临时表处理，常见于分组、排序，Using filesort，需要对结果用文件排序 。 示例建表123456CREATE TABLE `user` ( `id` int NOT NULL AUTO_INCREMENT, `name` varchar(255) NOT NULL, PRIMARY KEY (`id`), KEY `idx_name` (`name`)) ENGINE=InnoDB AUTO_INCREMENT=11 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci 使用EXPLAIN1EXPLAIN SELECT * FROM user WHERE name LIKE &#x27;张三%&#x27;; 查询结果1&#x2F;2：查询基础信息 id select_type table partitions type 1 SIMPLE user range 查询结果2&#x2F;2：索引与执行统计 possible_keys key key_len ref rows filtered Extra idx_name idx_name 1022 1 100.00 Using where; Using index 建表语句123456789CREATE TABLE `t` ( `id` int(11) NOT NULL, `a` int(11) DEFAULT NULL, `b` int(11) DEFAULT NULL, PRIMARY KEY (`id`), KEY `a` (`a`), KEY `b` (`b`)) ENGINE=InnoDB； 123456789101112delimiter ;;create procedure idata()begin declare i int; set i=1; while(i&lt;=100000)do insert into t values(i, i, i); set i=i+1; end while;end;;delimiter ;call idata();","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL 常用","path":"/posts/26960.html","content":"MySQL索引重建索引MySQL 5.7 常用的重建索引方式有以下三种： Dump and Reload ALTER TABLE REPAIR TABLE 详情参考官方或者中文文档的 2.11.12 Rebuilding or Repairing Tables or Indexes。 Dump and Reload使用的是 导出、重新导入 的方法重建表，同时索引也会被重置： 重建某个表，需要指定表名 123mysqldump db_name table1 &gt; dump.sqlmysql db_name &lt; dump.sql 重建单个数据库中全部表 123mysqldump db_name &gt; dump.sqlmysql db_name &lt; dump.sql 重建全部数据库中的全部表 123mysqldump --all-database &gt; dump.sqlmysql &lt; dump.sql ALTER TABLE1ALTER TABLE tbl_user_info ENGINE = INNODB; 通过修改存储引擎的方法重建索引，本质和 重建表 没有区别： 在执行命令前，查询表创建时间 1234567SELECT table_name, create_time FROM information_schema.TABLES WHERE table_name = &#x27;tbl_user_info&#x27;; 查询结果如下： table_name create_time tbl_user_info 2021-08-18 09:21:31 执行命令后再次查询 1ALTER TABLE tbl_user_info ENGINE = INNODB; 查询结果如下： table_name create_time tbl_user_info 2021-08-18 10:45:30 因为索引创建时间并不可能比表创建时间早，因此该方式可以成功重建索引。 REPAIR TABLE该方法只能修复引擎为 MyISAM, ARCHIVE, CSV 的表。 1REPAIR table1 查看索引基数索引基数（cardinality），表示一个索引上不同值的个数。 举例假设表 t 有 1w 条记录，在字段 a 上建了索引。如果 a 全都是 1，那 1w 条记录的 a 都是相同的，索引基数很低（只有1）。如果 a 从 1 ~ 1w，每个值都不同，索引基数很高（1w）。 1show index FROM TABLE_NAME 重新统计索引信息重新填统计索引信息命令，解决采样导致的扫描行数出错的问题。 如果发现 explan 命令结果的 rows 值和实际情况相差较大，可以使用该命令重置。 1analyze TABLE TABLE_NAME 常用查询时间相关DATE_FORMAT() 函数参数 常用的查询时间函数为 CURDATE() 只能查询当天开始的时间点，默认格式为 2021-08-18 (%Y-%m-%d)。 可以使用 DATE_FORMAT() 函数格式化，例如： DATE_FORMAT(CURDATE(),&#39;%Y-%m-%d %H:%i:%s&#39;)，查询结果为 2021-08-18 00:00:00。 NOW() 查询的是当前时间点，默认格式为 2021-08-18 11:26:06 (%Y-%m-%d %H:%i:%s)。 当天 当前时间123SELECT NOW(); -- 查询结果 2021-08-18 11:26:06SELECT CURDATE(); -- 查询结果 2021-08-18 当天 0 点1SELECT DATE_FORMAT(CURDATE(),&#x27;%Y-%m-%d %H:%i:%s&#x27;); -- 查询结果 2021-08-18 00:00:00 当天 9 点1SELECT DATE_ADD(CURDATE(), INTERVAL 9 HOUR); -- 查询结果 2021-08-18 09:00:00 日、月、年这里不能使用 CURDATE() - 1 的方式查询，在月末会出现错误，例如：7月31日使用，得到的结果为 8月0日。 日1234567891011-- 前一天SELECT date_sub( curdate( ), INTERVAL 1 DAY ); -- 查询结果 2021-08-17-- 当天SELECT CURDATE(); -- 查询结果 2021-08-18-- 后一天SELECT date_sub( curdate( ), INTERVAL -1 DAY ); -- 查询结果 2021-08-19-- 查询七天之前的数据SELECT * FROM 表名 WHERE DATE_ADD( createdate, INTERVAL 7 DAY ) &lt; NOW( ); 月12345-- 前一月SELECT date_sub( curdate( ), INTERVAL 1 MONTH ); -- 查询结果 2021-07-18-- 后一月SELECT date_sub( curdate( ), INTERVAL -1 MONTH ); -- 查询结果 2021-09-18 年12345-- 前一年SELECT date_sub( curdate( ), INTERVAL 1 YEAR ); -- 查询结果 2020-08-18-- 后一年SELECT date_sub( curdate( ), INTERVAL - 1 YEAR ); -- 查询结果 2022-08-18 指定日期 1234567SELECT date_sub( &#x27;2017-08-01&#x27;, INTERVAL 0 DAY ); -- 查询结果 2017-08-01SELECT date_sub( &#x27;2017-08-01&#x27;, INTERVAL 1 DAY ); -- 查询结果 2017-07-31SELECT date_sub( &#x27;2017-08-01&#x27;, INTERVAL -1 DAY ); -- 查询结果 2017-08-02SELECT date_sub( &#x27;2017-07-31&#x27;, INTERVAL -1 DAY ); -- 查询结果 2017-08-01 查询结果拼接字段 1SELECT CONCAT(userName,&#x27;(&#x27;,userAge,&#x27;)&#x27;) FROM tbl_user_info; JOIN自联结（self join）自联结作为外部语句，用来一袋从相同表中检索数据使用的子查询语句。 虽然结果相同，但是许多 DBMS 处理联结的速度要比子查询快。 实际操作中应该试一下两种方法，以确定哪种方法性能更好。 例如：需要获取用户信息表中，和张三在同一个公司的全部用户信息 使用子查询 12SELECT * FROM user_info WHERE company = (SELECT company FROM user_info WHERE username = &#x27;张三&#x27;); 使用自联结 123SELECT * FROM user_info u1, user_info u2WHERE u1.company = u2.company AND u2.username = &#x27;张三&#x27;; 视图视图是虚拟的表，只包含使用时动态检索数据的查询。 常见用途： 重用 SQL 语句 简化复杂的 SQL 操作 使用表的一部分而不是整个表 保护数据，可以指定用户访问表的特定部分权限 更改数据格式和表示 使用规则： 名称必须唯一，不能和其他视图或者表重复 视图的数量没有限制 可以嵌套其他视图 不能索引，也不能有关联的触发器或默认值 批量插入数据脚本123456789101112-- TRUNCATE TABLE log_info; #清空表数据DROP PROCEDURE IF EXISTS proc_init_data; -- 如果存在此存储过程则删掉DELIMITER $ -- 使用delimiter后，将不把分号当做语句结束，会将该段整个提交CREATE PROCEDURE proc_init_data()BEGIN DECLARE i INT DEFAULT 1; WHILE i&lt;=100 DO INSERT INTO log_info (`userid`, time) VALUES (i, CURDATE()); SET i = i+1; END WHILE;END $CALL proc_init_data();","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL实战 基础篇（五）","path":"/posts/7044.html","content":"该系列是极客时间林晓斌的 MySQL实战45讲 课程笔记。 背景知识为了更方便阅读下文，这里先梳理下相关的背景知识。 ACID：原子性（atomicity)、一致性（consistency)、隔离性（isolation）、持久性（durability）。 隔离级别 —— RC：读提交，只能读取已经提交的数据。 隔离级别 —— RR：可重复读，同一个事务内的查询和事务开始一致。 两阶段锁：InnoDB 的事务中，行锁在需要的时候加上，事务结束时释放。（而不是不需要时立刻释放）。 MVCC：Multi-Version Concurrency Control，即多版本并发控制，提高数据库并发性能，用更好的方式去处理读-写冲突，即使有读写冲突时，也能做到不加锁，非阻塞并发读。 乐观锁：在更新数据时，认为其他线程争抢这个共享变量的概率很小，所以更新时不会对其加锁，但是在正式更新前会根据版本信息检查其是否被其他线程修改过，如果被修改则会提示用户，如果没有修改则正常更新。 悲观锁：在更新数据时，认为必定会和其他线程产生冲突，所以在数据处理的整个过程中加锁，保证统一时间只能有一个线程访问该数据，具有排他性。 CAS：Compare and Swap 的缩写，即比较并替换。根据三个核心参数实现：版本号 A、共享变量的预期值 B、新值 C。 如果该版本号 A 现在的变量值等于 B，则将该位置的变量值更新为 C。 事务的启动方式： 第一种： 在执行到之后第一个操作 InnoDB 表的语句时，事务才真正启动（一致性视图在第一个快照读语句创建）： 123begin/start transaction;···commit; 第二种： 立刻启动一个事务（一致性视图在执行时就创建）： 1start transaction with consistent snapshot; 两个视图的概念： view： 用查询语句定义的虚拟表，调用时执行查询语句并生成结果。 一致性视图（consistent read view）： 没有物理结构，用于 RC（提交读） 和 RR（可重复读） 隔离级别的实现。 举例一一1234567CREATE TABLE `t` (\t`id` int(11) NOT NULL,\t`k` int(11) DEFAULT NULL,\tPRIMARY KEY (`id`)) ENGINE = InnoDB;INSERT INTO t (id, k) VALUES (1, 1), (2, 2); 事务 A、B、C的启动顺序 事务的启动和提交点都已经标注出来了。其中事务 C 没有显示启动、提交事务，是因为 update 本身就是一个事务，会在完成时自动提交。 那么，问题来了：事务 A、B 查询到的 k 值是多少呢？ 二1234567CREATE TABLE `t` (\t`id` int(11) NOT NULL,\t`c` int(11) DEFAULT NULL,\tPRIMARY KEY (`id`)) ENGINE = InnoDB;INSERT INTO t (id, c) VALUES (1, 1), (2, 2), (3, 3), (4, 4); 以这套表结构和初始化语句为环境，事务隔离级别是 RR，现在要把所有 字段值 c 和 id 值相等的行 的 c 值清零。 那么，问题来了：在哪种情况下，无法修改 c 的值？ MVCC实现原理主要由三部分组成：隐式字段、undo log、Read View（这里只是大概介绍）。 记录状态变更示意图 隐式字段 DB_TRX_ID 记录 创建 或 最后一次修改该记录的事务ID。 DB_ROLL_PTR 回滚指针，配合 undo 日志，指向这条记录的上一个版本。 DB_ROW_ID 隐藏的自增主键，数据库默认为该记录生成的唯一隐式主键。 undo log主要分为两种： insert undo log 事务在 insert 时产生的 undo log。只在回滚时需要；事务提交后可被立即丢弃。 update undo log 在 update 或 delete 时产生的 undo log。在回滚、快照读时需要。只有在回滚或者快照读不涉及该日志时，对应的日志会被 purge 统一清除。 对MVCC 有帮助的是 update undo log。 Read ViewRead View 就是事务进行 快照读 时产生的 读视图（Read View）。 在该事务执行快照的一刻，生成当前数据库系统的一个快照，记录并维护当前活跃事务的ID。 当前活跃事务的 ID 就是事务开始时被分配的 ID，具有唯一性且严格递增。 Read View 具有三个属性： trx_list（名字随便取的） 用来保存 Read View 生成时，系统内活跃的事务 ID。 up_limit_id 是数组中事务最小的 ID。 low_limit_id Read View 生成时，系统尚未分配的下一个事务 ID，即已出现过的事务 ID 最大值 + 1。 🌟事务可见性的判断 DB_TRX_ID &lt; up_limit_id ？ 如果小于，则当前事务可以看到 DB_TRX_ID 所在的记录； 如果大于等于，进入下一个判断。 DB_TRX_ID &gt;&#x3D; low_limit_id ？ 如果大于等于，则说明 DB_TRX_ID 所在的记录是 Read View 生成后出现的，对当前事务不可见； 如果小于，进入下一个判断。 DB_TRX_ID ⊆ trx_list ？ 如果在该数组中，则表示生成 Read View 时，该事务仍然活跃，没有提交，修改的数据对于当前事务不可见； 如果不在数组中，则说明这个事务在生成 Read View 前已经提交，当前事务可见。 举例二先声明条件： 假设事务 A 开始前，系统中只有一个活跃的事务，DB_TRX_ID &#x3D; 99 事务 A、B、C 的 DB_TRX_ID 分别为：100、101、102 在三个事务开始前，ID &#x3D; 1、K &#x3D; 1 这一行的 DB_TRX_ID &#x3D; 90（创建该记录时的事务 ID） 一致性读示意图 可以根据以上内容，重新分析下第一个例子： 因为事务 C 使用了 update 语句直接提交，所以 第一个有效更新的是事务 C k &#x3D; 2，DB_TRX_ID &#x3D; 102 使用了 update 更新数据，所以第二个有效更新的是事务 B k &#x3D; 3，DB_TRX_ID &#x3D; 101（参考 2.1.1 1.DB_TRX_ID） 但是事务 A 不可能查询到 k &#x3D; 3，否则会变成脏读。 事务 A 的查询流程（从当前版本读起） 当前最新版本 k &#x3D; 3，DB_TRX_ID &#x3D; 101 （1） DB_TRX_ID &#x3D; 101，大于数组 trx_list 中最小的事务 ID，即 up_limit_id &#x3D; 99。 进行下一步判断 （2） DB_TRX_ID &#x3D; 101 ，等于 low_limit_id &#x3D; 101（事务 A 生成时的 ID + 1，即 100 + 1） 所以当前版本不可见 历史版本1 k &#x3D; 2，DB_TRX_ID &#x3D; 102 （1） DB_TRX_ID &#x3D; 102，大于数组 trx_list 中最小的事务 ID，即 up_limit_id &#x3D; 99。 进行下一步判断 （2） DB_TRX_ID &#x3D; 102 ，等于 low_limit_id &#x3D; 101（事务 A 生成时的 ID + 1，即 100 + 1） 所以历史版本1不可见 历史版本2 k &#x3D; 1，DB_TRX_ID &#x3D; 90 （1） DB_TRX_ID &#x3D; 90，小于数组 trx_list 中最小的事务 ID，即 up_limit_id &#x3D; 99。 所以历史版本2可见 一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况： 版本未提交，不可见； 版本已提交，但是是在视图创建后提交的，不可见； 版本已提交，而且是在视图创建前提交的，可见。按照这个方法分析： DB_TRX_ID &#x3D; 101，属于情况1，不可见； DB_TRX_ID &#x3D; 102，属于情况2，不可见； DB_TRX_ID &#x3D; 90，属于情况3，可见。 总结一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：版本未提交，不可见；版本已提交，但是是在视图创建后提交的，不可见；版本已提交，而且是在视图创建前提交的，可见。按照这个方法分析：DB_TRX_ID &#x3D; 101，属于情况1，不可见；DB_TRX_ID &#x3D; 102，属于情况2，不可见；DB_TRX_ID &#x3D; 90，属于情况3，可见。 即使这行记录被修改过，但是事务 A 不论在什么时候查询，结果都是一致的，称为一致性读。 当前读如果按照 3.1 判断顺序对事务 B 进行判断，就会发现 k 的结果不一致。 这里要说明的是：更新数据都是先读后写，只能读记录的最新版本，同时还要保证其他并发事务不能修改当前记录，会对读取的记录加锁，是悲观锁的实现。 所以，事务 B 的 k &#x3D; k + 1 的操作，是在 k &#x3D; 2 的基础上。 在 MySQL 中，以下这些操作都是一种当前读： SELECT LOCK IN shaer mode(共享锁)； SELECT … FOR UPDATE； UPDATE； INSERT； DELETE(排他锁)。 另一个例子这里假设事务 C 没有马上提交，而事务 B 先发起了更新，查询结果会是什么呢？（这里的事务编号仍然按照 🌰 中的条件） 另一个🌰 如图所示，事务 C 更新完成后还没有提交时，事务 B 就发起了更新，虽然没有提交，但是当前版本已经被改变了： k &#x3D; 2，DB_TRX_ID &#x3D; 102。 这时候就需要用到 两阶段锁： 事务 C 没有提交，也就表示写锁未释放； 事务 B 是当前读，必须为最新版本，而且必须加锁； 所以只能等待事务 C 释放才可以继续进行当前读。 举例三如果在 可重复读(RR) 下，使用 CAS 式更新，这种问题是常见的，也就是所谓的 乐观锁。 例如，有一个应用版本表，在事务 A 中根据 version 字段更新记录： 1UPDATE app_version SET info = &quot;info&quot; WHERE id = &#x27;12345&#x27; AND version = &#x27;5.1&#x27;; 如果 version 字段被另一个事务 B 先更新了，则这个事务中会更新失败，DB_TRX_ID 没有变成事务 A 的 ID。 且在事务 A 中查询出的结果仍为旧值，就会出现：提交成功却没有更新数据的情况。 解决方案：每次 CAS 更新后，不论是否成功都关闭该事务，如果失败就重新启动一个事务进行查询更新。 RC和RR是怎么实现的？可重复读 RR 的核心就是 一致性读，事务更新时只能使用当前读，如果行锁被其他事务占用，就进入锁等待。 读提交 RC 与 可重复读 类似，都是用 一致性读（consistent read） 实现的 二者的区别在于，一致性视图的创建时机不同： 可重复读 只在事务开始时创建，之后该事务的查询共用这一个视图 读提交 每个语句执行前都会生成一个新的视图 总结 RR：查询时，只承认事务启动前提交的数据 RC：查询时，只承认语句启动前提交的数据 当前读：总是读取已提交的最新版本","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL实战 基础篇（四）","path":"/posts/55610.html","content":"该系列是极客时间林晓斌的 MySQL实战45讲 课程笔记。 简介MySQL 的锁大概分为三种：全局锁、表级锁、行锁。 行锁是在引擎层，由各个引擎实现的： MyISAM 引擎不支持行锁； InnoDB 支持行锁。 全局锁MySQL 提供了一个对整个数据库实例加锁的命令，可以使整个数据库处于只读的状态，通常在做全库逻辑备份时使用： 12345-- 全局锁命令Flush tables with read lock (FTWRL)-- 解除全局锁（或者退出执行加锁命令的窗口）unlock tables 执行改命令后，以下语句会被阻塞： 数据更新语句（增删改）； 数据定义语句（建表、修改表结构等）； 更新类事务的提交语句。 在主从数据库中使用该命令备份，容易碰到以下问题： 主库备份：备份期间不能更新数据，业务基本上停摆： 从库备份：如果是读写分类的，从库在备份期间不能执行主库传来的 binlog，造成主从延迟。 常见问题 备份不加锁会怎样？ 备份系统备份的数据和原数据库的逻辑视图是不一致的，也就是前后数据不一致。 官方有自带的逻辑备份工具，为什么还需要 FTWRL 呢？ 官方自带的 mysqldump 可以用来备份，使用参数 –single-transaction 时，会在导出数据前开启一个事务，保证视图一致性。 由于 MVCC 的支持，整个过程中还可以正常更新数据。 但是，MyISAM 引擎不支持事务，所以要用 FTWRL。 为什么不使用 set global read_only&#x3D;true 的方式呢？ 设置全库只读时不使用该属性主要有两个原因： 有些系统中，read_only 属性被用作其他逻辑。例如：判断是主库还是备库。 如果将 read_only 设置为 true，在发生异常后到恢复正常前的这段时间，整个库将处于只读的状态，风险较高；如果使用 FTWRL 时发生异常，MySQL 会自动释放全局锁，整个库恢复至正常可读写的状态。 表级锁表级锁通常分为两种：表锁和元数据锁。 表锁语法是： 1lock tables TABLE read/write; 与 FTWRL 类似，可以使用 unlock TABLE 主动解锁，也可以在客户端断开连接时自动解锁。 不仅会限制其他线程的读写，也限制了当前线程的操作对象。 例如：在线程A中执行了该命令， 1lock table table1 read, table2 write; 其他线程的 写table1、读写table2 的操作会被禁止； 线程A只能执行 读table1、读写table2。 对于 InnoDB 这种支持行锁的引擎，一般很少用到 lock tables 命令控制并发，整个表都被锁住的影响太大了。 元数据锁元数据锁 MDL（metadata lock)，不需要显式使用，每次访问表时会自动添加，在 MySQL 5.5 版本加入。 增删改查时，为该表加 MDL读锁 读锁之间不互斥，所以可以有多个线程同时进行增删改查。 操作表结构时，加 MDL写锁 读写锁之间、写锁之间是互斥的，需要保证表结构修改的安全性。 如果有两个线程同时给一个表添加字段，其中一个要等另一个执行完成后，才可以执行。 MDL 的 session 阻塞问题假设这里的 user_info 表是小表，有四个进程在使用： MDL的session阻塞问题示意图.png session A 先启动，这时给表添加了 MDL 读锁； session B 也需要 MDL 读锁，因此可以正常执行； session C 会被 blocked，是因为 session A 的读锁还没有释放，而 session C 需要 MDL 写锁； 因为 session C 被阻塞，前面也提到：所有对表的增删改查操作都需要先申请 MDL 读锁； 现状就是，该表不可进行读写，直到 session A、B 的 MDL 读锁 释放。 这种情况如何安全地添加字段？解决长事务 长事务在提交前会一直占用 MDL 锁，如果要修改表结构，建议先查询是否有正在执行的长事务。设置等待时间 例如：在 ALTER 语句中设置等待时间，如果在时间内拿不到 MDL 锁，则放弃执行，避免阻塞之后的业务 SQL。 MySQL 5.6 支持 online DDL，还会阻塞吗？online DDL 的过程如下： 拿到 MDL 写锁 降级为 MDL 读锁 执行 DDL 升级为 MDL 写锁 释放 MDL 整个过程中只有 3 是真正处理 DDL，占用了大量时间，这期间，表可以正常读写数据；1、2、4、5如果没有锁冲突执行速度会很快。 前面提到例子，是在第一步就发生了阻塞。 行锁行锁就是数据表中行记录的锁，当事务A更新了一行，事务B也要更新同一行时，必须等事务A操作完成后才可以更新。 两阶段锁两阶段锁定义：InnoDB 的事务中，行锁在需要的时候加上，事务结束时释放。（而不是不需要时立刻释放） 两阶段锁举例 有事务 A 和事务 B，字段 id 为主键，在事务 A 更新完成后，事务 B 的语句会被阻塞，直到事务 A 提交后才会执行。 如果事务中需要锁多个行，需要把容易造成锁冲突、影响并发的锁尽量靠后。 例如，电影购票时有下列三个操作： 顾客 A 的账户余额中扣除电影票价； 影院 B 的账户余额中增加电影票价； 记录一条交易日志。 完成这个交易需要进行两个 update 操作，一个 insert 操作。为了保证原子性，这三个操作必须放到一个事务里执行。 三个操作的顺序应该怎么排列呢？ 如果有另一个顾客 C 要买票，事务的操作和上文中一样，则有冲突的部分就是 2。需要修改影院的账户余额，是同一行记录。 根据两阶段锁定义，只有事务结束时才释放锁，所以需要把受冲突的行放到最后，尽量减少行被锁的时间，提升了并发度。所以应该该着 3、1、2 的顺序排列语句。 死锁和死锁检测死锁定义：当并发系统中不同线程出现循环资源依赖，设计的线程都在等待别的线程释放资源时，就会导致这几个线程进入无限等待的状态。 死锁举例 上图中：事务 B 等待事务 A 释放 id &#x3D; ‘200’ 的行锁，事务 A 在等待事务 B 释放 id &#x3D; ‘300’ 的行锁。事务 A 和事务 B 互相等待对方的资源释放，就进入了死锁状态。 死锁的解决策略 直接进入等待，直到超时。 超时时间可以通过参数 innodb_lock_wait_timeout 设置，默认值为 50s。 但是在系统中，等待 50s 是无法接受的；又不能把该参数设置的特别小，比如 1s 左右，容易误伤到普通的锁等待。 发起死锁检测 通过检测发现死锁后，主动回滚死锁链条中的某个事务，其他事务可以继续执行。 设置参数 innodb_deadlock_detect 为 on（默认值即为 on），表示开启这个逻辑。 每当一个事务被锁时，就要循环判断它所依赖的线程是否被其他线程锁住。 每个新启动的、被堵住的线程都需要判断是否因为自己的加入导致了死锁，时间复杂度为 O(n)。假设同时有 1000 个并发线程同时更新一行，死锁检测是 100 万这个量级的，消耗大量 CPU 资源，事务执行速度也很慢。 如何解决热点行更新导致的性能问题在上面 死锁的解决策略 中的 2 提到了该问题，主要难点在于，死锁检测需要消耗大量的 CPU 资源。 常用的解决方法有以下几种： 关闭死锁检测（不推荐） 业务设计时一般不会把死锁当做严重错误，如果出现死锁，就回滚事务，然后通过重试就可以了。 如果关闭检测，会出现大量的业务超时情况，因此不推荐该方法。 控制并发 在 Server 层或者中间件做并发控制，限制同一时间进入更新的线程数量。 也就是对于热点行的更新操作，要在进入引擎前排队，减少大量的死锁检测。 拆行 将一条记录改为逻辑上的多行，以减少锁冲突。 以上文的影院账户为例，将其拆分为 10 行，影院的账户总额为这 10 行记录的和，这样在每次增加金额时，只需要选择其中一行增加就可以，锁冲突的几率为 1&#x2F;10，减少锁等待个数，也降低 CPU 消耗。 但是需要业务逻辑的详细设计，比如在退票时，其中一条记录为 0，代码需要有特殊处理。","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL实战 基础篇（三）","path":"/posts/47099.html","content":"该系列是极客时间林晓斌的 MySQL实战45讲 课程笔记。 索引的常见数据结构索引的出现是为了提高查询效率，有很多种实现方式，也就引入了索引模型的概念。 哈希表哈希表是以键值对（key - value）的形式存储，输入待查找的 key，就可以找到对应的 value。 实现思路： 将 value 放在一个数组里，然后使用哈希函数将 key 换算成数组中确定的位置，把 value 保存在该位置上。 哈希冲突：多个 key 值经过哈希函数换算后，会出现值相同的情况。为了处理这种情况，需要拉出一个链表进行存储。（这里使用的是拉链法，还有其他解决方式） 哈希表存储示意图 以上图为例，ID_CARD_2 和 ID_CARD_4 根据哈希函数换算出的值都是 N。为了解决这个问题，将其都保存到 N 的链表中。 如果需要查找 ID_CARD_2，处理过程是这样的： 将 ID_CARD_2 通过哈希函数得出 N； 在链表中按照顺序遍历，找到 USER2。 图中四个 ID_CRAD_N 的值不是递增的，这样的好处是，在增加新的 USER 时速度很快，只需要按照顺序在后面追加即可。 也不是没有缺点，因为这样是无序排列的，所以区间查询的速度很慢，例如：需要查找 [ID_CARD_X, ID_CARD_Y] 之间的的所有 USER，就必须全部扫描。 哈希表只适用于等值查询的场景，例如：Memcached、Redis 等 NoSQL 引擎。 有序数组有序数组存储示意图 如果使用有序数组实现保存并查找身份证、用户名的功能，假设保存的身份证号不重复，这个数组就是按照递增的顺序保存。 在查询 ID_CARD_2 时，使用二分法就能快速得到结果，时间复杂度是 O(log(N))。 这个索引结果也支持范围查询，假设需要查找范围在 [ID_CARD_X, ID_CARD_Y] 区间的 User，先用二分法找到 ID_CARD_X（如果 ID_CARD_X 不存在，就找大于它的第一个 User），然后向右遍历，直到查询出第一个大于 ID_CARD_Y 的值，退出循环。 在查询效率来说，有序数组是最好的数据结构。 但是，在更新数据时就非常麻烦，往中间插入一条记录，就需要挪动后面的全部记录。 有序数组只适用于静态存储引擎，例如：保存某年的全部城市人口信息。这类不需要修改的数据。 二叉树二叉树示意图 二叉树的特点是： 父节点左子树 所有节点值小于父节点的值 父节点右子树 所有节点值大于父节点的值 按照示意图，如果要查询 ID_CARD_2，则搜索顺序为：USER A -&gt; USER C -&gt; USER F -&gt; USER 2，时间复杂度为 O(log(N))。 为了维持 O(log(N)) 的查询复杂度，就必须保证这是颗平衡二叉树。平衡更新的时间复杂度是 O(log(N))。 二叉树是搜索效率最高的，但是实际上大多数的数据库存储却并不使用二叉树。假设一颗平衡二叉树需要保存 100 万数据，树高为 20，一次查询需要访问二十个数据块。使用机械硬盘随机读一个数据块大概需要 10ms 左右的寻址时间，如果访问 100 万行的表，单独访问一行大概需要 20 * 10ms。时间非常慢。 N叉树为了让查询尽可能少的访问磁盘，就必须少访问数据块，就应该使用 N叉树，这里的 N 取决于数据块的大小。 以 InnoDB 的整数字段为例，N 差不多是 1200，树高 4 层的时候，就可以保存 1200 的数据，大概有 17 亿。 考虑到树根的数据块总是在内存中的，一个 10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。 InnoDB索引模型InnoDB 的索引使用 B+ 树索引模型，所有数据都保存在 B+ 树中。 每张表都是多个 B+ 树：一个主键索引树和多个非主键索引树。树节点的 key 就是某行的主键，value 是该行的其他数据。 每个索引都对应一颗 B+ 树，新建索引就是新建一个 B+ 树，如果查询不走索引，则遍历主 B+ 树。 这部分参考了《MySQL的InnoDB索引原理详解》 第二节 Mysql 的存储引擎和索引。原文中还对比了 MyISM 的非聚簇索引。 假设有下面这个表，主键列为 ID，有字段 Name、Company，且字段 Name 上有索引。 建表语句为： 1234567891011create table user_info( id int primary key, name varchar(16), company varchar(32), index (name))engine = InnoDB;INSERT INTO user_info (id, name, company) values (&#x27;5&#x27;,&#x27;王钢蛋&#x27;,&#x27;公司A&#x27;);INSERT INTO user_info (id, name, company) values (&#x27;8&#x27;,&#x27;小明&#x27;,&#x27;公司B&#x27;);INSERT INTO user_info (id, name, company) values (&#x27;13&#x27;,&#x27;小刚&#x27;,&#x27;公司C&#x27;);INSERT INTO user_info (id, name, company) values (&#x27;16&#x27;,&#x27;小红&#x27;,&#x27;公司D&#x27;); ID Name Company 5 王钢蛋 公司A 8 小明 公司B 13 小红 公司C 16 小刚 公司D InnoDB 索引组织结构图 InnoDB 使用的是 聚簇索引（主键索引也被称为聚簇索引），将主键放在一颗 B+ 树中，行数据保存在叶子节点上。 如果使用 id &#x3D; ‘8’ 的条件查找主键，按照 B+ 树的算法即可找到对应的叶子节点，然后获得行数据。 如果使用 name &#x3D; ‘小刚’ 的条件查询，则有两个步骤： 在辅助键索引的 B+ 树中检索 Name，并获得对应的主键； 使用该主键在主键索引的 B+ 树再次执行检索操作，最终到达叶子节点，获取该行数据。 也就是说，如果使用非主键索引进行查询，会触发一次回表操作，比主键查询要多扫描一颗 B+ 树。因此，尽量多使用主键索引。 因为行数据和叶子节点存储在一起，这样主键和行数据会一起加载进内存。找到叶子节点后可以立刻返回行数据。如果按照主键 ID 组织数据，查询速度会更快。 辅助索引使用主键作为“指针”，不使用地址值作为“指针”的优点是：(1) 减少了当出现行移动或者数据页分裂时索引的维护工作。(2) InnoDB在移动行时，无需更新辅助索引中的“指针”,行的位置会随着数据的修改而发生变化；如果使用聚簇索引，则不管主键 B+ 树如何改变，辅助索引树都不受影响。 聚簇索引的优势在哪？因为行数据和叶子节点存储在一起，这样主键和行数据会一起加载进内存。找到叶子节点后可以立刻返回行数据。如果按照主键 ID 组织数据，查询速度会更快。辅助索引使用主键作为“指针”，不使用地址值作为“指针”的优点是：减少了当出现行移动或者数据页分裂时索引的维护工作。InnoDB在移动行时，无需更新辅助索引中的“指针”,行的位置会随着数据的修改而发生变化；如果使用聚簇索引，则不管主键 B+ 树如何改变，辅助索引树都不受影响。 聚簇索引非聚簇索引索引的几个概念12345678910111213141516CREATE TABLE user_info ( id int PRIMARY KEY, idCard varchar(32) NOT NULL, userName varchar(16) NOT NULL DEFAULT &#x27;&#x27;, age varchar(6), isMale tinyint(1) DEFAULT NULL, INDEX age(age)) ENGINE = InnoDB;INSERT INTO user_infoVALUES (100, &#x27;1234&#x27;, &#x27;王钢蛋&#x27;, &#x27;23&#x27;, &#x27;0&#x27;),\t(200, &#x27;1221&#x27;, &#x27;小明&#x27;, &#x27;15&#x27;, &#x27;1&#x27;),\t(300, &#x27;1529&#x27;, &#x27;小红&#x27;, &#x27;20&#x27;, &#x27;0&#x27;),\t(500, &#x27;4326&#x27;, &#x27;小刚&#x27;, &#x27;18&#x27;, &#x27;1&#x27;),\t(600, &#x27;2341&#x27;, &#x27;于老二&#x27;, &#x27;32&#x27;, &#x27;1&#x27;),\t(700, &#x27;7584&#x27;, &#x27;斧子&#x27;, &#x27;24&#x27;, &#x27;0&#x27;); 以上面这个表为例，如果我想查询年龄在 15 ~ 20 之间的用户，可以使用这个语句： 1SELECT * FROM user_info WHERE age BETWEEN &#x27;15&#x27; AND &#x27;20&#x27;; 在执行的过程中，需要执行几次树的搜索操作，会扫描多少行？ 先过一遍这个语句的执行流程： 在 Name 索引树上查询 age &#x3D; 15 的记录，得到 ID &#x3D; 200； 根据 ID &#x3D; 200，在 ID 索引树中获取对应的行数据； 在 Name 索引树上取下一个值 age &#x3D; 20 ，得到 ID &#x3D; 300； 再回到 ID 索引树中，根据 ID &#x3D; 300 获取对应的行数据； Name 索引树取下一个值 age &#x3D; 21，不满足条件，循环结束。 在这个过程中，回到主键索引树搜索的过程，被称为回表。 可以看到，这条查询语句一共读了 Name 索引树的 3 条记录（步骤1、3、5），回表两次（步骤2、4）。 可以进行索引优化，避免回表过程，如下： 覆盖索引如果查询的语句是： 1SELECT ID FROM user_info WHERE age BETWEEN &#x27;15&#x27; AND &#x27;20&#x27;; 只查询 ID，会命中 age 索引树，叶子节点保存了 ID 值，可以直接返回数据，不需要回表。 在这个查询中，索引 age 已经覆盖了查询需求，被称为 覆盖索引。 由于覆盖索引可以显著减少树的搜索次数、提升查询性能，也是常用的性能提升手段。 常见优化建议优先覆盖高频查询 ：即使无法覆盖所有字段，也要尽量减少回表次数。 例如：最近浏览商品列表，需要返回商品id、name信息，可以直接通过索引覆盖合理设计索引结构 ：利用多字段索引、包含列（INCLUDE）等特性。 例如：分页查询的字段上添加索引，可以快速定位分页位置，减少扫描行数结合其他优化手段 ：如缓存、查询重构、索引合并等。 组合索引（联合索引）B+ 树这种数据结构，可以使用索引的“最左前缀”，定位记录。 为了直观说明这个问题，以上面的 user_info 表为例，使用 userName、age 建立联合索引： 联合索引.png 当查询条件为 userName &#x3D; ‘小刚’，可以快速定位到 ID &#x3D; 500；当查询条件为 userName like ‘王%’，查找到第一个符合条件的记录 ID &#x3D; 100，再向后遍历，直到不满足条件。 只要满足最左前缀，就可以利用索引加速，包括最左的几个字符或者字段： 字符：userName like ‘王%’; 字段：userName &#x3D; ‘斧子’ and age &#x3D; ‘24’; 即使查询条件的顺序和创建复合索引的数据不一致，只要包含最左字段，且不跳过中间字段，就可以生效。 如何安排联合索引内的字段顺序？这里的标准是：索引的复用能力。第一原则：通过调整顺序可以减少索引数量，则优先采用。 如果使用 (idCard, userName) 建立联合索引，就可以不用建立 idCard 字段的索引。 如果既有联合索引 (idCard, userName)，又需要根据 userName 单独查询呢？第二原则：空间。 idCard字段要大于userName字段，则推荐建立联合索引 (idCard, userName)和单字段索引(userName)。 索引下推这是 MySQL 5.6 版本引入的，可以在索引遍历的过程中，对索引包含的字段先做判断，过滤掉不满足条件的记录，减少回表次数。 在 MySQL 5.6 版本之前，只能根据顺序回表，在主键索引上找到相应的数据行，然后比对字段值。 以该语句为例： 1SELECT * FROM user_info WHERE userName LIKE &#x27;于%&#x27; AND age = &#x27;20&#x27; AND isMale = 1; 图中每个箭头表示回表一次。 无索引下推：因为不需要比对，特意去掉了 age 的值，会按照顺序查找 ID 再回表取出记录。回表 4 次 有索引下推：在索引内部就比对了 age，不满足 age &#x3D; ‘20’ 的记录直接跳过，只对 ID9、ID6 的数据回表。回表 2 次 索引下推的局限性索引字段顺序必须符合最左前缀原则查询条件的字段必须包含在索引中版本要求 5.6+","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL实战 基础篇（二）","path":"/posts/48002.html","content":"该系列是极客时间林晓斌的 MySQL实战45讲 基础篇 3、8 课程笔记。 事物就是要保证一组数据库操作，要么全部成功，要不全部失败。MySQL 的事物支持是在引擎层实现的，但不是所有引擎都支持事物，比如 MySQL 原生的 MyISAM 引擎就不支持事务，这也是 MyISAM 被 InnoDB 取代的重要原因之一。 事物和 MVCC事物是数据库操作的逻辑单元，将多个操作打包为一个不可分割的原子性过程。MVCC 是实现事务隔离性的核心机制。 事物的特性 ACID（Atomicity、Consistency、Isolation、Durability）： 原子性：事物是一个不可分割的最小操作单元，事物中的操作要么全部成功提交，要么全部失败回滚 实现方式Undo Log事物执行过程中，InnoDB 会记录所有数据修改前的原始值到 Undo Log 中。 一致性：事物执行前后，数据库必须保持逻辑一致性（数据完整性、业务规则） 实现方式使用 持久性 + 原子性 + 隔离性一起实现约束保障：主键、外键、唯一约束等保证数据完整性；业务逻辑：依赖于应用层的校验，确保逻辑无误（比如：转账余额不能为负）；ACID联动：原子性、隔离性、持久性共同确保一致性。 隔离性：并发事物之间互不干扰，每个事物感知不到其他事物的存在 实现方式锁机制行级锁：锁住被修改的行，仿制其他事物干扰（比如写锁互斥）间隙锁：防止幻读，锁定索引记录的间隙MVCCRead View：事物启动时生成一个数据快照，基于事物ID判断可见性版本链：每条记录包含了隐藏字段（DB_TRX_ID、DB_ROLL_PTR），指向 Undo Log Undo Log 的历史版本 持久性：事物提交后，修改永久保存，即使系统崩溃也不会丢失 实现方式Redo log将所有对数据的修改（增、删、改）都写入日志（Undo log） 事物的隔离性和隔离级别事物并行可能出现的问题脏读（dirty read）：一个事物读到了另一个 未提交事物修改过的数据不可重复读（non-repeatable read）：一个事物内多次执行相同的查询，出现了前后两次读到的数据不一样的情况幻影读（phantom read）：一个事物内多次执行相同的查询，但是由于其他事物的干扰，导致前后查询结果集行数不同 为了解决这些问题，出现了 隔离级别 的概念。隔离的级别越高，效率就越低。 隔离级别（低到高） 描述 读未提交 Read Uncommitted 一个事务还没提交时，它做的变更就能被别的事务看到。 读提交 Read Committed 一个事务提交之后，它做的变更才会被其他事务看到。 可重复读 Repeatable Read 一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。未提交变更对其他事务不可见。 串行化 Serializable 对于同一行记录，”写”加”写锁”，”读”加”读锁”。读写锁冲突时，后访问的事务需等待前一个事务完成。 针对不同的隔离级别，事物并发时可能出现的问题也不同： 读未提交，可能出现的问题：脏读、不可重复读、幻影读 读提交，可能出现的问题：不可重复读、幻影读 可重复读，可能出现的问题：幻影读 串行化，以上问题不可能发生 不同隔离级别示例读未提交： V1 &#x3D; 2， V2 &#x3D; 2， V3 &#x3D; 2读提交： V1 &#x3D; 1， V2 &#x3D; 2， V3 &#x3D; 2重复读： V1 &#x3D; 1， V2 &#x3D; 1， V3 &#x3D; 2串行化： V1 &#x3D; 1， V2 &#x3D; 1， V3 &#x3D; 2 实现方式： 在事务四种隔离级别的实现中，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。 读未提交：直接返回记录中的最新值，在这个级别下没有视图的概念； 读提交：视图在每个 SQL 语句的执行时创建； 可重复读：视图在启动时创建，在整个事务的执行过程中使用； 串行化：使用加锁的方式避免并行访问。 配置： Oracle 的默认隔离级别是 读提交。 MySQL 的默认隔离级别是 重复读，可以通过启动参数 transaction-isolation 进行隔离级别的设置，查看命令如下： 1show variables MVCC如何支撑事物隔离当前读和快照读两种不同的读取方式，区别主要在于 是否读取最新版本数据 以及 是否加锁 当前读 需要操作最新数据并保证数据一致性，常用于写操作依赖读的场景 使用方式 显示使用锁：SELECT ... FOR UPDATE、SELECT ... LOCK IN SHARE MODE； 隐式触发：UPDATE、DELETE、INSERT 实现机制 锁 快照读 仅需读取数据且不要求最新值，适合读多写少的业务 使用方式 普通 SELECT 语句 实现机制 MVCC MVCC是什么MySQL 的 Innodb 引擎下，隔离级别为 RR 或 RC，且快照读时，基于 MVCC 做数据的多版本并发控制。 多版本：MySQL 维护着 行数据的多个版本 并发控制：多个事物操作某一行记录时，MySQL 控制返回多个版本行记录的某个版本 只有在SELECT时才会涉及到MVCC；UPDATE、DELETE、INSERT都使用锁解决 MVCC实现原理主要由三部分组成：隐式字段、undo log、Read View（这里只是大概介绍）。 记录状态变更示意图 隐式字段 DB_TRX_ID 创建 或 最后一次修改该记录的事务ID。 DB_ROLL_PTR 回滚指针，配合 undo log，指向这条记录的上一个版本，形成一个链表。 DB_ROW_ID 隐藏的自增主键，数据库默认为该记录生成的唯一隐式主键。 undo log主要分为两种： insert undo log 事务在 insert 时产生的 undo log。只在回滚时需要；事务提交后可被立即丢弃。 update undo log 在 update 或 delete 时产生的 undo log。在回滚、快照读时需要。只有在回滚或者快照读不涉及该日志时，对应的日志会被 purge 统一清除。 对MVCC 有帮助的是 update undo log。 Read ViewRead View 就是事务进行 快照读 时产生的 读视图（Read View）。 在该事务执行快照的一刻，生成当前数据库系统的一个快照，记录并维护当前活跃事务的ID。 当前活跃事务的 ID 就是事务开始时被分配的 ID，具有唯一性且严格递增。 Read View 的四个属性结合 版本链数据访问规则（undo log） Read View 具有四个属性： creator_trx_id 创建该 Read View 的事物 ID（也就是当前事物的 ID）。 trx_ids 一个数组，用来保存 Read View 生成时，系统内所有其他活跃事物的事务 ID。 up_limit_id 所有活跃事物的 最小事物 ID。 low_limit_id 系统中已分配的 最大事物 ID，任何新事物 ID，都会从 `low_limit_id + 1` 开始分配。 版本链数据访问规则（事务可见性的判断） trx_id，代表的是当前事物 ID trx_id == creator_trx_id 可以访问该版本。 说明数据是由当前这个事物更改的。 trx_id &lt; up_limit_id 可以访问该版本。 说明数据已经提交了。 trx_id &gt; low_limit_id 不可以访问该版本。 说明该事物是在 Read View 生成后才开启的。 up_limit_id &lt;= trx_id &lt;= low_limit_id 如果 trx_id 不在 trx_ids 中，可以访问该版本。 说明数据已经提交。 在 RC 和 RR 下的不同表现在同一个事物内，进行两次快照读： RR，返回的是相同版本 RC，返回的是不同版本记录 为什么 RC 有不可重复读的问题，RR 是可重复读 RC 和 RR 的实现可重复读 RR 的核心就是 一致性读，事务更新时只能使用当前读，如果行锁被其他事务占用，就进入锁等待。 读提交 RC 也是用 一致性读 实现的。 二者的区别在于，一致性视图的创建时机不同（也是出现不同表现的原因）： 可重复读 RR 只在事务开始时创建 Read View，之后该事务的查询共用 读提交 RC 每个语句执行前都会生成一个新的 Read View RR、RC 总结可重复读 RR：查询时，只承认事务启动前提交的数据 读提交 RC：查询时，只承认语句启动前提交的数据 解决了什么问题 解决了读写阻塞的问题 SELECT ... FOR UPDATE、SELECT ... LOCK IN SHARE MODE 都是当前读，会独占写锁； 这样对读锁和写锁是互斥的，这两个事物都会被阻塞。 普通的 SELECT 语句就不会涉及到锁，底层使用 MVCC 实现的，有效避免了被阻塞。 在 RR 隔离下，在快照读方面避免出现幻读 并没有完全解决，实际还是要依靠间隙锁盒临键锁解决。 长事物的风险MySQL 中，每条记录在更新时都会在 undo log 中记录一条回滚操作，通过该记录可以得到前一个状态的值。 undo log 的作用就是为了回滚，所以记录是反向的。比如事务的操作时把1改成2，undo log 的记录就是将2改成1，这样是为了方便回滚。 此处以 可重复读 为例假设有一个值1，按照顺序被改成了2、3、4，则 undo log 就会有图中的记录，方便进行回滚操作。当前的值为4，但是在查询这条记录时，不同时间段启动的事物有不同的 read view。如图所示，不同的视图中，这个记录的值分别为1、2、4，同一条记录在系统中有不同的版本，这个就是数据库的多版本并发控制（MVCC）。对于 read view A 而言，如果要取到 1，则需要将当前值按照顺序依次回滚。即使有另一个事物正在将 4 改成 5，这个事物和 read view A、B 也是不冲突的。有行锁保证修改时，另一个事物不会出现回滚的现象。 回滚日志（undo log）并不是一直保留的，当系统中没有比这个回滚日志更早的 read view 时，就会被删除。 也因为这个原因，不建议使用长事物。 长事物会在系统中保存很多老的事物视图，由于这些事物随时可能访问数据库里的任何数据，所以在这个事物提交前，需要保留它可能用到的回滚日志，意味着要占用大量存储空间。 除了存储空间，长事物还会占用锁资源，有可能拖垮整个数据库。 事物的启动方式和设置事务的启动方式： 第一种： 使用 BEGIN、ROLLBACK、COMMIT 实现 BEGIN : 开始一个事物 ROLLBACK : 回滚事物 COMMIT : 提交事物 在执行到之后第一个操作 InnoDB 表的语句时，事务才真正启动（一致性视图在第一个快照读语句创建）： 123START TRANSACTION···COMMIT; 第二种： 立刻启动一个事务（一致性视图在执行时就创建）： 1START TRANSACTION WITH consistent SNAPSHOT; 自动提交通过参数配置，改变自动提交模式 SET AUTOCOMMIT &#x3D; 0 : 关闭自动提交 SET AUTOCOMMIT &#x3D; 1 : 开启自动提交 长事物的排查和设置有些数据库默认设置 SET AUTOCOMMIT = 0，这导致了接下来的查询都在事物中，如果有长连接，就会导致意外的长事物。建议使用 commit work and chain 语法，提交事务后自动开启下一个事务，省去了再次执行 begin 的开销。12-- 查询超过60s的事务select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))&gt;60","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL实战 基础篇（一）","path":"/posts/11256.html","content":"该系列是极客时间林晓斌的 MySQL实战45讲 课程笔记。 MySQL逻辑架构图MySQL 逻辑架构图 查询语句的执行过程大体来说，MySQL可以分为两部分：Server层和存储引擎层。 Server层 包括连接器、查询缓存、分析器、优化器、执行器等，涵盖MySQL大多数核心服务功能，以及所有内置函数（例如：日期、时间、数学和加密函数等）。 所有跨存储引擎的功能都在这一层实现，比如：存储过程、触发器、视图等。 存储引擎层 负责数据的存储和提取。 架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。 现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。 也就是说，如果执行 CREATE TABLE 建表的时候，如果不指定引擎类型，默认是用 InnoDB。也可以在建表语句中使用 engine &#x3D; memory，指定使用内存引擎创建表。 不同存储引擎的表数据存取方式、支持的功能不同。 从图中可以看出，不同存储引擎共同一个 Server层。 下面以这条查询语句为例，了解执行流程和每个组件的作用： 1SELECT * FROM TABLE WHERE ID = 10; 连接器第一步：通过连接器连接数据库。连接器负责与客户端建立连接、获取权限、维持和管理连接。 连接命令如下，其中，mysql是客户端工具，用来和服务端建立连接；-h 指定IP；-P 指定端口；-u 指定用户名；p指定密码。： 1mysql -h$ip -P$port -u$user -p 在完成TCP握手后，连接器使用输入的用户名和密码验证身份： 如果用户名或密码错误，会收到一个”Access denied for user”的错误，然后客户端程序结束执行。 如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。 如果权限发生变化，将会在下次重新连接后生效。 可以使用 show processlist 命令查看空闲的连接，如果长时间没有操作，连接器会自动断开，是由参数 wait_timeout 控制的，默认值是 8 小时。 连接断开后如果继续发起请求，会收到错误提示：Lost connection to MySQL server during query。如果要继续请求，重新建立连接后执行就可以了。 长链接：连接成功后，如果客户端持续有请求，则一直使用同一个连接。 短连接：每次执行完很少的几次查询就断开连接，下一次查询再重新建立连接。 长连接太多会占用内存，可能导致内存占用过多，被系统杀进程（MySQL异常重启）。 短连接频繁建立耗时 尽量使用长连接，上述问题的解决方法可以参考下列两种方式： 定期断开长连接。使用过一段时间后，或者程序里执行内存较大的操作后，断开连接，之后要查询再重连。 MySQL 5.7 或更新版本，可以执行 mysql_reset_connection 初始化连接资源。不需要重新连接和权限校验。 查询缓存第二步：查询缓存。建立连接后就可以执行SQL语句，会先查询缓存。 MySQL拿到一个查询请求后，会先在缓存中查找，是否执行过该语句。 之前执行结果是以 key-value 形式保存的，key是查询语句，value是查询结果。如果能根据语句找到key，就会将value直接返回给客户端。 如果语句不在缓存中，则继续执行后面的阶段，执行完成后将结果存入缓存。 查询缓存弊大于利，且MySQL 8.0后删除了该功能。 查询缓存时，需要语句和参数与缓存中的key完全相同。 表更新后，该表的全部缓存会被情况。除非是系统配置表，或者静态码表，否则不推荐使用缓存。 对于需要查询的语句，可以设置参数进行查询（MySQL 8.0后删除）： 1SELECT * SQL_CACHE FROM TABLE WHERE ID = 10; 分析器第三步：对SQL语句进行解析。如果缓存没有命中，分析器会解析SQL语句，了解用户意图。 这一步会判断语句是否正确，表、列是否存在等。 分析器会按照词法、语法的步骤分析传入的SQL语句： 词法分析 将输入语句中的 select 关键字识别出来，是查询语句。把字符串 TABLE 识别为 表名TABLE，字符串 ID 识别为 列ID。 语法分析 分析器根据词法分析的结果，判断查询语句是否符合MySQL的语法要求。 如果出现语法错误，会收到提示，例如： 123ELECT * FROM TABLE WHERE ID=1;ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near &#x27;ELECT * FROM TABLE WHERE ID=1&#x27; at line 1 语法错误通常会提示第一个出现错误的位置，只需要关注 user near 后的内容。 优化器第四步：对SQL语句进行优化，选择处理方式。执行前的最后一步，这一步将决定SQL语句的执行方案。 优化器是在表里有多个索引时，决定使用哪一个索引；或者在多表关联查询时，决定各个表的连接顺序。 1SELECT * FROM TABLE1 t1 JOIN TABLE2 t2 USING(ID) WHERE t1.C = 10 and t2.D = 20; 以这条查询语句为例： 可以先TABLE1中取出 C &#x3D; 10 的记录，再根据 ID 关联到TABLE2，再判断TABLE2中 D 的值是否为 20； 也可以TABLE2中取出 D &#x3D; 20 的记录，再根据 ID 关联到TABLE1，再判断TABLE1中 C 的值是否为 10. 这两种执行方案的逻辑结果相同，但是执行效率不同，优化器的作用就是决定使用哪一个方案。 执行器第五步：执行SQL语句。最后一步，确定了意图和方案后，开始执行语句。 开始执行前，会先判断用户对这个表是否有操作的权限，如果没有，就会返回权限错误。 限验证不止在执行器中，在分析器中和缓存结果返回前都会进行验证。 判断用户有该表的权限后，语句会打开表继续执行。打开表时，执行器根据表的引擎定义，调用这个引擎的相关接口。 在这条语句中，如果ID字段没有索引，执行器的流程如下： 调用 InnoDB 引擎接口，取这个表的第一行，判断ID是否为10，如果不是则跳过，如果是就把这行结果存到结果集中； 调用引擎接口取下一行，进行相同的逻辑判断，直到这个表的最后一行； 执行器将上述遍历过程中，所有满足条件的结果行组成记录，作为结果集返回给客户端。 至此，这个查询语句就执行完了。 如果ID字段有索引，执行的逻辑也差不多： 第一次调用的是 “取满足条件的第一行” 这个接口； 循环调用 “取满足条件的下一行” 接口； 遍历完成后返回给客户端。 数据库的慢查询日志中有一个 rows_examined 的字段，表示这条语句在执行过程中扫描了多少行。这个值是在执行器每次调用引擎获取数据行时累加的。 有些场景下，执行器调用一次，在内部引擎扫描了多行，因此引擎扫描行数和 rows_examined 不是完全相同的。 总结： 引擎层各种获取数据的方法都是定义好的，是静态方法； 优化器生成的执行计划，决定了执行器会选择存储引擎的哪个方法获取数据； InnoDB存储引擎层的优化措施很多，对执行器来说是一个黑箱，只要调用即可。 更新语句的执行过程以下面这条更新语句为例： 1UPDATE TABLE SET B = B + 1 WHERE ID = 10; 和查询语句类似，通过连接器和数据库建立连接。 这条更新语句会表 TABLE 的缓存全部清空，这也是不推荐使用缓存查询的原因。 然后按照分析器、优化器、执行器的流程继续执行。 与查询流程不一样的出，除了上述部分，更新语句还涉及到两个重要的日志模块： redo log （重做日志） binlog （归档日志） 客户端在执行下列语句时，数据库服务端会涉及到 redo log 和 binlog 两个日志文件的更新： DDL（create）DML（insert, update, delete）DCL（grant, revoke） redo log举例不知道你还记不记得《孔乙己》这篇文章，酒店掌柜有一个黑板，专门用来记录客人的赊账记录。如果赊账的人不多，那么他可以把顾客名和账目写在板上。但如果赊账的人多了，黑板总会有记不下的时候，这个时候掌柜一定还有一个专门记录赊账的账本。如果有人要赊账或者还账的话，掌柜一般有两种做法：一：直接把账本翻出来，把这次赊的账加上去或者扣除掉；二：先在黑板上记下这次的账，等打烊以后再把账本翻出来核算。在生意红火柜台很忙时，掌柜一定会选择后者，因为前者操作实在是太麻烦了。首先，你得找到这个人的赊账总额那条记录。你想想，密密麻麻几十页，掌柜要找到那个名字，可能还得带上老花镜慢慢找，找到之后再拿出算盘计算，最后再将结果写回到账本上。这整个过程想想都麻烦。相比之下，还是先在黑板上记一下方便。你想想，如果掌柜没有黑板的帮助，每次记账都得翻账本，效率是不是低得让人难以忍受？ MySQL中也是如此，如果每次更新操作都需要写进磁盘，磁盘找到对应记录再更新，整个IO成本和查找成本都很高。MySQL也使用了类似酒店掌柜黑板的思路来解决这个问题。 黑板和账本配合的过程，就是MySQL中长水的 WAL技术（Write-Ahead logging），先写日志，再写磁盘（先写到黑板上，再更新账本）。 具体而言，需要更新一条记录时，InnoDB会先把记录写到 redo log 中，并更新内存，这时更新就算完成了。在空闲的时候，InnoDB会把这条操作记录更新到磁盘里面。 如果今天需要更新的数据特别多怎么办？ InnoDB的 redo log 大小是固定的，比如一组四个文件，每个文件大小是1GB，那这块“黑板”就可以记录4GB的操作。从头开始写，写到末尾就回到开头循环。 write pos：是当前记录的位置，一边写一边后移，写到 logFile-3的末尾就会回到logFile-0的开头，继续操作。 check point：是当前要擦除的位置，往后推移并循环，擦除前需要把记录更新到数据文件。 write pos 和 check point 之间：表示还空着的部分，可以记录新的操作。如果write pos追上的话，则不能执行新的更新，需要暂时停止，擦除记录后继续操作。 有了 redo log，InnoDB才能保证，即使数据库发生异常重启，之前提交的记录也不会丢失，这个功能被称为crash-safe。 总结redo log 是 InnoDB 特有的，属于存储引擎层；redo log保存在内存和硬盘中，分为 redo log buffer（日志缓冲，易丢失）和 redo log file（持久的）；redo log 记录的不是数据页更新后的状态，而是数据页的改动。 binlog注意MySQL 5.7 版本的 binlog 默认关闭需要使用命令：show variables like &#39;log_bin%&#39; 手动开启后查看。 最开始没有 InnoDB 引擎，MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。所以 InnoDB 使用另外一套日志系统——也就是 redo log 来实现 crash-safe 能力。 binlog 是在MySQL的Server层实现； binlog 是逻辑日志，记录的是这个语句的原始逻辑，例如：给 ID &#x3D; 10 这一行的 B 字段 + 1； binlog 存储空间不固定，也就是说一个 binlog 文件写到一定大小后，会自动切换到下一个，不会覆盖以前的日志。 注意为什么binlog记录了操作却不支持crash-safe？redo log 记录的是没有写入磁盘的日志，写入磁盘的日志会被删除；而 binlog 记录的是全量日志；假设数据库crash，想将未写入磁盘但是已写入 redo log 和 binlog 中的数据恢复到内存中，binlog无法恢复，因为没有类似 check point 的记录，不能明确哪些数据已经写入到磁盘，哪些数据还没有写入。 对这两个日志系统有一定了解后，再来看执行器和 InnoDB 引擎在执行这个简单的 update 语句时的内部流程。 执行器先找引擎取 ID&#x3D;2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID&#x3D;2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。 执行器生成这个操作的 binlog，并把 binlog 写入磁盘。 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。 update执行流程示意图 在示意图中最后三步，将 redo log 的提交拆分成了两步，prepare 和 commit，这就是两阶段提交。 两阶段提交因为 redo log 和 binlog 是完全不同的逻辑，如果先写 redo log 再写 binlog，或者使用反过来的顺序，很容易出现问题。 以上面的更新语句为例，假设当前 ID &#x3D; 10 的这一行，字段 B 的数值为0，需要将其 +1；执行update的过程中，在写入完第一个日志后，还没有开始写入第二个日志前，发生了crash。 redo log 写入完成，binlog 尚未写入假设此时数据库crash，只凭借 redo log 也可以恢复数据，字段 B 的数值已经变为1。但是 binlog 没有写入就发生日常，这一条语句不会出现在 binlog 的备份日志中，如果日后需要使用 binlog 恢复数据，恢复后的字段 B 仍为0，与原库的数据不符。 redo log 没有写入，binlog 写入成功因为 redo log 还没有写入就发生异常，重启后判断这个事物无效，将会回滚这次操作，字段 B 的值仍为0。但是 binlog 已经保存了这次操作，之后使用 binlog 恢复数据时，会把字段 B 改为1，与原库中的数据不符。 可以看出，如果不使用两阶段提交，很容易出现恢复数据时前后两次数据不一致的情况。 这个情况不止出现在恢复数据时，数据库扩容通常使用全量备份 + binlog 实现，如果出现恢复时，前后两次数据不一致的情况，就会导致线上的主从数据库不一致。 redo log 和 binlog 都可以表示事物的提交状态，两阶段提交是为了保证逻辑上的相同。 小结 怎样让数据库恢复到半个月内任意一秒的状态？ binlog 记录了全部的逻辑操作，如果要恢复误删除的数据，就必须要有一个时间段内的全部 binlog，比如要恢复半个月内的任意一次操作，那必须有半个月内全部 binlog 备份。 例如：某天上午十点有一次误删表的操作，应该如何恢复呢？ 首先，找到最近一次的全量备份，将其恢复到临时库； 然后从备份的时间点开始，取出 binlog，一直到误删的前一时刻； 就可以按需将临时库的数据恢复到正式库中。 redo log和binlog的区别： redo log binlog 所在层级不同 引擎层，InnoDB特有的 Server层 记录内容不同 物理日志：在某个数据页上做了什么修改 逻辑日志：记录原始逻辑，给id&#x3D;2这一行的c字段+1 写入文件、方式不同 写入的空间固定，循环写 空间不固定，追加写入。文件写完后会自动切换到下一个文件，不覆盖之前的日志。 两阶段提交 是跨系统维持数据库逻辑一致性的常用方案。 相关参数设置 innodb_flush_log_at_trx_commit &#x3D; 1 表示每次事物的 redo log 都会持久化到磁盘中，可以保证数据库异常重启后，数据不丢失。 sync_binlog &#x3D; 1 表示每次事物的 binlog 都会持久化到磁盘中，可以保证数据库异常重启后，binlog 不丢失。 问题02 | 日志系统：一条SQL更新语句是如何执行的？-极客时间 (geekbang.org)网页搜索 WL，评论区 redo log的概念是什么?为什么会存在redo log 是 InnoDB 特有的，在存储引擎层，包含两部分： 内存中的 日志缓冲 redo log buffer 硬盘中的 日志文件 redo log file 什么是WAL(write-ahead log)机制, 好处是什么redo log 为什么可以保证crash safe机制binlog的概念是什么, 起到什么作用, 可以做crash safe吗?binlog和redolog的不同点有哪些?物理一致性和逻辑一直性各应该怎么理解?执行器和innoDB在执行update语句时候的流程是什么样的?如果数据库误操作, 如何执行数据恢复?什么是两阶段提交, 为什么需要两阶段提交, 两阶段提交怎么保证数据库中两份日志间的逻辑一致性(什么叫逻辑一致性)?如果不是两阶段提交, 先写redo log和先写bin log两种情况各会遇到什么问题?","tags":["MySQL"],"categories":["MySQL"]}]